diff --git a/Documents/ADDER_v1.0.1_Release_Notes.pdf b/Documents/ADDER_v1.0.1_Release_Notes.pdf
deleted file mode 100755
index 6c1db5e..0000000
Binary files a/Documents/ADDER_v1.0.1_Release_Notes.pdf and /dev/null differ
diff --git a/Documents/Manuals/ADDER_User_Guide_v1.0.1_ANL_RTR_TM_21-8.pdf b/Documents/Manuals/ADDER_User_Guide_v1.0.1_ANL_RTR_TM_21-8.pdf
deleted file mode 100644
index 62b48a0..0000000
Binary files a/Documents/Manuals/ADDER_User_Guide_v1.0.1_ANL_RTR_TM_21-8.pdf and /dev/null differ
diff --git a/List of known ADDER bugs.docx b/List of known ADDER bugs.docx
deleted file mode 100644
index 6e0b8ea..0000000
Binary files a/List of known ADDER bugs.docx and /dev/null differ
diff --git a/README.rst b/README.rst
index 248a6e6..0bf6174 100755
--- a/README.rst
+++ b/README.rst
@@ -3,11 +3,9 @@ Advanced Dimensional Depletion for Engineering of Reactors (ADDER)
 ==================================================================
 
 The Advanced Dimensional Depletion for Engineering of Reactors (ADDER) software
-is a flexible, performant, and modern fuel management and depletion tool. The
-target audience of this tool is first the Research and Test Reactor Program
-at Argonne National Laboratory (ANL) and, eventually, to experts outside of ANL.
-This report is the user guide for the software release referred to as ADDER
-v1.0.1.
+is a flexible, performant, and modern fuel management and depletion tool. The 
+report included in the Documents folder is the user guide for the software 
+release referred to as ADDER v1.1.0, released in July 2025.
 
 This software is fundamentally an interface between the user, external neutron
 diffusion or transport theory solvers, and a depletion solver. The user will
@@ -20,9 +18,10 @@ for the design of a reactor, such as branch calculations for multiple xenon
 conditions or operating temperatures.
 
 The initial application of ADDER will be to utilize the MCNP6_ (or MCNP5_)
-software for neutron transport and either ORIGEN2_ for depletion and decay
-functionality or an internal Chebyshev rational approximation method (CRAM_)
-solver.
+software for neutron transport and either an internal Chebyshev rational 
+approximation method (CRAM_) solver or ORIGEN2_ for depletion and decay 
+functionality. The former, developed natively within ADDER, is generally 
+preferred.
 
 This README file provides a primer for the ADDER software. The complete 
 software manual is located in the ``Documents`` folder of this repository. 
@@ -35,7 +34,7 @@ Installing ADDER
 ****************
 
 ADDER is written in the Python 3 programming language. It therefore requires
-that a Python 3.7-compatible interpreter be installed locally.
+that a Python 3.8 interpreter be installed locally.
 
 In addition to Python itself, ADDER relies on third-party packages.
 All prerequisites can be installed using Anaconda_ (recommended), Python's
@@ -61,6 +60,14 @@ pip_ command, or through the package manager in most Linux distributions.
       Configobj is a simple but powerful configuration file reader with syntax
       similar to the classic Windows .INI file format.
 
+   `MCNPTools <https://github.com/lanl/mcnptools>`_
+      MCNPTools includes binary utilities that facilitate common tasks or 
+      querying MCNP output files. ADDER uses MCNPTools to extract MCNP tallies.
+
+   `pyparsing <https://github.com/pyparsing/pyparsing>`_
+      pyparsing is used to parse strings in the initial MCNP input to retrieve 
+      information related to MCNP tally cards that are processed by ADDER.
+
 .. admonition:: Optional
    :class: note
 
@@ -106,6 +113,7 @@ of interest.
 ***************
 Executing ADDER
 ***************
+
 ADDER can be executed in whichever directory the user wishes. The simplest
 usage of ADDER includes providing one input argument, the name of the
 already-generated ADDER input file. The format of this input file is described
@@ -226,40 +234,45 @@ The ADDER software is distributed with a few utility scripts, included in the
 	Radiation Safety Information Computational Center (RSICC) distribution 
 	of ORIGEN2.2. The path to the library folder needs to be provided via 
 	the command-line argument ``-r``. Additional information can be found 
-	in Section 4.1.1 of the manual.
+	in the User Guide.
 * ``adder_convert_origen22_library.py``: 
 	this scripts allows users to convert an individual ORIGEN2.2 library file, 
 	containing the desired cross-sections and yield values to convert. 
-	The script requires several arguments. More information can be found in 
-	Section 4.1.1 of the manual.
+	The script requires several arguments. More information can be found in the
+    User Guide
 * ``adder_extract_materials.py``: 
 	extracts the ADDER HDF5 output (``results.h5``) and generates a ``.csv`` 
 	file containing the power, k:eff:, one-group fluxes, Q-recoverable energy, 
 	and isotopic data for a selected material. The script requires 
 	(in the following order): the path to the ``results.h5`` file generated
 	by ADDER, the path to the desired output ``.csv`` file, and the name of the 
-	required material. Additional information can be found in Section 3.1 of the manual.
+	required material. Additional information can be found in the User Guide.
 
 ****************
 Release Schedule
 ****************
-ADDER v.1.1.0 is currently scheduled to release at the end of August 2024. Dates are subject to change.
+
+ADDER v.2.0.0 is currently scheduled to release in 2026. 
+Dates are subject to change.
 
 ********
 Contacts
 ********
-For inquiries about the ADDER software please reach out to our development team at adder@anl.gov.
-Please contact us to be added to the list of known users and receive notifications concerning errors and
-bugs as they are discovered, as well as updates on new versions releases.
+
+For inquiries about the ADDER software please reach out to our development team 
+at adder@anl.gov. Please contact us to be added to the list of known users and 
+receive notifications concerning errors and bugs as they are discovered, as 
+well as updates on new versions releases.
 
 ************
 Citing ADDER
 ************
+
 If you use ADDER for your work, please cite the following reference:
 
-Anderson, K., Mascolino, V., and Nelson, A. G.. 2022. "User Guide to the 
-Advanced Dimensional Depletion for Engineering of Reactors (ADDER) Software". 
-United States. https://doi.org/10.2172/1866062. https://www.osti.gov/servlets/purl/1866062.
+V. Mascolino, K. Anderson, C. Castagna, M. Elsawi, and E. Wilson, "User Guide
+to the Advanced Dimensional Depletion for Engineering of Reactors (ADDER)
+Software", ANL/RTR/TM-24/25, Rev 1, Argonne National Laboratory, USA, Jul. 2025
 
 **********
 References
diff --git a/adder/__init__.py b/adder/__init__.py
index 40a7d60..0fc1ad9 100644
--- a/adder/__init__.py
+++ b/adder/__init__.py
@@ -11,7 +11,8 @@ from adder.input_validation import *
 from adder.isotope import *
 from adder.control_group import ControlGroup
 from adder.material import Material
+from adder.mcnp.tally import Tally
 from adder.neutronics import Neutronics
 from adder.depletion import Depletion
 
-__version__ = '1.0.1'
+__version__ = '1.1.0'
diff --git a/adder/constants.py b/adder/constants.py
index fd35c85..e879357 100644
--- a/adder/constants.py
+++ b/adder/constants.py
@@ -26,22 +26,29 @@ VALID_OPERATIONS_SECTIONS = ["deplete", "shuffle", "transform", "write_input"]
 VALID_MOVE_TYPES = defaultdict(lambda: ["material"])
 VALID_MOVE_TYPES["mcnp"] = ["material", "universe"]
 DEFAULT_MOVE_TYPE = defaultdict(lambda: "material")
+VALID_TALLY_TYPES = ["material", "universe", "unprocessed"]
+DEFAULT_TALLY_TYPE = defaultdict(lambda: "universe")
 VALID_TRANSFORM_TYPES = defaultdict(lambda: None)
 VALID_TRANSFORM_TYPES["mcnp"] = ["universe", "cell", "surface"]
 DEFAULT_TRANSFORM_TYPE = defaultdict(lambda: None)
 DEFAULT_TRANSFORM_TYPE["mcnp"] = "universe"
+DEFAULT_TRANSFORM_RESET = False
 DEFAULT_LIBRARY_DUMP_ALL = "all_modified"
 VALID_GEOM_SWEEP_TYPES = ["surface"]
 VALID_GEOM_SWEEP_AXES = ["x", "y", "z", "pitch", "yaw", "roll"]
 DEFAULT_GEOM_SWEEP_RANGE_ENDPOINT = True
 VALID_ANGLE_TYPES = ["degrees", "radians"]
 DEFAULT_ANGLE_TYPE = "degrees"
+VALID_GEOM_SEARCH_REFERENCE_POSITION = ["initial", "last"]
+DEFAULT_GEOM_SEARCH_REFERENCE_POSITION = "initial"
+VALID_GEOM_SEARCH_INITIAL_GUESS = ["last"]
 DEFAULT_GEOM_SEARCH_MAX_ITERATIONS = 30
 DEFAULT_GEOM_SEARCH_MIN_ACTIVE_BATCHES = 30
+VALID_GEOM_SEARCH_MIN_ACTIVE_BATCHES = 4
 DEFAULT_GEOM_SEARCH_UNCERTAINTY_FRACTION = 0.6
 DEFAULT_REACTIVITY_THRESH = 0.0
 DEFAULT_REACTIVITY_THRESH_TO_INITIAL = False
-
+DEFAULT_RENORMALIZE_POWER_DENSITY = True
 
 # Define the possible types of neutronics solvers
 NEUTRONICS_SOLVER_TYPES = ["mcnp", "test"]
@@ -59,11 +66,14 @@ MATL_MAX_ID = 99999999
 
 TIME_STRINGF = "%Y-%m-%d %H:%M:%S"
 
-DEFAULT_DENSITY = 1.0
-
 DEFAULT_VOL_TARGET_UNC = 1.E-3  # In units of percent
 DEFAULT_VOL_MAX_HIST = int(10E9)  # Set to 10 billion histories
 
+# Heuristic factor to use in automated chunksize calculation. The heuristic
+# factor (and overall chunksize calculation) are the same as used in Python's
+# multiprocessing.Pool.map() method.
+CHUNKSIZE_FACTOR = 4
+
 # Values here are from the Committee on Data for Science and Technology
 # (CODATA) 2014 recommendation (doi:10.1103/RevModPhys.88.035009).
 
@@ -73,6 +83,7 @@ K_BOLTZMANN = 8.6173303e-5
 # Unit conversions
 EV_PER_MEV = 1.0e6
 JOULE_PER_EV = 1.6021766208e-19
+SECONDS_PER_DAY = 86400
 
 # Avogadro's constant
 AVOGADRO = 6.022140857e23
@@ -83,6 +94,9 @@ NEUTRON_MASS = 1.00866491588
 # The relative precision of volumes to require when doing fuel mgmt
 VOLUME_PRECISION = 1.E-3
 
+# Relative power precision for total reactor power normalization
+POWER_PRECISION = 1.E-2
+
 # Maximum metastable level assumed to exist in a data library
 # This is required because removed versions of isotopes will have
 # this added to their metastable state
@@ -1412,3 +1426,7 @@ for iso, types in ORIGEN_ISO_DECAY_TYPES_FROM_SRC.items():
     for type_ in ORIGEN_ISO_DECAY_TYPES.keys():
         if type_ in types:
             ORIGEN_ISO_DECAY_TYPES[type_].add(iso)
+
+# the default user tallies managed in the simulation
+DEFAULT_TALLY_IDS = "all"
+DEFAULT_TALLY_TYPE = "universe"
diff --git a/adder/control_group.py b/adder/control_group.py
index be37175..65a8f26 100644
--- a/adder/control_group.py
+++ b/adder/control_group.py
@@ -107,11 +107,11 @@ class ControlGroup(LoggedClass):
         """
 
         self_grp = group.create_group(self.name, track_order=True)
-        self_grp.attrs["name"] = np.string_(self.name)
-        self_grp.attrs["type"] = np.string_(self.type)
-        self_grp.attrs["axis"] = np.string_(self.axis)
+        self_grp.attrs["name"] = np.bytes_(self.name)
+        self_grp.attrs["type"] = np.bytes_(self.type)
+        self_grp.attrs["axis"] = np.bytes_(self.axis)
         self_grp.attrs["set"] = self.set
-        self_grp.attrs["angle_units"] = np.string_(self.angle_units)
+        self_grp.attrs["angle_units"] = np.bytes_(self.angle_units)
         self_grp.attrs["displacement"] = self.displacement
 
     @classmethod
diff --git a/adder/cram/cram.py b/adder/cram/cram.py
index e28d343..f13af2f 100644
--- a/adder/cram/cram.py
+++ b/adder/cram/cram.py
@@ -94,14 +94,13 @@ class CRAMDepletion(Depletion):
                                         dtype=np.float64)
 
     def compute_library(self, depl_lib, flux):
-        """Computes and returns the total library,
-        decay + flux-induces reactions. For ORIGEN this is a lib string,
-        for CRAM this is the sparse matrix"""
+        """Computes and returns the total library, decay + flux-induces
+        reactions. This method requires that the decay
+        data already be computed via Depletion.compute_decay().
+        For ORIGEN this is a lib string, for CRAM this is the sparse matrix"""
 
-        if self.decay_data is None:
-            self.compute_decay(depl_lib)
         A_matrix = \
-                depl_lib.build_depletion_matrix(flux, "csr", self.decay_data)
+                depl_lib.build_depletion_matrix(flux, self.decay_data, "csr")
         return A_matrix
 
     def _eval_expm(self, A, n0, dt, dt_units="d"):
@@ -178,9 +177,8 @@ class CRAMDepletion(Depletion):
 
         Returns
         -------
-        new_isos : Iterable of 3-tuple (str, str, bool)
-            A list of the isotope name (str), the xs library (str), and whether
-            it is depleting (bool). There is one of these 3-tuples per isotope.
+        new_isos : np.ndarray
+            The IsotopeRegistry indices of each isotope
         new_fracs : np.ndarray
             A 1-D vector containing the depleted atom fractions for each of
             the isotopes in new_isos
diff --git a/adder/data.py b/adder/data.py
index 136be03..e62fc9f 100644
--- a/adder/data.py
+++ b/adder/data.py
@@ -285,7 +285,7 @@ def get_metadata(zaid, metastable_scheme='mcnp'):
     ----------
     zaid : int
         ZAID (1000*Z + A) obtained from a library
-    metastable_scheme : {'nndc', 'mcnp'}
+    metastable_scheme : {'mcnp'}
         Determine how ZAID identifiers are to be interpreted in the case of
         a metastable nuclide. Because the normal ZAID (=1000*Z + A) does not
         encode metastable information, different conventions are used among
@@ -293,6 +293,7 @@ def get_metadata(zaid, metastable_scheme='mcnp'):
         for a metastable nuclide except for Am242m, for which 95242 is
         metastable and 95642 (or 1095242 in newer libraries) is the ground
         state. For NNDC libraries, ZAID is given as 1000*Z + A + 100*m.
+        Currently, the processing of NNDC libraries is disabled.
     Returns
     -------
     name : str
@@ -309,7 +310,7 @@ def get_metadata(zaid, metastable_scheme='mcnp'):
     """
 
     check_type('zaid', zaid, int)
-    check_value('metastable_scheme', metastable_scheme, ['nndc', 'mcnp'])
+    check_value('metastable_scheme', metastable_scheme, ['mcnp'])
 
     Z = zaid // 1000
     mass_number = zaid % 1000
@@ -329,12 +330,16 @@ def get_metadata(zaid, metastable_scheme='mcnp'):
                 metastable = 0
             else:
                 metastable = 1 if mass_number > 300 else 0
-    elif metastable_scheme == 'nndc':
-        metastable = 1 if mass_number > 300 else 0
-
-    while mass_number > 3 * Z:
-        mass_number -= 100
-
+    # metastable state processing needs to be fixed if re-enabled.
+    # elif metastable_scheme == 'nndc':
+    #    metastable = 1 if mass_number > 300 else 0
+
+    if (metastable!=0 or zaid == 95642) and zaid != 95242 and mass_number > 300:
+        # 50998.99m, 50999.99m are older XS for fission-product pairs
+        if zaid == 50998 or zaid == 50999:
+            mass_number = 228
+        else:
+            mass_number = mass_number - 400
     # Determine name
     element = ATOMIC_SYMBOL[Z]
     name = gnd_name(Z, mass_number, metastable)
diff --git a/adder/depletion.py b/adder/depletion.py
index 2b0e112..05c21c6 100644
--- a/adder/depletion.py
+++ b/adder/depletion.py
@@ -114,7 +114,7 @@ class Depletion(object):
     @chunksize.setter
     def chunksize(self, chunksize):
         check_type("chunksize", chunksize, int)
-        check_greater_than("chunksize", chunksize, 0)
+        check_greater_than("chunksize", chunksize, -1)
         self._chunksize = chunksize
 
     def compute_decay(self, depl_lib):
@@ -124,8 +124,9 @@ class Depletion(object):
 
     def compute_library(self, depl_lib, flux):
         """Computes and returns the total library,
-        decay + flux-induces reactions. For ORIGEN this is a lib string,
-        for CRAM this is the sparse matrix"""
+        decay + flux-induces reactions. This method requires that the decay
+        data already be computed via Depletion.compute_decay().
+        For ORIGEN this is a lib string, for CRAM this is the sparse matrix"""
         pass
 
     def init_h5_file(self, h5_file):
@@ -135,9 +136,9 @@ class Depletion(object):
 
         # Store the runtime options as root attributes
         h5_file.attrs["num_depletion_threads"] = self.num_threads
-        h5_file.attrs["depletion_chunksize"] = self.num_threads
-        h5_file.attrs["depletion_solver"] = np.string_(self.solver)
-        h5_file.attrs["depletion_exec"] = np.string_(self.exec_cmd)
+        h5_file.attrs["depletion_chunksize"] = self.chunksize
+        h5_file.attrs["depletion_solver"] = np.bytes_(self.solver)
+        h5_file.attrs["depletion_exec"] = np.bytes_(self.exec_cmd)
 
     def execute(self, material, A_matrix, iso_indices, inv_iso_indices,
                 duration, depletion_step, num_substeps, is_serial=True):
@@ -167,9 +168,8 @@ class Depletion(object):
 
         Returns
         -------
-        new_isos : Iterable of 3-tuple (str, str, bool)
-            A list of the isotope name (str), the xs library (str), and whether
-            it is depleting (bool). There is one of these 3-tuples per isotope.
+        new_isos : np.ndarray
+            The IsotopeRegistry indices of each isotope
         new_fracs : np.ndarray
             A 1-D vector containing the depleted atom fractions for each of
             the isotopes in new_isos
diff --git a/adder/depletionlibrary.py b/adder/depletionlibrary.py
index e874fbf..1949a1b 100644
--- a/adder/depletionlibrary.py
+++ b/adder/depletionlibrary.py
@@ -1,4 +1,3 @@
-from collections import OrderedDict
 from copy import deepcopy
 import os
 import math
@@ -12,6 +11,9 @@ from adder.constants import MAX_METASTABLE_STATE, FILETYPE_DEPLETION_LIBRARY, \
     VERSION_DEPLETION_LIBRARY
 import adder.data
 
+
+NP_DTYPE_TARGET_YIELDS = np.dtype([('targets', 'U9'), ('yields', np.double)])
+
 # Constants specific to obtaining data from ORIGEN2.2
 # How many characters are in an ORIGEN library id
 CHARACTERS_FOR_LIB_ID = 4
@@ -34,9 +36,9 @@ _DECAY_UNITS = ['s', 'm', 'hr', 'd', 'yr', 'kyr', 'Myr', 'Gyr']
     # The following are based on ENDF/B-VII.1 decay data
 _DECAY_TYPES = \
     ["alpha", "n", "n,n", "p", "p,p", "beta-", "beta-,n",
-        "beta-,n,n", "beta-,n,n,n", "beta-,n,n,n,n", "beta-,alpha",
-        "beta-,beta-", "ec/beta+", "ec/beta+,alpha", "ec/beta+,p",
-        "ec/beta+,p,p", "ec/beta+,sf", "it", "sf", "removal"]
+     "beta-,n,n", "beta-,n,n,n", "beta-,n,n,n,n", "beta-,alpha",
+     "beta-,beta-", "ec/beta+", "ec/beta+,alpha", "ec/beta+,p",
+     "ec/beta+,p,p", "ec/beta+,sf", "it", "sf", "removal"]
 
 _DECAY_SECONDARY_PARTICLES = {
     "alpha": [(1., "He4")],
@@ -59,7 +61,7 @@ _RXN_TYPES = \
         '(n,n2p)', '(n,2a)', '(n,3a)', '(n,2p)', '(n,pa)', '(n,t2a)',
         '(n,d2a)', '(n,pd)', '(n,pt)', '(n,da)']
 
-_RXN_NEUTRON_MULTIPLICITES = \
+_RXN_NEUTRON_MULTIPLICITIES = \
     {'(n,gamma)': 0., '(n,2n)': 2., '(n,3n)': 3., '(n,4n)': 4.,
         'fission': 2.43, '(n,p)': 0., '(n,d)': 0., '(n,t)': 0., '(n,3He)': 0.,
         '(n,a)': 0., '(n,2nd)': 2., '(n,na)': 1., '(n,3na)': 3.,
@@ -78,9 +80,9 @@ _RXN_SECONDARY_PARTICLES = {
     '(n,2na)': [(1., 'He4')], '(n,np)': [(1., 'H1')],
     '(n,n2a)': [(2., 'He4')], '(n,2n2a)': [(2., 'He4')],
     '(n,nd)': [(1., 'H2')], '(n,nt)': [(1., 'H3')],
-    '(n,nHe-3)': [(1., 'He3')], '(n,nd2a)': [(1., 'H2'), (1., 'He4')],
+    '(n,nHe-3)': [(1., 'He3')], '(n,nd2a)': [(1., 'H2'), (2., 'He4')],
     '(n,nt2a)': [(1., 'H3'), (2., 'He4')], '(n,2np)': [(1., 'H1')],
-    '(n,3np)': [(1., 'H1')], '(n,n2p)': [(1., 'H1')],
+    '(n,3np)': [(1., 'H1')], '(n,n2p)': [(2., 'H1')],
     '(n,2a)': [(2., 'He4')], '(n,3a)': [(3., 'He4')],
     '(n,2p)': [(2., 'H1')], '(n,pa)': [(1., 'H1'), (1., 'He4')],
     '(n,t2a)': [(1., 'H3'), (2., 'He4')],
@@ -105,13 +107,12 @@ class IsotopeData(object):
 
     Parameters
     ----------
-    name : str
-        GND name of the isotope represented by this class
+    atomic_mass : float, optional
+        The atomic mass, in units of amu. Defaults to a value of 1, which is
+        to be used for pseudo-nuclides
 
     Attributes
     ----------
-    name : str
-        GND name of the isotope represented by this class
     atomic_mass : float
         The atomic mass, in units of amu. For pseudo-nuclides, this will
         have a value of 1
@@ -126,22 +127,11 @@ class IsotopeData(object):
         applicable to MSR's
     """
 
-    def __init__(self, name):
-        self.name = name
-        is_isotope = adder.data.is_isotope(self.name)
+    __slots__ = ['_atomic_mass', '_decay', '_removal', '_neutron_xs',
+                 '_neutron_fission_yield']
 
-        if is_isotope:
-            # Set the atomic mass
-            amu = adder.data.atomic_mass(self.name)
-            if amu is None:
-                # Then this isotope is not present in the source data
-                # for the atomic mass info (could be a pseudo-nuc)
-                # if so, use the value of A
-                _, a, _ = adder.data.zam(self.name)
-                amu = float(a)
-        else:
-            amu = 1.
-        self.atomic_mass = amu
+    def __init__(self, atomic_mass=1.):
+        self.atomic_mass = atomic_mass
 
         # Initialize the member data containers
         self.neutron_xs = None
@@ -150,7 +140,7 @@ class IsotopeData(object):
         self.removal = None
 
     def __repr__(self):
-        return "<IsotopeData: {}>".format(self.name)
+        return "<IsotopeData: {}>".format(self.atomic_mass)
 
     def __deepcopy__(self, memo):
         # This method is called when copy.deepcopy() is called as a result
@@ -158,23 +148,13 @@ class IsotopeData(object):
         # actually be a deepcopy of only the neutron_xs and removal data.
         # The rest will be a reference to the original (i.e., a shallow copy)
 
-        that = IsotopeData(self._name)
-        that._atomic_mass = self._atomic_mass
+        that = IsotopeData(self._atomic_mass)
         that._neutron_xs = deepcopy(self._neutron_xs)
         that._neutron_fission_yield = self._neutron_fission_yield
         that._decay = self._decay
         that._removal = deepcopy(self._removal)
         return that
 
-    @property
-    def name(self):
-        return self._name
-
-    @name.setter
-    def name(self, name):
-        check_type("name", name, str)
-        self._name = name
-
     @property
     def atomic_mass(self):
         return self._atomic_mass
@@ -229,12 +209,12 @@ class IsotopeData(object):
     def get_total_removal_xs(self, units):
         if self.neutron_xs is not None:
             xs = self.neutron_xs.total_xs
-            if self.neutron_xs.xs_units == units:
-                return xs
+            if xs is None:
+                return None
             if units == "b":
-                return np.copy(xs) * 1.E24
+                return xs
             elif units == "cm2":
-                return np.copy(xs) * 1.E-24
+                return xs * 1.E-24
         else:
             return None
 
@@ -289,7 +269,7 @@ class IsotopeData(object):
 
         Parameters
         ----------
-        isotopic_group : h5py.Group
+        iso_group : h5py.Group
             The hdf5 group with this data
         name : str
             The name of the isotope
@@ -299,16 +279,30 @@ class IsotopeData(object):
         # Get the isotopic data we need to initialize the IsotopeData
         # class
         if "decay" in iso_group:
-            decay = DecayData.from_hdf5(iso_group["decay"], name)
+            decay = DecayData.from_hdf5(iso_group["decay"])
         if "neutron_xs" in iso_group:
-            neutron_xs = ReactionData.from_hdf5(iso_group["neutron_xs"], name)
+            neutron_xs = ReactionData.from_hdf5(iso_group["neutron_xs"])
         if "neutron_fission_yield" in iso_group:
-            nfy = YieldData.from_hdf5(iso_group["neutron_fission_yield"], name)
+            nfy = YieldData.from_hdf5(iso_group["neutron_fission_yield"])
         if "removal" in iso_group:
-            removal = DecayData.from_hdf5(iso_group["removal"], name)
+            removal = DecayData.from_hdf5(iso_group["removal"])
 
         # Now we can create our object
-        this = cls(name)
+        is_isotope = adder.data.is_isotope(name)
+
+        if is_isotope:
+            # Set the atomic mass
+            atomic_mass = adder.data.atomic_mass(name)
+            if atomic_mass is None:
+                # Then this isotope is not present in the source data
+                # for the atomic mass info (could be a pseudo-nuc)
+                # if so, use the value of A
+                _, a, _ = adder.data.zam(name)
+                atomic_mass = float(a)
+        else:
+            atomic_mass = 1.
+
+        this = cls(atomic_mass)
 
         if "decay" in iso_group:
             this.decay = decay
@@ -331,13 +325,11 @@ class IsotopeData(object):
 
 
 class DecayData(object):
-    """Decay mode information for an isotope.
+    """This class contains decay mode information for an isotope including the
+     half-life, units of the half-life, and decay energy.
 
-    Decay products are accessed via dictionary-like interface where the
-    key is the decay type (e.g., "alpha" for an alpha decay) and the
-    corresponding value is a 3-tuple of the branching ratio, a list of
-    the decay products (including the secondary products, like He4 for
-    an alpha decay), and the yield of each of these products.
+    Decay product information (branching ratios, targets, yields) are accessed
+    via class interface functions.
 
     Parameters
     ----------
@@ -356,13 +348,17 @@ class DecayData(object):
         The units of the half-life
     decay_energy : float
         Average energy deposited from decay in units of MeV
-    """
+     """
+
+    __slots__ = ['_half_life', '_decay_energy', '_half_life_units',
+                 '_product_types', '_products']
 
     def __init__(self, half_life, half_life_units, decay_energy):
         self.half_life = half_life
         self.half_life_units = half_life_units
         self.decay_energy = decay_energy
-        self._products = {}
+        self._product_types = tuple()
+        self._products = tuple()
 
     @property
     def half_life(self):
@@ -388,7 +384,7 @@ class DecayData(object):
 
     @decay_energy.setter
     def decay_energy(self, decay_energy):
-        check_type("decay_energy", decay_energy, float)
+        check_type("decay_energy", decay_energy, (float, np.double))
         self._decay_energy = decay_energy
 
     @property
@@ -403,28 +399,36 @@ class DecayData(object):
 
     @property
     def num_types(self):
-        return len(self._products)
+        return len(self._product_types)
 
     def __contains__(self, type_):
-        return type_ in self._products
+        return type_ in self._product_types
 
-    def __iter__(self):
-        return iter(self._products.values())
+    def get_type_by_idx(self, idx):
+        return self._product_types[idx]
 
-    def __getitem__(self, type_):
-        if type_ in self._products:
-            return self._products[type_]
-        else:
+    def get_type_index(self, type_):
+        try:
+            idx = self._product_types.index(type_)
+        except ValueError:
             return None
+        return idx
 
-    def keys(self):
-        return iter(self._products.keys())
+    def get_product_data_by_idx(self, idx):
+        return self._products[idx]
 
-    def items(self):
-        return iter(self._products.items())
+    def get_product_data_by_type(self, type_):
+        try:
+            idx = self._product_types.index(type_)
+        except ValueError:
+            return None
+        return self._products[idx]
 
-    def values(self):
-        return iter(self._products.values())
+    def get_br_by_idx(self, idx):
+        return self._products[idx][0]
+
+    def get_targets_and_yields_by_idx(self, idx):
+        return self._products[idx][1]['targets'], self._products[idx][1]['yields']
 
     def add_type(self, type_, br, targets, yields_=None, add_secondaries=True):
         # Adds data for the type; this function adds the secondary
@@ -463,13 +467,32 @@ class DecayData(object):
         if add_secondaries:
             if type_ in _DECAY_SECONDARY_PARTICLES:
                 s_data = _DECAY_SECONDARY_PARTICLES[type_]
-
                 for s_yield, s_target in s_data:
                     yields__.append(s_yield)
                     targets_.append(s_target)
 
         # Build our product
-        self._products[type_] = (br, targets_, yields__)
+        self._product_types = self._product_types + (type_,)
+        # Since targets and yields are of same length, convert to a numpy
+        # structured array
+        targets_yields = np.array(
+            [(t, y) for t, y in zip(targets_, yields__)],
+            dtype=NP_DTYPE_TARGET_YIELDS)
+        self._products = self._products + ((br, targets_yields),)
+
+    def update_type(self, type_, br, targets_yields):
+            # Updated an entry for a reaction channel with already formulated data
+            # This method does not check correctness of values as these likely have
+            # been modified from already existing data
+        idx = self.get_type_index(type_)
+        if idx is None:
+            # Then this doesnt exist, so just add it
+            self._product_types = self._product_types + (type_,)
+            self._products = self._products + ((br, targets_yields),)
+        else:
+            product_data = self._products
+            self._products = product_data[:idx] + \
+                ((br, targets_yields),) + product_data[idx + 1:]
 
     def to_hdf5(self, group):
         """Writes the DecayData to an opened HDF5 group.
@@ -485,33 +508,32 @@ class DecayData(object):
             group.attrs["half_life"] = "None"
         else:
             group.attrs["half_life"] = self.half_life
-        group.attrs["half_life_units"] = np.string_(self.half_life_units)
+        group.attrs["half_life_units"] = np.bytes_(self.half_life_units)
         group.attrs["decay_energy"] = self.decay_energy
 
         # Now we have to write the products, they get their own group
-        for type_, values in self._products.items():
+        for idx, type_ in enumerate(self._product_types):
+            values = self.get_product_data_by_idx(idx)
             # ec/beta+ (and in future? others) have a slash, which
             # can confuse hdf5 as it may look like a group path
             # so lets intercept and convert to a double underscore
             # which we will fix on re-read
             t_group = group.create_group(type_.replace("/", "__"))
-            br, targets, yields_ = values
+            br, targets_yields = values
             t_group.attrs["branching_ratio"] = br
-            t_group.create_dataset("targets",
-                                   data=np.array([np.string_(t)
-                                                  for t in targets]))
-            t_group.create_dataset("yields", data=np.array(yields_))
+            targets = np.array(targets_yields['targets'], dtype=np.bytes_)
+            yields_ = targets_yields['yields']
+            t_group.create_dataset("targets", data=targets)
+            t_group.create_dataset("yields", data=yields_)
 
     @classmethod
-    def from_hdf5(cls, group, name):
+    def from_hdf5(cls, group):
         """Initializes a DecayData object from an opened HDF5 group
 
         Parameters
         ----------
         group : h5py.Group
             HDF5 group to read from
-        name : str
-            Isotope name
 
         Returns
         -------
@@ -544,96 +566,92 @@ class DecayData(object):
 
 
 class ReactionData(object):
-    """Flux-induced reaction information for an isotope.
+    """This class contains flux-induced reaction information for an isotope.
 
-    Reaction products are accessed via dictionary-like interface where
-    the key is the reaction type (e.g., "(n,alpha)") and the
-    corresponding value is a 4-tuple of an np.ndarray of the
-    group-wise cross sections, a list of the target isotopes (including
-    secondary products like He4 for an (n,alpha) reaction type), the
-    yield of each of these targets, and the Q-value of the reaction
-    in units of MeV.
+    Reaction product information (Q-value of the reaction [MeV], group-wise
+    cross sections [b], targets, and yields) are accessed via are accessed via
+    class interface functions.
+    """
+    __slots__ = ['_product_types', '_products', '_product_qs']
 
-    Parameters
-    ----------
-    xs_units : {"b", "cm2"}
-        The units of the cross section
-    num_groups : int
-        The number of energy groups the data is present in
+    def __deepcopy__(self, memo):
+        # Since we defined getstate, we need to make our own custom deepcopy
+        # for when we clone a depletion library
+        that = ReactionData()
+        # Our product_types and qs will not change with clones (as all that
+        # changes are the xs values), so lets assign references for everything
+        # but the products data
+        that._product_types = self._product_types
+        that._product_qs = self._product_qs
+        that._products = deepcopy(self._products)
+        return that
 
-    Attributes
-    ----------
-    xs_units : {"b", "cm2"}
-        The units of the cross section
-    num_groups : int
-        The number of energy groups the data is present in
-    products : dict of (branching_ratio, List of GND targets, List of yields)
-        Keyed by the type of interaction
-    """
+    def __init__(self):
+        self._product_types = tuple()
+        self._products = tuple()
+        self._product_qs = tuple()
 
-    def __init__(self, xs_units, num_groups):
-        self.xs_units = xs_units
-        self.num_groups = num_groups
-        self._products = {}
+    def get_type_by_idx(self, idx):
+        return self._product_types[idx]
 
-    @property
-    def xs_units(self):
-        return self._xs_units
+    def get_type_index(self, type_):
+        try:
+            idx = self._product_types.index(type_)
+        except ValueError:
+            return None
+        return idx
 
-    @xs_units.setter
-    def xs_units(self, xs_units):
-        check_value("xs_units", xs_units, _RXN_UNITS)
-        self._xs_units = xs_units
+    def get_product_data_by_idx(self, idx):
+        return *self._products[idx], self._product_qs[idx]
 
-    @property
-    def num_groups(self):
-        return self._num_groups
+    def get_product_data_by_type(self, type_):
+        try:
+            idx = self._product_types.index(type_)
+        except ValueError:
+            return None
+        return *self._products[idx], self._product_qs[idx]
+
+    def get_xs_by_idx(self, idx):
+        return self._products[idx][0]
 
-    @num_groups.setter
-    def num_groups(self, num_groups):
-        check_type("num_groups", num_groups, int)
-        check_greater_than("num_groups", num_groups, 0)
-        self._num_groups = num_groups
+    def get_targets_and_yields_by_idx(self, idx):
+        return self._products[idx][1]['targets'], self._products[idx][1]['yields']
+
+    def get_Q_by_idx(self, idx):
+        return self._product_qs[idx]
+
+    def __contains__(self, type_):
+        return type_ in self._product_types
 
     @property
     def num_types(self):
-        return len(self._products)
+        return len(self._product_types)
 
     @property
     def total_xs(self):
-        tot_rem_xs = np.zeros(self._num_groups)
+        # We dont know the number of groups until we have a xs structure, so
+        # lets hold off on initializing tot_rem_xs until we get our 1st xs
+        tot_rem_xs = None
         for type_ in _RXN_TOTAL_TYPES:
-            if type_ in self._products:
-                xs, _, _, _ = self._products[type_]
-                tot_rem_xs += xs
+            idx = self.get_type_index(type_)
+            if idx is not None:
+                xs = self.get_xs_by_idx(idx)
+                if tot_rem_xs is None:
+                    # Now we have our xs structure so lets initialize and set
+                    tot_rem_xs = np.copy(xs)
+                else:
+                    tot_rem_xs += xs
+        # Note that if we have none of _RXN_TOTAL_TYPES in our data channels,
+        # then tot_rem_xs will be None. Would be nice to allocate as 0, but
+        # then we need to store the number of groups on this class, wasting
+        # precious memory. Instead, return the None and let upstream handle it
         return tot_rem_xs
 
-    def __contains__(self, type_):
-        return type_ in self._products
-
-    def __iter__(self):
-        return iter(self._products.values())
-
-    def __getitem__(self, type_):
-        if type_ in self._products:
-            return self._products[type_]
-        else:
-            return None
-
-    def keys(self):
-        return iter(self._products.keys())
-
-    def items(self):
-        return iter(self._products.items())
-
-    def values(self):
-        return iter(self._products.values())
-
     def add_type(self, type_, xs_units, xs, targets=None, yields_=None,
                  add_secondaries=True, q_value=0.):
         # Adds data for the type; this function adds the secondary
         # particles for the user
-        if type_ in self._products:
+        if type_ in self:
             msg = "XS type {} already exists in the data!".format(type_)
             raise ValueError(msg)
 
@@ -645,7 +663,6 @@ class ReactionData(object):
         check_iterable_type("xs", xs, (float, np.float64))
         for xs_val in xs:
             check_greater_than("xs value", xs_val, 0., equality=True)
-        check_length("xs", xs, self._num_groups)
         if type_ == "fission" and targets is None:
             targets_ = ["fission"]
         elif isinstance(targets, str):
@@ -678,47 +695,90 @@ class ReactionData(object):
                     yields__.append(s_yield)
                     targets_.append(s_target)
 
-        # Convert xs units
-        if self._xs_units != xs_units:
-            if xs_units == "b":
-                # Then self.xs_units is cm2 and we need to be consistent
-                # with that
-                xs = np.copy(np.asarray(xs)) * 1.E-24
-            elif xs_units == "cm2":
-                # Then self.xs_units is b and we need to be consistent
-                # with that
-                xs = np.copy(np.asarray(xs)) * 1.E24
-        else:
+        # Convert xs units if needed
+        if xs_units == "b":
             xs = np.array(xs)
+        elif xs_units == "cm2":
+            xs = np.array(xs) * 1.E24
 
         # Build our product
-        self._products[type_] = (xs, targets_, yields__, q_value)
+        endf_type, _ = endf_rx_type(type_, targets_, yields__) 
+        self._product_types = self._product_types + (endf_type,)
+        # Since targets and yields are of same length, convert to a numpy
+        # structured array
+        targets_yields = np.array(
+            [(t, y) for t, y in zip(targets_, yields__)],
+            dtype=NP_DTYPE_TARGET_YIELDS)
+        self._products = self._products + ((xs, targets_yields),)
+        self._product_qs = self._product_qs + (q_value,)
+
+    def update_type(self, type_, xs, targets_yields, q_value):
+        # Updated an entry for a reaction channel with already formulated data
+        # This method does not check correctness of values as these likely have
+        # been modified from already existing data
+        idx = self._product_types.index(type_)
+        if idx is None:
+            # Then this doesnt exist, so just add it
+            self._product_types = self._product_types + (type_,)
+            self._products = self._products + ((xs, targets_yields),)
+            self._product_qs = self._product_qs + (q_value,)
+        else:
+            product_data = self._products
+            self._products = product_data[:idx] + \
+                ((xs, targets_yields),) + product_data[idx + 1:]
+            product_qs = self._product_qs
+            self._product_qs = product_qs[:idx] + \
+                (q_value,) + product_qs[idx + 1:]
 
     def get_xs(self, type_, output_units, meta_state=0):
         # Finds the cross section to a desired metastable state in the
         # requested units
-        if self._xs_units == output_units:
-            conv_const = 1.
-        elif output_units == "b":
-            conv_const = 1.E24
+        if output_units == "b":
+            conv_const = 1.0
         elif output_units == "cm2":
             conv_const = 1.E-24
 
-        if type_ in self._products:
-            xs, targets, yields_, _ = self._products[type_]
-            for t, target in enumerate(targets):
+        idx = self.get_type_index(type_)
+        if idx is not None:
+            xs, target_yields = self._products[idx]
+            for ty in target_yields:
+                target = ty['targets']
+                yield_ = ty['yields']
                 if target != "fission":
                     _, _, m = adder.data.zam(target)
                     if m == meta_state:
-                        return xs * yields_[t] * conv_const
+                        return xs * yield_ * conv_const
                 else:
-                    return xs * yields_[t] * conv_const
+                    return xs * yield_ * conv_const
             # If we get here, we didnt find it
             return None
-
         else:
             return None
 
+    def equivalent_rx_type(self, main_rx_type):
+        """Provides reaction type that is equivalent to main_rx_type.
+
+        This method uses the endf_rx_type method to get alternative reaction
+        rate identifiers, that are equivalent to main_rx_type, e.g., (n,a) for
+        Li-6(n,t)
+
+        Parameters
+        ----------
+        main_rx_type : string
+            Reaction type, e.g., (n,a)
+        """
+        alt_types = []
+        for type_ in self._product_types:
+            if not main_rx_type == type_:
+                product_data = self.get_product_data_by_type(type_)
+                targets = [data[0] for data in product_data[1]]
+                yields_ = [data[1] for data in product_data[1]]
+                _, alt_rxs = endf_rx_type(type_, targets, yields_) 
+                if main_rx_type in alt_rxs:
+                    alt_types.append(type_)
+
+        return alt_types
+
     def to_hdf5(self, group):
         """Writes the ReactionData to an opened HDF5 group.
 
@@ -729,30 +789,27 @@ class ReactionData(object):
 
         """
 
-        group.attrs["xs_units"] = np.string_(self._xs_units)
-        group.attrs["num_groups"] = self._num_groups
+        group.attrs["xs_units"] = np.bytes_('b')
 
         # Now we have to write the products, they get their own group
-        for type_, values in self._products.items():
+        for idx, type_ in enumerate(self._product_types):
+            xs, targets_yields, q_value = self.get_product_data_by_idx(idx)
             t_group = group.create_group(type_)
-            xs, targets, yields_, q_value = values
             t_group.create_dataset("xs", data=xs)
-            t_group.create_dataset("targets",
-                                   data=np.array([np.string_(t)
-                                                  for t in targets]))
-            t_group.create_dataset("yields", data=np.array(yields_))
+            targets = np.array(targets_yields['targets'], dtype=np.bytes_)
+            yields_ = targets_yields['yields']
+            t_group.create_dataset("targets", data=targets)
+            t_group.create_dataset("yields", data=yields_)
             t_group.attrs["q_value"] = q_value
 
     @classmethod
-    def from_hdf5(cls, group, name):
+    def from_hdf5(cls, group):
         """Initializes a ReactionData object from an opened HDF5 group
 
         Parameters
         ----------
         group : h5py.Group
             HDF5 group to read from
-        name : str
-            Isotope name
 
         Returns
         -------
@@ -760,10 +817,9 @@ class ReactionData(object):
             A ReactionData object initialized from HDF5
         """
         xs_units = group.attrs["xs_units"].decode()
-        num_groups = int(group.attrs["num_groups"])
 
         # Initialize the object
-        this = cls(xs_units, num_groups)
+        this = cls()
 
         # Now get the products' data
         for type_ in group.keys():
@@ -784,35 +840,45 @@ class YieldData(object):
     transition to another isotope via complex outgoing distributions
     such as fission.
 
+    This class behaves like a dictionary where the keys are isotopes and the
+    fission product yields are the values.
+
     """
+    __slots__ = ['_isos', '_yields']
 
     def __init__(self):
-        self._products = {}
+        self._isos = tuple()
+        # We use a np array here because it is more compact than an array.array
+        # somehow for longer arrays (each indiv item is smaller but it has
+        # more overhead than array.array) Since this is a large array, np.array
+        # ends up being more compact
+        self._yields = np.array([], dtype=np.double)
 
     @property
     def num_isotopes(self):
-        return len(self._products)
+        return len(self._isos)
 
     def __contains__(self, iso):
-        return iso in self._products
+        return iso in self._isos
 
     def __getitem__(self, iso):
-        if iso in self._products:
-            return self._products[iso]
-        else:
+        try:
+            idx = self._isos.index(iso)
+            return self._yields[idx]
+        except ValueError:
             return None
 
     def __iter__(self):
-        return iter(self._products.values())
+        return iter(self._yields)
 
     def keys(self):
-        return iter(self._products.keys())
+        return iter(self._isos)
 
     def items(self):
-        return iter(self._products.items())
+        return zip(self._isos, self._yields)
 
     def values(self):
-        return iter(self._products.values())
+        return iter(self._yields)
 
     def add_isotope(self, iso, yield_):
         """Adds an isotope to the YieldData object
@@ -820,7 +886,9 @@ class YieldData(object):
 
         check_type("iso", iso, str)
         check_type("yield_", yield_, (float, np.float64))
-        self._products[iso] = yield_
+
+        self._isos = self._isos + (iso,)
+        self._yields = np.append(self._yields, yield_)
 
     def to_hdf5(self, group):
         """Writes the TransitionData to an opened HDF5 group.
@@ -831,31 +899,23 @@ class YieldData(object):
             HDF5 group to write to
 
         """
-
-        isos = np.array([np.string_(k) for k in self._products.keys()])
-        yields_ = np.array([v for v in self._products.values()])
-
-        # And now we can write them
-        group.create_dataset("isotopes", data=isos)
-        group.create_dataset("yields", data=yields_)
+        group.create_dataset("isotopes",
+            data=np.array([np.bytes_(iso) for iso in self._isos]))
+        group.create_dataset("yields", data=self._yields)
 
     @classmethod
-    def from_hdf5(cls, group, name, num_groups=None):
-        """Initializes a TransitionData object from an opened HDF5 group
+    def from_hdf5(cls, group):
+        """Initializes a YieldData object from an opened HDF5 group
 
         Parameters
         ----------
         group : h5py.Group
             HDF5 group to read from
-        name : str
-            Isotope name
-        num_groups : int, optional
-            The number fo groups in the library; defaults to None.
 
         Returns
         -------
-        this : TransitionData
-            A TransitionData subclass object initialized from HDF5
+        this : YieldData
+            A YieldData object initialized from HDF5
         """
 
         this = cls()
@@ -868,8 +928,8 @@ class YieldData(object):
         if len(isotopes) != len(yields_):
             raise ValueError("'isotopes' and 'yields' must have same size!")
 
-        for i in range(len(isotopes)):
-            this._products[isotopes[i]] = yields_[i]
+        this._isos = tuple(isotopes)
+        this._yields = np.array(yields_, dtype=np.double)
         return this
 
 
@@ -914,16 +974,22 @@ class DepletionLibrary(object):
     num_neutron_groups : int
         The number of groups used for incident neutron data
     """
+    __slots__ = ['_name', '_neutron_group_structure', '_num_neutron_groups',
+                 'isotopes', '_isotopes_ordered', 'isotope_indices',
+                 'inverse_isotope_indices', 'initial_isotopes',
+                 'atomic_mass_vector']
 
     def __init__(self, name, neutron_group_structure):
         self.name = name
         self.neutron_group_structure = neutron_group_structure
+        self.num_neutron_groups = len(self._neutron_group_structure) - 1
         # Initialize data structs relied on when data is populated
-        self.isotopes = OrderedDict()
+        self.isotopes = {}
         self._isotopes_ordered = False
-        self.isotope_indices = OrderedDict()
-        self.inverse_isotope_indices = OrderedDict()
+        self.isotope_indices = {}
+        self.inverse_isotope_indices = {}
         self.initial_isotopes = set()
+        self.atomic_mass_vector = None
 
     @property
     def name(self):
@@ -946,7 +1012,12 @@ class DepletionLibrary(object):
 
     @property
     def num_neutron_groups(self):
-        return len(self._neutron_group_structure) - 1
+        return self._num_neutron_groups
+
+    @num_neutron_groups.setter
+    def num_neutron_groups(self, num_groups):
+        check_type("num_neutron_groups", num_groups, int)
+        self._num_neutron_groups = num_groups
 
     @property
     def num_isotopes(self):
@@ -955,6 +1026,17 @@ class DepletionLibrary(object):
     def __repr__(self):
         return "<DepletionLibrary: {}>".format(self.name)
 
+    def __deepcopy__(self, memo):
+        new_instance = type(self)(self._name, self._neutron_group_structure)
+        state = {attr: getattr(self, attr) for attr in self.__slots__
+                 if attr != 'isotopes'}
+        for attr, value in state.items():
+            setattr(new_instance, attr, deepcopy(value))
+        # isotopes knows how to make copies of itself to save space, so lets
+        # let its __deepcopy__ method handle that.
+        new_instance.isotopes = deepcopy(self.isotopes)
+        return new_instance
+
     def clone(self, new_name=None):
         """Create a clone of this library, assigning a new name if
         requested"""
@@ -1006,8 +1088,9 @@ class DepletionLibrary(object):
                 if c_name != "fission" and c_name not in self.isotope_indices:
                     if c_val > 0.:
                         # Find the first relevant decay and add to msg
-                        for type_ in decay.keys():
-                            _, targets, _ = decay[type_]
+                        for idx, type_ in enumerate(decay._product_types):
+                            targets, _ = \
+                                decay.get_targets_and_yields_by_idx(idx)
                             if c_name in targets:
                                 msgs.append(msg_template.format(c_name, name,
                                                                 c_name, type_))
@@ -1028,8 +1111,9 @@ class DepletionLibrary(object):
                 if c_name != "fission" and c_name not in self.isotope_indices:
                     if c_val > 0.:
                         # Find the first relevant decay and add to msg
-                        for type_ in n_xs.keys():
-                            _, targets, _, _ = n_xs[type_]
+                        for idx, type_ in enumerate(n_xs._product_types):
+                            targets, _ = \
+                                n_xs.get_targets_and_yields_by_idx(idx)
                             if c_name in targets:
                                 msgs.append(msg_template.format(c_name, name,
                                                                 c_name, type_))
@@ -1039,7 +1123,7 @@ class DepletionLibrary(object):
 
         # Now add the isotopes to the library
         stable = DecayData(None, "s", 0.)
-        noxs = ReactionData("b", self.num_neutron_groups)
+        noxs = ReactionData()
         for iso in isos_to_add:
             self.add_isotope(iso, xs=noxs, decay=stable)
         if len(isos_to_add) > 0:
@@ -1088,21 +1172,23 @@ class DepletionLibrary(object):
         for src, lambda_ in zip([decay, rem], [decay_lambda_, rem_lambda_]):
             if src is None:
                 continue
-            for child, (br, targets, yields_) in src.items():
+            for idx, child in enumerate(src._product_types):
+                br, targets_yields = src.get_product_data_by_idx(idx)
                 if br <= 0.:
                     continue
                 # Get the value to be multiplied by the yields
                 # (lambda * branch ratio)
                 rxn_val = lambda_ * br
 
-                for t, target in enumerate(targets):
+                for ty in targets_yields:
+                    target = ty['targets']
+                    yield_ = ty['yields']
                     # Handle the fission reaction
-                    rxn_yield = rxn_val * yields_[t]
+                    rxn_yield = rxn_val * yield_
                     if child in fission_keys:
                         for fission_child, fission_yield in nfy.items():
                             child_names.append(fission_child)
                             child_values.append(rxn_yield * fission_yield)
-
                     else:
                         # The direct product is simpler
                         child_names.append(target)
@@ -1144,23 +1230,22 @@ class DepletionLibrary(object):
         fission_keys = ["fission"]
 
         # unit conversion constant
-        if src.xs_units == output_unit:
+        if output_unit == "cm2":
+            conversion = 1.E-24
+        elif output_unit == "b":
             conversion = 1.0
-        else:
-            if output_unit == "cm2":
-                conversion = 1.E-24
-            elif output_unit == "b":
-                conversion = 1.E24
 
         # Gather the target information
-        for _, (xs, targets, yields_, _) in src.items():
+        for idx in range(len(src._product_types)):
+            xs = src.get_xs_by_idx(idx)
+            targets, yields = src.get_targets_and_yields_by_idx(idx)
             # Check to see if the xs is 0 over all groups
             if not np.any(xs):
                 continue
             rxn_val = np.dot(xs, flux) * conversion
-            for t, target in enumerate(targets):
+            for target, yield_ in zip(targets, yields):
                 # Handle the fission reaction
-                rxn_yield = rxn_val * yields_[t]
+                rxn_yield = rxn_val * yield_
                 if target in fission_keys:
                     for fission_child, fission_yield in nfy.items():
                         child_names.append(fission_child)
@@ -1177,7 +1262,7 @@ class DepletionLibrary(object):
         # we want the highest nucid to be first
         # GND_to_origen_nucid
         # Reset the isotope indices map
-        self.isotope_indices = OrderedDict()
+        self.isotope_indices = {}
 
         # We need an array of iso names and an array of nucids
         # We then sort by nucids and rearrange iso names accordingly
@@ -1205,7 +1290,7 @@ class DepletionLibrary(object):
         sorted_indices = nucids.argsort()
 
         # Now store our map and its inverse
-        self.inverse_isotope_indices = OrderedDict()
+        self.inverse_isotope_indices = {}
         for i, key in enumerate(iso_names[sorted_indices]):
             self.isotope_indices[key] = i
             self.inverse_isotope_indices[i] = key
@@ -1247,7 +1332,7 @@ class DepletionLibrary(object):
             # Get the total removal and place in the diagonal
             lambda_removal = \
                 self.isotopes[name].get_total_decay_const(time_units,
-                                                            "all")
+                                                          "all")
 
             if lambda_removal is None:
                 continue
@@ -1268,18 +1353,17 @@ class DepletionLibrary(object):
 
         return D
 
-    def build_depletion_matrix(self, flux, matrix_format="csr",
-        dk_matrix=None):
+    def build_depletion_matrix(self, flux, dk_matrix, matrix_format="csr"):
         """Build the A matrix used for depletion from the library info
 
         Parameters
         ----------
         flux : np.ndarray
             The group-wise flux to use.
+        dk_matrix : scipy.sparse array
+            The pre-computed decay matrix
         matrix_format : {"csr", "csc", "dense"}, optional
             The matrix format to keep the matrix in; defaults to "csr"
-        dk_matrix : None or np.ndarray
-            The pre-computed decay matrix, if available
 
         Returns
         -------
@@ -1291,27 +1375,25 @@ class DepletionLibrary(object):
         check_length("flux", flux, length_min=self.num_neutron_groups)
         check_value("matrix_format", matrix_format, ("csr", "csc", "dense"))
 
-        # Make sure the decay matrix is calculated
-        if dk_matrix is None:
-            decay_matrix = self.build_decay_matrix()
-        else:
-            if sp.issparse(dk_matrix):
-                decay_matrix = dk_matrix.todense()
-            else:
-                decay_matrix = dk_matrix
-
         # Now we can move on to building A; start by using decay matrix
-        A = np.copy(decay_matrix)
+        coo_decay = dk_matrix.tocoo(copy=True)
+        # Create the data that we eventually want to put into this matrix
+        rows = coo_decay.row.tolist()
+        cols = coo_decay.col.tolist()
+        values = coo_decay.data.tolist()
         # Now we go in and add the components
         for name, i in self.isotope_indices.items():
             iso = self.isotopes[name]
             # First the diagonal (transmute from i to any other)
             xs = iso.get_total_removal_xs("cm2")
             if xs is None:
+                # Then there is no channel (0 value xs)
                 continue
             else:
                 val = np.dot(xs, flux)
-            A[i, i] -= val
+            values.append(-val)
+            rows.append(i)
+            cols.append(i)
 
             # Now get the children of this isotope and place in the
             # appropriate locations
@@ -1321,9 +1403,16 @@ class DepletionLibrary(object):
             # Now progress through each of these children, find
             # their index, and accrue the transmutation value
             for c_name, c_val in zip(child_names, child_values):
-                if c_name in self.isotope_indices:
+                try:
                     j = self.isotope_indices[c_name]
-                    A[j, i] += c_val
+                except KeyError:
+                    pass
+                values.append(c_val)
+                rows.append(j)
+                cols.append(i)
+
+        A = sp.coo_matrix((values, (rows, cols)), shape=dk_matrix.shape)
+        A.sum_duplicates()
 
         if matrix_format == "csr":
             A_in_format = sp.csr_matrix(A, dtype=np.float64)
@@ -1365,14 +1454,20 @@ class DepletionLibrary(object):
                 msg = "{} already in exists in Isotopes!".format(iso_name)
                 raise ValueError(msg)
 
-            # Work the specific datatypes
-            if xs:
-                # Check that the groups are consistent with expectations
-                if xs.num_groups != self.num_neutron_groups:
-                    msg = "xs groups and DepletionLibrary groups do not match!"
-                    raise ValueError(msg)
-
-            isotope = IsotopeData(iso_name)
+            is_isotope = adder.data.is_isotope(iso_name)
+
+            if is_isotope:
+                # Set the atomic mass
+                atomic_mass = adder.data.atomic_mass(iso_name)
+                if atomic_mass is None:
+                    # Then this isotope is not present in the source data
+                    # for the atomic mass info (could be a pseudo-nuc)
+                    # if so, use the value of A
+                    _, a, _ = adder.data.zam(iso_name)
+                    atomic_mass = float(a)
+            else:
+                atomic_mass = 1.
+            isotope = IsotopeData(atomic_mass)
             if xs:
                 isotope.neutron_xs = xs
             if nfy:
@@ -1410,18 +1505,21 @@ class DepletionLibrary(object):
         if rxn_type == "absorb":
             # First we add up the straightforward absorption channels
             for type_ in _RXN_ABSORB_TYPES:
-                if type_ in iso_xs.keys():
-                    xs, _, _, _ = iso_xs[type_]
+                idx = iso_xs.get_type_index(type_)
+                if idx is not None:
+                    xs = iso_xs.get_xs_by_idx(idx)
                     micro_xs += xs
 
             # And now we take away the multiplicity part
             # e.g., if (n,Xn) we subtract (X - 1) * sig_(n,2n)
             # where it is (X - 1) to account for the replacement of the
             # incident neutron with one of the outgoing neutrons
-            for type_, X in _RXN_NEUTRON_MULTIPLICITES.items():
-                if type_ in iso_xs.keys() and type_ != "fission" and X > 0.:
-                    xs, _, _, _ = iso_xs[type_]
-                    micro_xs -= (X - 1.) * xs
+            for type_, X in _RXN_NEUTRON_MULTIPLICITIES.items():
+                if type_ != 'fission' and X > 0.:
+                    idx = iso_xs.get_type_index(type_)
+                    if idx is not None:
+                        xs = iso_xs.get_xs_by_idx(idx)
+                        micro_xs -= (X - 1.) * xs
         elif rxn_type == "nu-fission":
             # nu-fission is only used for determining important isotopes
             # the fission multiplicities includes a value of 2.43.
@@ -1430,9 +1528,10 @@ class DepletionLibrary(object):
             # and so it would need to be provided from elsewhere; until
             # I have that capability incorporated this constant is used
             for type_ in _RXN_FISSION_TYPES:
-                if type_ in iso_xs.keys():
-                    xs, _, _, _ = iso_xs[type_]
-                    micro_xs += _RXN_NEUTRON_MULTIPLICITES[type_] * xs
+                idx = iso_xs.get_type_index(type_)
+                if idx is not None:
+                    xs = iso_xs.get_xs_by_idx(idx)
+                    micro_xs += _RXN_NEUTRON_MULTIPLICITIES[type_] * xs
         else:
             if rxn_type == "total":
                 types = _RXN_TOTAL_TYPES
@@ -1441,8 +1540,9 @@ class DepletionLibrary(object):
             else:
                 types = [rxn_type]
             for type_ in types:
-                if type_ in iso_xs.keys():
-                    xs, _, _, _ = iso_xs[type_]
+                idx = iso_xs.get_type_index(type_)
+                if idx is not None:
+                    xs = iso_xs.get_xs_by_idx(idx)
                     micro_xs += xs
 
         return micro_xs
@@ -1489,7 +1589,7 @@ class DepletionLibrary(object):
 
         check_iterable_type("flux", flux, float)
         check_length("flux", flux, self.num_neutron_groups)
-        arr_flux = np.asfarray(flux)
+        arr_flux = np.asarray(flux, dtype=float)
 
         if iso_name in self.isotopes:
             mg_xs = self.get_micro_neutron_xs(iso_name, rxn_type)
@@ -1535,7 +1635,7 @@ class DepletionLibrary(object):
 
         check_iterable_type("flux", flux, float)
         check_length("flux", flux, self.num_neutron_groups)
-        arr_flux = np.asfarray(flux)
+        arr_flux = np.asarray(flux, dtype=float)
 
         mg_xs = self.get_macro_neutron_xs(iso_names, iso_concentrations,
                                           rxn_type)
@@ -1630,7 +1730,6 @@ class DepletionLibrary(object):
                 check_iterable_type("flux", flux, float)
                 check_length("flux", flux, self.num_neutron_groups)
                 raise NotImplementedError("This has not yet been implemented")
-                # arr_flux = np.asfarray(flux)
         else:
             iso_Q = 0.
 
@@ -1669,7 +1768,7 @@ class DepletionLibrary(object):
                                    VERSION_DEPLETION_LIBRARY)
         else:
             # Then we have to write the file status.
-            root.attrs['filetype'] = np.string_(FILETYPE_DEPLETION_LIBRARY)
+            root.attrs['filetype'] = np.bytes_(FILETYPE_DEPLETION_LIBRARY)
             root.attrs['version'] = [VERSION_DEPLETION_LIBRARY, 0]
 
         # Create the group for this object
@@ -1801,9 +1900,9 @@ class DepletionLibrary(object):
         # Open and operate on the file data
         # Do the cross section data first
         lib_name = None
-        xs_data = OrderedDict()
-        decay_data = OrderedDict()
-        yield_data = OrderedDict()
+        xs_data = {}
+        decay_data = {}
+        yield_data = {}
         for library_type in ["xs", "decay"]:
             if library_type == "xs":
                 filename = xs_filename
@@ -1977,7 +2076,7 @@ class DepletionLibrary(object):
 
         # Convert the data for each isotope into our TransitionData format
         # Start with the decay data
-        iso_decay = OrderedDict()
+        iso_decay = {}
         iso_decay_types = {}
         has_fission = set()
         for iso_name in decay_data:
@@ -2069,11 +2168,11 @@ class DepletionLibrary(object):
                 iso_decay_types[iso_name] = data['isotope_types']
 
         # Repeat for xs
-        iso_xs = OrderedDict()
+        iso_xs = {}
         iso_xs_types = {}
         for iso_name in xs_data:
             # Create the object
-            that = ReactionData(xs_units, num_groups=1)
+            that = ReactionData()
 
             # Get the library data
             data = xs_data[iso_name]
@@ -2223,3 +2322,76 @@ def GND_to_origen_nucid(iso_name):
         # Shift these high to be above the real nuclides
         origen_nucid = 10000 * Z + 10 * A + M + 10000000
     return origen_nucid
+
+def endf_rx_type(rx_type, targets, yields):
+    """This method returns a reaction type e.g., (n,t), consistent with the
+    ENDF notation, in which the lightest product is included in parentheses.
+
+    Parameters
+    ----------
+    rx_type : str
+        The reaction type for which the equivalent ENDF type is looked
+    targets : iterable of str 
+        Isotopes that are produced by the reaction (e.g., 'Li6') 
+    yields  : iterable of float
+        Number of targets that are produced per reaction 
+
+    Returns
+    ----------
+    endf_type : str 
+        Equivalent reaction type consistent with the ENDF notation. If the 
+        rx_type is already consistent with the ENDF notation, endf_type is 
+        identical.
+    alternatives : list of str
+        Provides all of the reaction types that are equivalent and alternative
+        to the rx_type provided as an argument, including reactions that have
+        no targets other than the reaction's secondary particles as per dict
+        _RXN_SECONDARY_PARTICLES.
+    """
+
+    # Converts the reaction type to be consistent with ENDF libraries
+    # e.g., Li6(n,a)H3 is actually Li6(n,t)He4; with the lighter product in 
+    # parentheses
+    alternatives = []
+    endf_type = rx_type 
+
+    if targets and yields and endf_type in _RXN_SECONDARY_PARTICLES:
+        
+        # Determine a list of expected secondary particles for rx_type
+        rx_products = []
+        for target, yieldx in zip(targets, yields):
+            # Add target and yields from the HDF5 library
+            rx_products.append((yieldx, target))
+            
+        # Cycle through alternative reaction types from dictionary 
+        for alt_type in _RXN_SECONDARY_PARTICLES:
+            alt_products = _RXN_SECONDARY_PARTICLES[alt_type]
+
+            # Check whether the products from the library for the alternative 
+            # type are all also be in the ORIGEN products list. Also, neutron 
+            # multiplicities are checked
+            if (set(alt_products).issubset(set(rx_products)) and (
+                    _RXN_NEUTRON_MULTIPLICITIES[alt_type] == 
+                    _RXN_NEUTRON_MULTIPLICITIES[endf_type] 
+               )):
+                # These are the same reaction
+                if not alt_type == rx_type:
+                    # The alt_type does not coincide with rx_type
+                    # i,e., it is a true alternative
+                    alternatives.append(alt_type)
+                    rx_A = [adder.data.zam(x[1])[1] for x in 
+                                    _RXN_SECONDARY_PARTICLES[endf_type]]
+                    alt_A = [adder.data.zam(x[1])[1] for x in 
+                                    _RXN_SECONDARY_PARTICLES[alt_type]]
+
+                    if min(alt_A) <= min(rx_A):
+                        if ( ( min(alt_A) < min(rx_A) ) or (
+                            len(_RXN_SECONDARY_PARTICLES[alt_type]) < 
+                            len(_RXN_SECONDARY_PARTICLES[endf_type]) 
+                        )):
+                            # The alternative type has a smaller product identifier
+                            # and - as such - it follows the ENDF convention
+                            endf_type = alt_type 
+
+    return endf_type, alternatives
+                                
diff --git a/adder/input.py b/adder/input.py
index b65558f..be352ba 100644
--- a/adder/input.py
+++ b/adder/input.py
@@ -11,12 +11,12 @@ from adder.control_group import ControlGroup
 from adder.loggedclass import LoggedClass
 from adder.constants import *
 from adder.msr_reactor import MSRReactor
+from collections import Counter
 
 
 logger = LoggedClass(0, __name__)
 _INDENT = 2
 
-
 def get_input(input_file):
     """Reads the input file located at the input_file path and returns
     an initialized adder.Reactor object.
@@ -46,6 +46,8 @@ def get_input(input_file):
     logger.log("info", "Processing ADDER Input")
     config = ConfigObj(input_file, raise_errors=True,
                        list_values=True, stringify=True)
+
+    # validate input & setting default values
     adder.input_validation.validate(config)
     input_echo(config)
 
@@ -58,6 +60,14 @@ def get_input(input_file):
     if "universes" in config:
         uni_aliases = setup_universe_aliases(config["universes"], rx)
 
+    # check list of matuni names
+    mat_names = [mat.name for mat in rx.materials]
+    check_names(mat_names, "material")
+    if "universes" in rx.neutronics.__dir__():
+        uni_names = [uni.name for uni in rx.neutronics.universes.values()]
+        check_names(uni_names, "universe")
+
+    # setup operations object
     ops = setup_operations(config, mat_aliases, uni_aliases, rx)
 
     logger.log("info", "Completed ADDER Input Processing")
@@ -194,14 +204,58 @@ def setup_reactor(config):
             create_univ_supply_storage(config["universes"]["storage"],
                                        rx, "[universes][[storage]]")
 
+    # Create and associate unique XS libraries to storage materials and
+    # check that all storage materials have densities assigned
+    rx.validate_storage_materials()
+
     # Setup the control group information
     if "control_groups" in config:
         for group_name, data in config["control_groups"].items():
             rx.control_groups[group_name] = ControlGroup(group_name, data)
 
+    # Adding user tallies to be managed by ADDER
+    if "tallies" in config:
+        user_tallies_adder_i = get_user_tallies(config["tallies"])
+        for tally_id in user_tallies_adder_i.keys():
+            logger.log("info_file",
+                       f"Tally {tally_id}, type {user_tallies_adder_i[tally_id]}, processing", 6)
+        rx.user_tallies_adder_i = user_tallies_adder_i
+
     return rx
 
 
+# check for managing tallies
+def get_user_tallies(user_tallies_info):
+    # This parses the config block to get the information
+    # of the tallies to be processed from the ADDER input.
+    user_tallies = OrderedDict()
+    for ssec, subcfg in user_tallies_info.items():
+        # Handle the ids in range, list or item
+        tally_ids = []
+        if ssec.startswith("range"):
+            tally_id_start = subcfg["tally_id_start"]
+            tally_id_end = subcfg["tally_id_end"]
+            exclude = subcfg["exclude_tally_ids"]
+            if exclude is None:
+                exclude = []
+            for id_ in range(tally_id_start, tally_id_end + 1):
+                if id_ not in exclude:
+                    tally_ids.append(id_)
+        elif ssec.startswith("list"):
+            # Handle the list
+            tally_ids = subcfg["tally_ids"]
+        elif ssec.startswith("item"):
+            # End with the individuals
+            tally_ids = [subcfg["tally_id"]]
+
+        # Get the remaining data that doesn't depend on type
+        tally_type = subcfg["type"]
+        # associate tally id to tally type
+        for id_ in tally_ids:
+            user_tallies[str(id_)] = tally_type
+
+    return user_tallies
+
 def get_mat_univ_shuffles(config):
     # This parses the config block to figure out which materials are shuffled
     # so that we can determine which materials to duplicate
@@ -613,6 +667,12 @@ def setup_material_aliases(config, rx):
     for alias_data in aliases_info.values():
         name = alias_data["name"]
 
+        # check name duplication
+        if name in aliases.keys():
+            msg = "The same name {} is assigned to more".format(name) + \
+                  " than one material alias. Check ADDER input."
+            logger.log("error", msg)
+
         # First we make sure this alias name does not exist in the model
         # as a material
         for model_material in rx.materials:
@@ -650,6 +710,7 @@ def setup_material_aliases(config, rx):
     return aliases
 
 
+
 def setup_universe_aliases(config, rx):
     """Given the config dictionary, this method creates the
     list of aliases to be used with fuel management operations.
@@ -677,29 +738,35 @@ def setup_universe_aliases(config, rx):
     for alias_data in aliases_info.values():
         name = alias_data["name"]
 
+        # check name duplication
+        if name in aliases.keys():
+            msg = "The same name {} is assigned to more".format(name) + \
+                  " than one universe alias. Check ADDER input."
+            logger.log("error", msg)
+
         # First we make sure this alias name does not exist in the model
-        # as a material
-        for model_material in rx.materials:
-            if name == model_material.name:
+        # as a universe
+        for model_universe in rx.neutronics.universes.values():
+            if name == model_universe.name:
                 msg = "Alias {} cannot have the same ".format(name) + \
                     "name as a universe"
                 logger.log("error", msg)
 
         # The validator made sure there was a list of length 1
         # for the set attribute, all that is left is to make sure it is
-        # a valid material name and that all materials in the set are
+        # a valid universe name and that all universes in the set are
         # the same type (supply, storage, in_core)
         alias_set = alias_data["set"]
         statuses = []
-        for alias_material in alias_set:
+        for alias_universe in alias_set:
             match = False
-            for model_material in rx.materials:
-                if model_material.name == alias_material:
-                    statuses.append(model_material.status)
+            for model_universe in rx.neutronics.universes.values():
+                if model_universe.name == alias_universe:
+                    statuses.append(model_universe.status)
                     match = True
                     break
             if not match:
-                msg = "{} from alias {}".format(alias_material, name) + \
+                msg = "{} from alias {}".format(alias_universe, name) + \
                     " is an invalid universe!"
                 logger.log("error", msg)
             else:
@@ -778,10 +845,19 @@ def setup_operations(config, mat_aliases, uni_aliases, rx):
                 depletion_method = ssec_data["depletion_method"]
                 depletion_substeps = ssec_data["depletion_substeps"]
                 execute_endpoint = ssec_data["execute_endpoint"]
+                renormalize_power_density = ssec_data["renormalize_power_density"]
+
+                # setting user_tallies . Include is defined in the write
+                user_tallies={}
+                if rx.user_tallies_adder_i:
+                    user_tallies = rx.user_tallies_adder_i
+
+                include_user_tallies = ssec_data["include_user_tallies"]
 
                 method_args = (delta_ts, cumulative_time_steps, powers,
-                               fluxes, depletion_substeps, depletion_method,
-                               execute_endpoint)
+                               fluxes, user_tallies, include_user_tallies,
+                               depletion_substeps, depletion_method, execute_endpoint,
+                               renormalize_power_density)
                 cumulative_time_steps += len(delta_ts)
                 # Store the results
                 if i == 0:
@@ -895,6 +971,8 @@ def setup_operations(config, mat_aliases, uni_aliases, rx):
                     angle_units = None
                     matrix = None
                     displacement = [ssec_data["value"], 0., 0.]
+                    matrix_notation="mcnp"
+                    reset = ssec_data["reset"]
                 else:
                     obj_type = ssec_data["type"]
                     obj_set = ssec_data["set"]
@@ -907,6 +985,9 @@ def setup_operations(config, mat_aliases, uni_aliases, rx):
                         matrix = np.array(matrix,
                                           dtype=np.float64).reshape((3, 3))
                     displacement = ssec_data["displacement"]
+                    matrix_notation = ssec_data["matrix_notation"]
+                    reset = ssec_data["reset"]
+
 
                     aliases = uni_aliases
 
@@ -916,7 +997,8 @@ def setup_operations(config, mat_aliases, uni_aliases, rx):
                 # Now create a transform for each in the set
                 method_name = "transform"
                 method_args = (full_obj_set, yaw, pitch, roll, angle_units,
-                               matrix, displacement, obj_type)
+                               matrix, displacement, obj_type, matrix_notation,
+                               reset)
 
                 if i == 0:
                     ops.append((label, subsection, method_name, method_args))
@@ -928,9 +1010,14 @@ def setup_operations(config, mat_aliases, uni_aliases, rx):
                 sweep_group = ssec_data["group_name"]
                 sweep_values = ssec_data["values"]
 
+                user_tallies = {}
+                if rx.user_tallies_adder_i:
+                    user_tallies = rx.user_tallies_adder_i
+                include_user_tallies = ssec_data["include_user_tallies"]
+
                 # Now create a transform for each in the set
                 method_name = "geom_sweep"
-                method_args = (sweep_group, sweep_values)
+                method_args = (sweep_group, sweep_values, user_tallies)
 
                 if i == 0:
                     ops.append((label, subsection, method_name, method_args))
@@ -949,6 +1036,7 @@ def setup_operations(config, mat_aliases, uni_aliases, rx):
 
                 k_target = ssec_data["k_target"]
                 bracket_interval = ssec_data["bracket_interval"]
+                reference_position = ssec_data["reference_position"]
                 target_interval = ssec_data["target_interval"]
                 initial_guess = ssec_data["initial_guess"]
                 min_act_batches = ssec_data["min_active_batches"]
@@ -957,8 +1045,9 @@ def setup_operations(config, mat_aliases, uni_aliases, rx):
 
                 # Now create a transform for each in the set
                 method_name = "geom_search"
-                method_args = (search_set, k_target, bracket_interval,
-                               target_interval, uncertainty_fraction,
+                method_args = (search_set, k_target, bracket_interval, 
+                               reference_position, target_interval, 
+                               uncertainty_fraction,
                                initial_guess, min_act_batches, max_iterations)
 
                 if i == 0:
@@ -972,12 +1061,20 @@ def setup_operations(config, mat_aliases, uni_aliases, rx):
                 # neutronics solver's input at this particular stage of the
                 # computation
                 fname = ssec_data["filename"]
-                user_tallies = ssec_data["include_user_tallies"]
                 user_output = ssec_data["include_user_output"]
+                include_user_tallies = ssec_data["include_user_tallies"]
                 adder_tallies = ssec_data["include_adder_tallies"]
 
+
+
+                user_tallies = {}
+
+                if rx.user_tallies_adder_i:
+                    user_tallies = rx.user_tallies_adder_i
+
                 method_name = "write_neutronics_input"
-                method_args = (fname, adder_tallies, user_tallies, user_output)
+                method_args = (fname, adder_tallies, user_tallies, include_user_tallies,
+                               user_output)
                 # Store the results
                 if i == 0:
                     ops.append((label, subsection, method_name, method_args))
@@ -1220,3 +1317,11 @@ def _all_equal(iterable):
     except StopIteration:
         return True
     return all(first == rest for rest in iterator)
+
+def check_names(matuni_names, type):
+    # check if each matuni name is used more than once
+    duplicates = [name for name, count in Counter(matuni_names).items() if count > 1]
+    for duplicate in duplicates:
+        msg = "The same name {} is assigned to more ".format(duplicate) + \
+              "than one {}. Check ADDER input.".format(type)
+        logger.log("error", msg)
diff --git a/adder/input_validation.py b/adder/input_validation.py
index 8d26226..e650dac 100644
--- a/adder/input_validation.py
+++ b/adder/input_validation.py
@@ -4,6 +4,7 @@ import adder.constants as constants
 from adder.data import is_isotope
 from adder.type_checker import *
 from adder.loggedclass import LoggedClass
+
 logger = LoggedClass(0, __name__)
 
 
@@ -23,6 +24,8 @@ def validate(config):
     if "universes" in config:
         _validate_universes(config["universes"])
         # No else needed since this block is optional
+    if "tallies" in config:
+        _validate_tallies(config["tallies"])
     if "operations" in config:
         num_time_steps = _validate_ops(config["operations"], config,
                                        group_names)
@@ -32,7 +35,7 @@ def validate(config):
             _validate_msr(config["msr"], num_time_steps)
         else:
             msg = "The [msr] block was provided, however " + \
-                "the depletion solver is not `msr`, `msr16`, or 'msr48'"
+                  "the depletion solver is not `msr`, `msr16`, or 'msr48'"
             raise ValueError(msg)
 
 
@@ -82,6 +85,10 @@ def _validate_metadata(config):
     default = constants.DEFAULT_REACTIVITY_THRESH_TO_INITIAL
     check_optional(config, keys, str_to_bool, level, default)
 
+    keys = ["renormalize_power_density"]
+    default = constants.DEFAULT_RENORMALIZE_POWER_DENSITY
+    check_optional(config, keys, str_to_bool, level, default)
+
     # If they only give num_threads, then set that to be what num_neut_threads
     # and num_depl_threads are
     if "num_threads" in config:
@@ -96,10 +103,10 @@ def _validate_metadata(config):
         check_num_and_range(config, keys, int, level, 1, min_val=1)
     # Check the integers
     keys = ["num_mpi_processes", "depletion_chunksize", "depletion_substeps"]
-    defaults = [1, 1000, 10]
+    defaults = [1, 0, 10]
     req_type = int
-    min_val = 1
-    for key, default in zip(keys, defaults):
+    min_vals = [1, 0, 1]
+    for key, default, min_val in zip(keys, defaults, min_vals):
         check_num_and_range(config, [key], req_type, level, default,
                             min_val=min_val)
 
@@ -159,6 +166,51 @@ def _validate_universes(config):
                                      "[universes][[storage]]")
 
 
+def _validate_tallies(config):
+    level = "[tallies]"
+    for mat_ssec, subcfg in config.items():
+        sublevel = level + "[[[{}]]]".format(mat_ssec)
+        # Handle just range
+        if mat_ssec.startswith("range"):
+            # Check required integers
+            keys = ["tally_id_start", "tally_id_end"]
+            req_type = int
+            check_required(subcfg, keys, req_type, sublevel)
+            check_num_and_range(subcfg, keys, req_type, sublevel, None,
+                                min_val=1)
+
+            # Check the exclude_neutronics_ids list
+            keys = ["exclude_tally_ids"]
+            check_lists(subcfg, keys, int, sublevel, required=False,
+                        set_None=True, min_val=1)
+
+        elif mat_ssec.startswith("list"):
+            # Handle just list
+            # Check the neutronics_ids list
+            keys = ["tally_ids"]
+            check_lists(subcfg, keys, int, sublevel, required=True, min_val=1)
+
+        elif mat_ssec.startswith("item"):
+            # Handle just individual items
+            keys = ["tally_id"]
+            req_type = int
+            check_required(subcfg, keys, req_type, sublevel)
+            check_num_and_range(subcfg, keys, req_type, sublevel, None,
+                                min_val=1)
+
+        else:
+            msg = "Invalid {} subsection name: {}".format(level, sublevel)
+            raise ValueError(msg)
+
+        # check type for keys
+        keys=["type"]
+        req_vals = constants.VALID_TALLY_TYPES
+        default = constants.DEFAULT_TALLY_TYPE
+        req_type = str
+        check_required(subcfg, keys, req_type, sublevel)
+        check_in_set(subcfg, keys, req_vals, level, None)
+
+
 def _validate_matuni_metadata(config, top_level):
     level = top_level + "[[metadata]]"
 
@@ -264,7 +316,6 @@ def _validate_aliases(config, top_level):
 
 
 def _validate_storage_and_supply(config, level):
-
     # We have either redefine, copy, or new subsections
     for my_ssec, subcfg in config.items():
         if my_ssec == "new":
@@ -380,7 +431,7 @@ def _validate_ops_deplete(config, top_config, level):
 
     # Either powers or fluxes must be provided
     if ("powers" in config and "fluxes" in config) or \
-        ("powers" not in config and "fluxes" not in config):
+            ("powers" not in config and "fluxes" not in config):
         msg = "One of 'powers' or 'fluxes'"
         raise ValueError(_reqd_errormsg(msg, level))
     if "powers" in config:
@@ -389,6 +440,8 @@ def _validate_ops_deplete(config, top_config, level):
     if "fluxes" in config:
         check_lists(config, ["fluxes"], float, level, min_num=1, required=True,
                     min_val=0.)
+    keys=["include_user_tallies"]
+    check_optional(config, keys, str_to_bool, level, True)
 
     # The next two are optional values that can overwrite the global
     # defaults from metadata, so get that metadata value for the default
@@ -410,6 +463,11 @@ def _validate_ops_deplete(config, top_config, level):
     keys = ["execute_endpoint"]
     check_optional(config, keys, str_to_bool, level, True)
 
+    # Check if power density should be renormalized
+    keys = ["renormalize_power_density"]
+    default = top_config[keys[0]]
+    check_optional(config, keys, str_to_bool, level, default)
+
     return len(config['durations'])
 
 
@@ -472,8 +530,7 @@ def _validate_ops_write_input(config, top_config, level):
     check_required(config, keys, str, level)
 
     # file writing information
-    keys = ["include_user_tallies", "include_user_output",
-            "include_adder_tallies"]
+    keys = ["include_user_tallies", "include_user_output", "include_adder_tallies"]
     check_optional(config, keys, str_to_bool, level, True)
 
 
@@ -508,16 +565,16 @@ def _validate_ops_calc_volume(config, top_config, level):
         for param in ["cylinder_bottom", "cylinder_radius", "cylinder_height"]:
             if param in config:
                 msg = "If `lower_left` and `upper_right` are specified," + \
-                    "{} cannot be specified as well".format(param)
+                      "{} cannot be specified as well".format(param)
                 raise ValueError(msg)
     elif "cylinder_bottom" in config and "cylinder_radius" in config and \
-        "cylinder_height" in config:
+            "cylinder_height" in config:
         vol_type = "cylinder"
         # Now ensure there is not any box inputs
         for param in ["lower_left", "upper_right"]:
             if param in config:
                 msg = "If `lower_left` or `upper_right` cannot be " + \
-                    "specified with cylinder parameters"
+                      "specified with cylinder parameters"
                 raise ValueError(msg)
 
     if vol_type == "box":
@@ -542,6 +599,8 @@ def _validate_ops_transform(config, top_config, level, group_names):
         # Then we just need to get the group
         check_in_set(config, ["group_name"], group_names, level, default=None)
         check_required(config, ["value"], float, level)
+        check_optional(config, ["reset"], str_to_bool, level,
+                       constants.DEFAULT_TRANSFORM_RESET)
     else:
         # Get the type
         keys = ["type"]
@@ -563,7 +622,7 @@ def _validate_ops_transform(config, top_config, level, group_names):
 
         # angle_units
         check_in_set(config, ["angle_units"], constants.VALID_ANGLE_TYPES, level,
-                    constants.DEFAULT_ANGLE_TYPE)
+                     constants.DEFAULT_ANGLE_TYPE)
 
         # Matrix
         keys = ["matrix"]
@@ -583,10 +642,22 @@ def _validate_ops_transform(config, top_config, level, group_names):
         if config[keys[0]] is None:
             config[keys[0]] = [0., 0., 0.]
 
+        # Matrix notation
+        keys = ["matrix_notation"]
+        check_optional(config, keys, str, level, default="mcnp")
+
+        # Reset flag
+        check_optional(config, ["reset"], str_to_bool, level,
+                       constants.DEFAULT_TRANSFORM_RESET)
+
 
 def _validate_ops_geom_sweep(config, top_config, level, group_names):
     check_in_set(config, ["group_name"], group_names, level, default=None)
 
+
+    keys=["include_user_tallies"]
+    check_optional(config, keys, str_to_bool, level, True)
+
     # And now we can check the range and list blocks
     values = []
     for key in config:
@@ -644,12 +715,21 @@ def _validate_ops_geom_search(config, top_config, level, group_names):
     # The required list of floats
     check_lists(config, ["bracket_interval"], float, level, 2, 2, True)
     # Optional parameters
-    check_optional(config, ["initial_guess"], float, level,
+    check_optional(config, ["reference_position"], str, level,
+                   constants.DEFAULT_GEOM_SEARCH_REFERENCE_POSITION)
+    check_float_or_string(config, ["reference_position"],
+                          constants.VALID_GEOM_SEARCH_REFERENCE_POSITION,
+                          level, None)
+    check_optional(config, ["initial_guess"], str, level,
                    config["bracket_interval"][1])
-    check_greater_than("initial_guess", config["initial_guess"],
-                       config["bracket_interval"][0], equality=True)
-    check_less_than("initial_guess", config["initial_guess"],
-                    config["bracket_interval"][1], equality=True)
+    check_float_or_string(config, ["initial_guess"],
+                          constants.VALID_GEOM_SEARCH_INITIAL_GUESS,
+                          level, None)
+    if isinstance(config["initial_guess"], float):
+        check_greater_than("initial_guess", config["initial_guess"],
+                           config["bracket_interval"][0], equality=True)
+        check_less_than("initial_guess", config["initial_guess"],
+                        config["bracket_interval"][1], equality=True)
     check_optional(config, ["min_active_batches"], int, level,
                    constants.DEFAULT_GEOM_SEARCH_MIN_ACTIVE_BATCHES)
     check_greater_than("min_active_batches", config["min_active_batches"], 3)
@@ -700,8 +780,8 @@ def _validate_msr(config, num_time_steps):
                 # duration, power/fluxes and feed rate must be the same length
                 if len(sscfg["feed_rate"]) != num_time_steps and len(sscfg["feed_rate"]) > 1:
                     msg = "The total number of durations in the deplete " + \
-                        "operations must be equal to number of feed_rate " + \
-                        "values."
+                          "operations must be equal to number of feed_rate " + \
+                          "values."
                     logger.log("error", msg)
 
                 # feed_rate, feed_material, feed_mixture must be same length
@@ -710,12 +790,12 @@ def _validate_msr(config, num_time_steps):
                        for lst in [sscfg["feed_material"],
                                    sscfg["feed_mixture"], sscfg["density"]]):
                     msg = "feed_rate, feed_material, feed_mixture, and " + \
-                        "density must be lists of the same length"
+                          "density must be lists of the same length"
                     logger.log("error", msg)
 
                 if len(sscfg["feed_rate"]) == 1:
-                    msg = "Only 1 feed rate value provided, CONSTANT feed " +\
-                        "rate assumed. "
+                    msg = "Only 1 feed rate value provided, CONSTANT feed " + \
+                          "rate assumed. "
                     logger.log("info", msg)
 
                 # Do any unit conversion so we dont have to deal with it later
@@ -744,7 +824,7 @@ def _validate_msr(config, num_time_steps):
                         continue
                     elif not subsubkey.lower().startswith("material"):
                         msg = "Only [[[material_#]]] blocks " + \
-                            "are allowed in a [msr][[system]][[[feed]]] block!"
+                              "are allowed in a [msr][[system]][[[feed]]] block!"
                         logger.log("error", msg)
 
                     ssscfg = sscfg[subsubkey]
@@ -762,13 +842,12 @@ def _validate_msr(config, num_time_steps):
                     check_with_function(ssscfg, ["names"], is_isotope,
                                         ssslevel)
 
-                    # make list of material names
                     if 'material_names' in locals():
-                        material_names.append(subsubkey.strip('material_'))
+                        material_names.append(subsubkey[len("material_"):])
                     else:
-                        material_names = [subsubkey.strip('material_')]
+                        material_names = [subsubkey[len("material_"):]]
 
-                # Now use feed_material and feed_mixture to organize isotope
+                        # Now use feed_material and feed_mixture to organize isotope
                 # amount and rearrange so we have a dictionary relating names
                 # to the vector
                 if "feed_vector" not in sscfg:
@@ -821,7 +900,7 @@ def _validate_msr(config, num_time_steps):
                     continue
                 elif not subkey.lower().startswith("component"):
                     msg = "Only [[[feed]]] and [[[component_#]]] blocks " + \
-                        "are allowed in a [msr][[system]] block!"
+                          "are allowed in a [msr][[system]] block!"
                     logger.log("error", msg)
 
                 sscfg = subcfg[subkey]
@@ -894,6 +973,7 @@ def _validate_msr(config, num_time_steps):
             msg = "Input Block {} Will Be Ignored".format(sublevel)
             logger.log("error", msg)
 
+
 ########################################################################
 
 
@@ -952,6 +1032,17 @@ def check_in_set(cfg, keys, req_vals, level, default, cast_to=None):
             check_value(param, cfg[param], req_vals)
 
 
+def check_float_or_string(cfg, keys, req_vals, level, default, cast_to=None):
+    for param in keys:
+        if param not in cfg:
+            cfg[param] = default
+        else:
+            try:
+                cfg[param] = float(cfg[param])
+            except:
+                check_in_set(cfg, keys, req_vals, level, default)
+
+
 def check_num_and_range(cfg, keys, req_type, level, default,
                         min_val=None, max_val=None):
     # This must convert the type, check that it is in the range, and set
@@ -991,19 +1082,19 @@ def _reqd_errormsg(name, level):
 
 def _min_len_errormsg(name, level, min_num):
     msg = "{} at the {} level of the input file is ".format(name, level) + \
-        "less than the minimum length of {}".format(min_num)
+          "less than the minimum length of {}".format(min_num)
     return msg
 
 
 def _max_len_errormsg(name, level, max_num):
     msg = "{} at the {} level of the input file is ".format(name, level) + \
-        "less than the maximum length of {}".format(max_num)
+          "less than the maximum length of {}".format(max_num)
     return msg
 
 
 def _min_val_errormsg(name, level, min_num):
     msg = "{} at the {} level of the input file is ".format(name, level) + \
-        "less than the minimum value of {}".format(min_num)
+          "less than the minimum value of {}".format(min_num)
     return msg
 
 
diff --git a/adder/isotope.py b/adder/isotope.py
index eb342b4..e2222f3 100644
--- a/adder/isotope.py
+++ b/adder/isotope.py
@@ -1,12 +1,9 @@
 from dataclasses import dataclass, field
+from ctypes import c_ushort
 
 from adder.type_checker import *
 from adder.data import atomic_mass, zam
 
-
-EXISTING_ISOTOPES = {}
-
-
 @dataclass
 class Isotope:
     """This class contains relevant information about an isotope.
@@ -40,9 +37,9 @@ class Isotope:
     name: str
     xs_library: str
     is_depleting: bool = True
-    Z: int = field(init=False)
-    A: int = field(init=False)
-    M: int = field(init=False)
+    _Z: c_ushort = field(init=False)
+    _A: c_ushort = field(init=False)
+    _M: c_ushort = field(init=False)
 
     def __post_init__(self):
         # Do the relevant checks of values
@@ -60,11 +57,23 @@ class Isotope:
         check_type("A", A, int)
         check_greater_than("A", A, 0, equality=True)
         check_less_than("A", A, 300, equality=True)
-        check_value("M", M, [0, 1, 2, 3, 4])
+        check_less_than("M", M, 10, equality=True)
         if A == 0 and M != 0:
             raise ValueError("Cannot provide M for elemental data!")
 
-        self.Z, self.A, self.M = Z, A, M
+        self._Z, self._A, self._M = c_ushort(Z), c_ushort(A), c_ushort(M)
+
+    @property
+    def Z(self):
+        return self._Z.value
+
+    @property
+    def A(self):
+        return self._A.value
+
+    @property
+    def M(self):
+        return self._M.value
 
     @property
     def atomic_mass(self):
@@ -77,40 +86,241 @@ class Isotope:
 
     def __hash__(self):
         # Control the hash so it is cheaper to create (its executed alot by the
-        # isotope_factory), and to guarantee reproducibility even across
+        # isotope registry), and to guarantee reproducibility even across
         # threads
         return hash((self.name, self.xs_library, self.is_depleting))
 
 
-def isotope_factory(name, xs_library, is_depleting=True):
-    """Creates a new isotope or returns a reference to a previously
-    created isotope; this is used so we can treat isotopes as immutable
-    to avoid initializing billions of each kind.
+class IsotopeRegistry:
+    """This class is a pre-allocated registry of all isotopes that may be
+    present in the model.
+
+    This registry is necessary for multiple reasons:
+
+    1. Materials must know which isotopes they contain, however, storing
+        Isotope instances for each Material will be very costly for even
+        moderately-sized models.  Therefore, we instead keep all the isotopes in
+        one place (this registry) and instead the Materials need only to keep
+        track of the index of the isotope in this registry.
+
+    2. This class provides a simple location of isotopes that can be placed in
+        shared memory by downstream parallelization techniques so that every
+        material will have access to the same isotope registry from the same
+        location in memory. This limits the amount of data duplication necessary
+        to initialize parallel execution blocks.
+
+    This registry will be pre-allocated with all possible isotopes, including
+    the combinations present in the neutronics library and perturbations of
+    is-depleting or not. This will use additional space, however, it will only
+    be several thousand isotopes and therefore will be significantly more
+    compact than storing on the Materials themselves.
 
     Parameters
     ----------
-    name : str
-        The isotope name in GND format, e.g., "U235"
-    xs_library : str
-        Cross section library reference, i.e. "80c" if using MCNP.
-    is_depleting : bool, optional
-        Whether or not the isotope should be treated as depleting;
-        defaults to True.
-
-    Returns
-    -------
-    iso : Isotope
-        Either a new isotope, or a reference to an already created isotope
+    neutronics_library_isos : dict
+        The keys are the isotope names in GND format and the values are an
+        Iterable of associated library names available in the neutronics
+        library.
     """
 
-    iso_hash = hash((name, xs_library, is_depleting))
-    if iso_hash in EXISTING_ISOTOPES:
-        return EXISTING_ISOTOPES[iso_hash]
-    else:
-        iso = Isotope(name, xs_library, is_depleting)
-        EXISTING_ISOTOPES[iso_hash] = iso
-        return iso
+    def __init__(self, neutronics_library_isos):
+        iso_names = []
+        iso_xs_libs = []
+        # First we set up the set of isotopes based on the neutronics lib
+        for iso_name, set_of_iso_libs in neutronics_library_isos.items():
+            # This is really just pulling values from the input directly as no
+            # further processing is needed
+            iso_names.append(iso_name)
+            iso_xs_libs.append(set_of_iso_libs)
+
+        # For robustness, make sure the iso names and xs_libs are the same size
+        if len(iso_names) != len(iso_xs_libs):
+            msg = 'iso_names and iso_xs_libs must be same length!'
+            raise ValueError(msg)
+
+        # Now we create depleting and non-depleting versions of each isotope
+        self._isos = []
+        self._iso_names = []
+        self._idxs_from_name = {}
+        for i in range(len(iso_names)):
+            iso_name = iso_names[i]
+            for xs_lib in iso_xs_libs[i]:
+                for is_depleting in (True, False):
+                    self.register_isotope(iso_name, xs_lib, is_depleting)
+
+    def clear(self):
+        """Clears the registry for unit tests"""
+
+        self._isos = []
+        self._iso_names = []
+        self._idxs_from_name = {}
+
+    def register_depletion_lib_isos(self, depletion_libs, materials):
+        """Registers isotopes that exist only in the depletion library and not
+        the neutronics library.
+
+        This must be done separate from the neutronics isotopes (in __init__)
+        because we need the neutronics isotopes to parse the neutronics file,
+        and we need to parse the neutronics file before we can get materials
+        which we need here.
+
+        Parameters
+        ----------
+        depletion_libs : OrderedDict of DepletionLibrary
+            The depletion libraries used by the materials
+        materials: List of adder.Material
+            The List of Materials for which we will need the default xs lib
+            from.
+
+        """
+
+        iso_names_and_libs = {}
+
+        # Get all the isotopes in a depleting materials inventory that
+        # need to register/check if registered
+        for mat in materials:
+            if mat.is_depleting:
+                dflt_xs_lib = mat.default_xs_library
+                for iso in depletion_libs[mat.depl_lib_name].isotopes.keys():
+                    if iso in iso_names_and_libs:
+                        iso_names_and_libs[iso].add(dflt_xs_lib)
+                    else:
+                        iso_names_and_libs[iso] = set([dflt_xs_lib])
+
+        # Now we can add it
+        for iso_name, iso_xs_libs in iso_names_and_libs.items():
+            for xs_lib in iso_xs_libs:
+                self.register_isotope(iso_name, xs_lib, is_depleting=True)
+
+    @property
+    def num_isos(self):
+        return len(self._isos)
+
+    def register_isotope(self, iso_name, xs_lib, is_depleting=True):
+        """Creates a new isotope if not present. Returns the index of the
+        isotope, whether newly created or not.
+
+        Parameters
+        ----------
+        iso_name : str
+            The isotope name in GND format, e.g., "U235"
+        xs_lib : str
+            Cross section library reference, e.g., "80c" if using MCNP.
+        is_depleting : bool
+            Whether or not the isotope should be treated as depleting
+
+        Returns
+        -------
+        idx : int
+            The new isotope index
+        """
+
+        # First check to see if this isotope exists
+        if iso_name in self._idxs_from_name:
+            # The isotope does exist but let's see if we have a xs_lib
+            # and depleting match
+            idxs = self._idxs_from_name[iso_name]
+            for idx in idxs:
+                iso = self._isos[idx]
+                if iso.name != iso_name:
+                    # Add an error if this is the case bc then _idxs_from_name
+                    # is out of sync with _isos and we need a dev to figure
+                    # out why.
+                    msg = "IsotopeRegistry._idxs_from_name may be corrupted!"
+                    raise ValueError(msg)
+                if iso.xs_library == xs_lib and iso.is_depleting == is_depleting:
+                    # Then we have a match, just return our idx
+                    return idx
+                # Otherwise, try the rest in idxs and if, when we do all of
+                # them, we find still make it this far, then it's time for a
+                # new isotope
+
+        # If we get here then we need a new isotope. Make it
+        idx = self.num_isos
+        iso = Isotope(iso_name, xs_lib, is_depleting)
+        self._isos.append(iso)
+        self._iso_names.append(iso_name)
+        if iso_name in self._idxs_from_name:
+            self._idxs_from_name[iso_name].append(idx)
+        else:
+            self._idxs_from_name[iso_name] = [idx]
+
+        return idx
+
+    def switch_iso_depleting_status(self, old_idx, new_is_depleting):
+        """Find the idx of the same isotope with a different depleting status.
+
+        Used when assigning isotopes a new status.
+
+        Parameters
+        ----------
+        old_idx : int
+            The index of the isotope to change
+        new_is_depleting : bool
+            Whether or not the isotope should be treated as depleting
+
+        Returns
+        -------
+        new_idx : int
+            The index of the isotope with the new status
+        """
+
+        if old_idx >= self.num_isos:
+            msg = "Original Isotope not found!"
+            raise ValueError(msg)
+
+        old_iso = self._isos[old_idx]
+
+        # We can short-circuit the register isotope process by checking to see
+        # if this isotope already has the new is_depleting status.
+        if new_is_depleting == old_iso.is_depleting:
+            return old_idx
+
+        # Otherwise, we need a new index so lets just go get it
+        new_idx = self.register_isotope(old_iso.name, old_iso.xs_library,
+            new_is_depleting)
+        return new_idx
+
+    def get_isotope(self, iso_name, xs_lib, is_depleting):
+        """Gets the isotope index from the registry.
+
+        This is somewhat similar to the register_isotope method but we know it
+        is read-only because we only access results, therefore making it more
+        applicable in parallel sections.
+
+        Parameters
+        ----------
+        iso_name : str
+            The isotope name in GND format, e.g., "U235"
+        xs_lib : str
+            Cross section library reference, i.e. "80c" if using MCNP.
+        is_depleting : bool
+            Whether or not the isotope should be treated as depleting
+
+        Returns
+        -------
+        idx : int
+            The isotope index
+        """
+
+        # First check to see if this isotope exists
+        if iso_name in self._idxs_from_name:
+            # The isotope does but lets see if we have a xs_lib
+            # and depleting match
+            idxs = self._idxs_from_name[iso_name]
+            for idx in idxs:
+                iso = self._isos[idx]
+                if iso.name != iso_name:
+                    # Add an error if this is the case bc then _idxs_from_name
+                    # is out of sync with _isos and we need a dev to figure
+                    # out why.
+                    msg = "IsotopeRegistry._idxs_from_name may be corrupted!"
+                    raise ValueError(msg)
+                if iso.xs_library == xs_lib and iso.is_depleting == is_depleting:
+                    # Then we have a match, just return our idx
+                    return idx
 
+        # Just in case, to help with debugging (should never get here!)
+        raise ValueError(f'Invalid Isotope: {iso_name}, {xs_lib}, {is_depleting}')
 
-def update_isotope_depleting_status(old_iso, new_is_depleting):
-    return isotope_factory(old_iso.name, old_iso.xs_library, new_is_depleting)
+ISO_REGISTRY = IsotopeRegistry({})
diff --git a/adder/material.py b/adder/material.py
index d621683..d52bf21 100644
--- a/adder/material.py
+++ b/adder/material.py
@@ -6,7 +6,7 @@ import h5py
 
 from adder.data import atomic_mass
 from adder.depletionlibrary import DecayData, ReactionData
-from adder.isotope import *
+import adder.isotope
 import adder.constants as constants
 from adder.type_checker import *
 from adder.utils import get_id
@@ -22,6 +22,9 @@ class Material(object):
     id_ : int
         The identifier of the material, as referred to in the neutronics
         solver.
+    parent_id: int
+        The parent material's ID, from which the material is duplicate.
+        None (default) corresponds to not duplicated material
     density : float
         The material density in units of a/b-cm
     isotope_data : Iterable of tuples
@@ -60,11 +63,11 @@ class Material(object):
         Whether or not this material is to be depleted.
     density : float
         The material density in units of a/b-cm
-    isotopes : Iterable of adder.Isotopes
-        The isotopes within the material.
-    atom_fractions : Iterable of float
+    isotopes : numpy.ndarray of uint16
+        The indices in the Isotope Registry of isotopes within the material.
+    atom_fractions : numpy.ndarray of np.double
         The fractions of the density of the constituent isotopes.
-    number_densities : numpy.ndarray
+    number_densities : numpy.ndarray of np.double
         The number densities of each isotope
     volume : float
         The volume of the material in units of cm^3.
@@ -73,12 +76,15 @@ class Material(object):
         storage.
     flux : np.ndarray of float
         The group-wise flux
+    power_density : float
+        Power density in W/cm3
+    fission_density : float
+        Fission density in fissions/cm3
+    burnup : float
+        Burnup in MWd
     default_xs_library : str
         The default xs library to apply to isotopes as introduced by
         depletion or otherwise.
-    num_groups : int
-        The number of groups in the depletion library, and thus the
-        size of the flux array
     thermal_xs_libraries : List of str.
         This provides the names of the associated thermal scattering
         libraries, if needed. Defaults to a blank list, indicating no
@@ -98,11 +104,13 @@ class Material(object):
 
     def __init__(self, name, id_, density, isotope_data,
                  atom_fractions, is_depleting, default_xs_library,
-                 num_groups, thermal_xs_libraries, status, check=True):
+                 num_groups, thermal_xs_libraries, status, check=True,
+                 parent_id=None):
         self.name = name
         self.id = id_
+        self.parent_id = parent_id
         self.density = density
-        self.isotopes = [isotope_factory(*data) for data in isotope_data]
+        self.isotopes = isotope_data
         self.atom_fractions = atom_fractions
         self.is_depleting = is_depleting
         # Volumes will be over-written after the neutronics solver runs
@@ -110,8 +118,11 @@ class Material(object):
         self.status = status
         self.is_default_depletion_library = False
         self.depl_lib_name = constants.BASE_LIB
-        self.num_groups = num_groups
-        self.flux = np.zeros(self.num_groups)
+        self.flux = np.zeros(num_groups)
+        self._flux_1g = 0.
+        self.power_density = 0.
+        self.fission_density = 0.
+        self.burnup = 0.
         self.default_xs_library = default_xs_library
         self.thermal_xs_libraries = thermal_xs_libraries
         self.isotopes_in_neutronics = True
@@ -140,19 +151,6 @@ class Material(object):
         if check:
             self.check()
 
-    def __getstate__(self):
-        selfdict = self.__dict__.copy()
-        nope = ['_id', '_is_depleting', '_volume', '_status',
-            '_depl_lib_name', '_num_groups', '_is_default_depletion_library',
-            '_thermal_xs_libraries', '_isotopes_in_neutronics', 'Q',
-            'num_copies', '_h5_path', 'h5_status_change', 'logs', '_USED_IDS']
-        for key in nope:
-            try:
-                del selfdict[key]
-            except:
-                pass
-        return selfdict
-
     @property
     def name(self):
         return self._name
@@ -187,6 +185,22 @@ class Material(object):
             self._id = id_
             Material._USED_IDS.add(self._id)
 
+    @property
+    def parent_id(self):
+        return self._parent_id
+
+    @parent_id.setter
+    def parent_id(self, parent_id_):
+        if parent_id_ is not None:
+            check_type("parent_id", parent_id_, int)
+            check_greater_than("parent_id", parent_id_, 0, equality=False)
+            check_less_than("parent_id", parent_id_, constants.MATL_MAX_ID, equality=True)
+            self._parent_id = parent_id_
+            Material._USED_IDS.add(self._parent_id)
+        else:
+            self._parent_id = parent_id_
+
+
     @property
     def density(self):
         return self._density
@@ -211,7 +225,7 @@ class Material(object):
         n = self.number_densities
         n_dot_amu = 0.
         for i in range(len(n)):
-            n_dot_amu += n[i] * atomic_mass(self._isotopes[i].name)
+            n_dot_amu += n[i] * atomic_mass(self.isotope_obj(i).name)
         mass_density = n_dot_amu / constants.AVOGADRO
         return mass_density
 
@@ -220,9 +234,14 @@ class Material(object):
         return self._isotopes
 
     @isotopes.setter
-    def isotopes(self, isotopes):
-        check_iterable_type("isotopes", isotopes, Isotope)
-        self._isotopes = isotopes
+    def isotopes(self, isotope_data):
+        try:
+            check_iterable_type('isotopes', isotope_data, np.uint16)
+            self._isotopes = isotope_data
+        except TypeError:
+            self._isotopes = np.array(
+                [np.uint16(adder.isotope.ISO_REGISTRY.register_isotope(*data))
+                 for data in isotope_data], dtype=np.uint16)
 
     @property
     def atom_fractions(self):
@@ -236,7 +255,8 @@ class Material(object):
             check_greater_than("atom_fractions", val, 0., equality=True)
         # Modify the atom fractions to sum to 1.0
         tot_frac = np.sum(atom_fractions)
-        norm_frac = [user_frac / tot_frac for user_frac in atom_fractions]
+        norm_frac = np.array([user_frac / tot_frac
+                              for user_frac in atom_fractions], dtype=np.double)
         self._atom_fractions = norm_frac[:]
 
     @property
@@ -246,6 +266,12 @@ class Material(object):
     @status.setter
     def status(self, status):
         check_value("status", status, constants.ALLOWED_STATUSES)
+        try:
+            if not status == self._status:
+                # Update the hdf5 status change flag
+                self.h5_status_change = True
+        except AttributeError:
+            pass
         self._status = status
 
     @property
@@ -311,24 +337,21 @@ class Material(object):
 
     @isotopes_in_neutronics.setter
     def isotopes_in_neutronics(self, isotopes_in_neutronics):
-        if isinstance(isotopes_in_neutronics, bool):
+        if isinstance(isotopes_in_neutronics, (bool, np.bool_)):
             self._isotopes_in_neutronics = \
-                [isotopes_in_neutronics] * self.num_isotopes
+                np.full(self.num_isotopes, np.bool_(isotopes_in_neutronics),
+                        dtype=np.bool_)
         else:
             check_iterable_type("isotopes_in_neutronics",
-                                isotopes_in_neutronics, bool)
+                                isotopes_in_neutronics, (bool, np.bool_))
             check_length("isotopes_in_neutronics", isotopes_in_neutronics,
                          self.num_isotopes)
-            self._isotopes_in_neutronics = isotopes_in_neutronics[:]
+            self._isotopes_in_neutronics = np.array(
+                isotopes_in_neutronics, dtype=np.bool_)
 
     @property
     def num_groups(self):
-        return self._num_groups
-
-    @num_groups.setter
-    def num_groups(self, num_groups):
-        check_type("num_groups", num_groups, int)
-        self._num_groups = num_groups
+        return self._flux.shape[0]
 
     @property
     def flux(self):
@@ -341,22 +364,55 @@ class Material(object):
         self._flux_1g = np.sum(flux)
         self.h5_status_change = True
 
+    @property
+    def power_density(self):
+        return self._power_density
+
+    @power_density.setter
+    def power_density(self, power_density):
+        check_type("power_density", power_density, float)
+        self._power_density = power_density
+        self.h5_status_change = True
+
+    @property
+    def fission_density(self):
+        return self._fission_density
+
+    @fission_density.setter
+    def fission_density(self, fission_density):
+        check_type("fission_density", fission_density, float)
+        self._fission_density = fission_density
+        self.h5_status_change = True
+
+    @property
+    def burnup(self):
+        return self._burnup
+
+    @burnup.setter
+    def burnup(self, burnup):
+        check_type("burnup", burnup, float)
+        self._burnup = burnup
+        self.h5_status_change = True
+
     @property
     def flux_1g(self):
         return self._flux_1g
 
     @property
     def number_densities(self):
-        N = self._density * np.asarray(self._atom_fractions) * 1.E24
+        N = self._density * np.asarray(self._atom_fractions, dtype=float) * 1.E24
         return N
 
     @property
     def num_isotopes(self):
         return len(self._isotopes)
 
+    def isotope_obj(self, i):
+        return adder.isotope.ISO_REGISTRY._isos[int(self._isotopes[i])]
+
     @property
     def isotope_names(self):
-        return [iso.name for iso in self._isotopes]
+        return [self.isotope_obj(i).name for i in range(self.num_isotopes)]
 
     def __repr__(self):
         return "<Material Name: {}, Id: {}, is_depleting: {}>".format(
@@ -383,7 +439,7 @@ class Material(object):
             if self._atom_fractions[i] == 0.:
                 to_remove.append(i)
         for i in to_remove:
-            msg = f'{self._isotopes[i].name} in Material {self._name} ' \
+            msg = f'{self.isotope_obj(i).name} in Material {self._name} ' \
                 f'(id: {self._id}) was removed as it has a zero atom fraction'
             self.logs.append(("info_file", msg, None))
             self.remove_isotope_by_index(i)
@@ -391,14 +447,10 @@ class Material(object):
     def remove_isotope_by_index(self, idx):
         # Remove an isotope by deleting the entries in:
         # isotopes, atom_fractions, and isotopes_in_neutronics
-        for items in (self._isotopes, self._atom_fractions,
-                      self._isotopes_in_neutronics):
-            if isinstance(items, list):
-                items.pop(idx)
-            else:
-                raise NotImplementedError(
-                    "remove_isotope_by_index "
-                    "currently only implemented for lists")
+        self._isotopes = np.delete(self._isotopes, idx)
+        self._atom_fractions = np.delete(self._atom_fractions, idx)
+        self._isotopes_in_neutronics = np.delete(
+            self._isotopes_in_neutronics, idx)
 
     def establish_initial_isotopes(self, apply_threshold_to_initial):
         """Sets the list of isotopes that should not be subject to the
@@ -427,8 +479,9 @@ class Material(object):
 
         # If we make it here, then we have the information we need
         stable = DecayData(None, "s", 0.)
-        zero_xs = ReactionData("b", lib.num_neutron_groups)
-        for i, iso in enumerate(self._isotopes):
+        zero_xs = ReactionData()
+        for i in range(self.num_isotopes):
+            iso = self.isotope_obj(i)
             if iso.name not in lib.initial_isotopes:
                 # The isotope is not in the depletion library, flag it as
                 # non-depleting
@@ -436,11 +489,12 @@ class Material(object):
                     "in Material {} to non-depleting ".format(self._name) + \
                     "since it is not in the depletion library"
                 self.logs.append(("info_file", msg, None))
-                self._isotopes[i] = update_isotope_depleting_status(iso, False)
+                self._isotopes[i] = adder.isotope.ISO_REGISTRY.switch_iso_depleting_status(
+                    self._isotopes[i], False)
 
                 if iso.name not in lib.isotopes:
-                    # If this isotope wasnt already added to the list of isos,
-                    # then do it witha stable, 0 cross section version of
+                    # If this isotope wasn't already added to the list of isos,
+                    # then do it with a stable, 0 cross section version of
                     # the isotope in the library so that indexing works
                     # later on.
                     lib.add_isotope(iso.name, xs=zero_xs, decay=stable)
@@ -473,9 +527,7 @@ class Material(object):
         if self._is_depleting:
             # Spend the memory and make copies of the isotopic data as it
             # will change in time
-            isotopes = np.empty(self.num_isotopes, dtype=object)
-            for i, iso in enumerate(self._isotopes):
-                isotopes[i] = (iso.name, iso.xs_library, iso.is_depleting)
+            isotopes = np.copy(self._isotopes)
             atom_fractions = np.copy(self._atom_fractions)
             is_depleting = True
             flux = np.copy(self._flux)
@@ -493,7 +545,7 @@ class Material(object):
             Q = self.Q
             iso_in_neut = self._isotopes_in_neutronics
         default_xs_library = deepcopy(self._default_xs_library)
-        num_groups = deepcopy(self._num_groups)
+        num_groups = self.num_groups
         thermal_xs_libraries = deepcopy(self._thermal_xs_libraries)
         status = deepcopy(self._status)
 
@@ -503,6 +555,10 @@ class Material(object):
 
         # Set the new id
         id_ = None
+        if not self.parent_id:
+            parent_id = self.id
+        else:
+            parent_id = self.parent_id
 
         # Update the number of clones so we can keep our names up to date
         self.num_copies += 1
@@ -515,7 +571,7 @@ class Material(object):
 
         clone = Material(name, id_, density, isotopes, atom_fractions,
                          is_depleting, default_xs_library, num_groups,
-                         thermal_xs_libraries, status)
+                         thermal_xs_libraries, status, parent_id=parent_id)
 
         if not clone._is_depleting:
             # Then we have to go back and add back in the references to the
@@ -579,6 +635,11 @@ class Material(object):
         if not self._is_depleting:
             return tot_Q, tot_fiss_rate
 
+        # if zero tot flx, tot. energy release and fiss. rate are zero
+        if np.sum(np.asarray(self._flux, dtype=float)) == 0:
+            msg = f"Zero flux in material {self.name}"
+            self.logs.append(("warning", msg, 12))
+
         Q, FR = depl_lib.get_composition_Q_fiss_rate(self.isotope_names,
                                                      self._atom_fractions,
                                                      self._flux)
@@ -630,9 +691,9 @@ class Material(object):
         if self._flux_1g <= 0. and self.num_groups > 1:
             # We will only preclude the isotopes of the smallest concentrations
             for i in range(len(self._isotopes)):
+                iso = self.isotope_obj(i)
                 if self._atom_fractions[i] < 1.E-10 and \
-                        (self._isotopes[i].name
-                         not in self.isotopes_to_keep_in_model):
+                        (iso.name not in self.isotopes_to_keep_in_model):
                     self._isotopes_in_neutronics[i] = False
             return
         elif self._flux_1g <= 0.:
@@ -648,7 +709,7 @@ class Material(object):
         # isotope
         delta_rhos = np.zeros(len(self._isotopes))
         # Step through each isotope and determine delta_rho
-        iso_names = [iso.name for iso in self._isotopes]
+        iso_names = [self.isotope_obj(i).name for i in range(self.num_isotopes)]
         N = self.number_densities
         base_nufiss = lib.get_1g_macro_xs(iso_names, N, "nu-fission", flux)
         base_abs = lib.get_1g_macro_xs(iso_names, N, "absorb", flux)
@@ -697,9 +758,9 @@ class Material(object):
             # But dont neglect isotopes which we do not deplete
             # (otherwise they wouldnt be in the model), or those which are
             # identified as to be kept in the model
-            if self._isotopes[neglect_index].is_depleting and \
-                (self._isotopes[neglect_index].name
-                 not in self.isotopes_to_keep_in_model):
+            iso = self.isotope_obj(neglect_index)
+            if iso.is_depleting and (iso.name
+                                     not in self.isotopes_to_keep_in_model):
                 self._isotopes_in_neutronics[neglect_index] = False
 
     def get_library_number_density_vector(self, iso_indices):
@@ -720,7 +781,8 @@ class Material(object):
         n_vector = np.zeros(len(iso_indices))
 
         mat_N = self.number_densities
-        for i, iso in enumerate(self._isotopes):
+        for i in range(self.num_isotopes):
+            iso = self.isotope_obj(i)
             if iso.is_depleting:
                 # Then we include it so its effect on the decay chain is
                 # captured
@@ -729,7 +791,8 @@ class Material(object):
         return n_vector
 
     def calc_composition_from_number_densities(self, n_vector, iso_indices,
-        inv_iso_indices, scale_constant=None):
+                                               inv_iso_indices,
+                                               scale_constant=None):
         """Computes a new material inventory based on a number density
         returned from a depletion calculation using this depletion
         library.
@@ -754,12 +817,11 @@ class Material(object):
 
         Returns
         -------
-        new_isotopes : Iterable of 3-tuple (str, str, bool)
-            A list of the isotope name (str), the xs library (str), and whether
-            it is depleting (bool). There is one of these 3-tuples per isotope.
-        new_fractions : np.ndarray
+        new_isotopes : np.ndarray of np.uint16
+            The indices into the isotope registry for our new composition
+        new_fractions : np.ndarray of np.double
             A 1-D vector containing the atom fractions for each of the isotopes
-            in new_isos
+            in new_isotopes
         new_density : float
             The new material density in units of a/b-cm
 
@@ -772,12 +834,14 @@ class Material(object):
         original_N = self.number_densities
         non_depleting_indices = []
         non_depleting_non_library = []
-        for i, isotope in enumerate(self._isotopes):
+        for i in range(self.num_isotopes):
+            isotope = self.isotope_obj(i)
             name = isotope.name
+            idx = self._isotopes[i]
             # Using the same loop we will also create a dictionary of the
-            # xs_libraries so we can re-set these later
-            original_iso_metadata[name] = (isotope.xs_library,
-                                           isotope.is_depleting, original_N[i])
+            # original iso attributes so we can re-set these later
+            original_iso_metadata[name] = (idx, isotope.is_depleting,
+                                           original_N[i])
             if not isotope.is_depleting:
                 if name in iso_indices:
                     non_depleting_indices.append(iso_indices[name])
@@ -800,14 +864,19 @@ class Material(object):
             # originally, so if this isnt a new isotope, use the
             # previous xs library
             if iso_name in original_iso_metadata:
-                xs_library, is_depleting, orig_N = \
+                idx, is_depleting, orig_N = \
                     original_iso_metadata[iso_name]
+                # xs_lib and is_depleting is the same, so we can use the same
+                # isotope index
+                new_isotopes[j] = idx
             else:
-                # Then this is new so use the default
-                xs_library = self._default_xs_library
+                # Then this is new so use the default xs lib, set to is_depleting
+                # and get its index.
                 is_depleting = True
                 orig_N = None
-            new_isotopes[j] = (iso_name, xs_library, is_depleting)
+
+                new_isotopes[j] = adder.isotope.ISO_REGISTRY.get_isotope(
+                    iso_name, self._default_xs_library, True)
 
             # Now, if this isotope was not depleting, we need to get
             # back the original value
@@ -824,8 +893,8 @@ class Material(object):
         # whether it be bc they are not in the library or otherwise
         for iso_name in non_depleting_non_library:
             # Get the starting info
-            xs_library, is_depleting, orig_N = original_iso_metadata[iso_name]
-            new_isotopes.append((iso_name, xs_library, is_depleting))
+            idx, is_depleting, orig_N = original_iso_metadata[iso_name]
+            new_isotopes.append(idx)
             new_fractions = np.append(new_fractions, orig_N)
             new_density += orig_N
 
@@ -852,9 +921,8 @@ class Material(object):
 
         Parameters
         ----------
-        new_isos : Iterable of 3-tuple (str, str, bool)
-            A list of the isotope name (str), the xs library (str), and whether
-            it is depleting (bool). There is one of these 3-tuples per isotope.
+        new_isos : np.ndarray
+            An array of isotope indices from the isotope registry.
         new_fracs : np.ndarray
             A 1-D vector containing the atom fractions for each of the isotopes
             in new_isos
@@ -862,8 +930,7 @@ class Material(object):
             The new material density in units of a/b-cm
         """
 
-        self._isotopes = [isotope_factory(*iso) for iso in new_isos]
-        # Convert the atom fractions to an array
+        self._isotopes = np.array(new_isos, dtype=np.uint16)
         self._atom_fractions = new_fracs
         self._density = new_density
         self.h5_status_change = True
@@ -917,7 +984,7 @@ class Material(object):
         else:
             vol = -1.
         if self._thermal_xs_libraries:
-            xslibs = np.array([np.string_(xs)
+            xslibs = np.array([np.bytes_(xs)
                                for xs in self._thermal_xs_libraries])
             num_therm = len(xslibs)
         else:
@@ -942,17 +1009,22 @@ class Material(object):
             ('density', np.float64),
             ('volume', np.float64),
             ('flux', np.float64, (len(self._flux),)),
+            ('power_density', np.float64),
+            ('fission_density', np.float64),
+            ('burnup', np.float64),
             ('default_lib', 'S6'),
             ('thermal_libs', 'S20', (num_therm,)),
             ('atom_fractions', np.float64, (num_iso,)),
             ('iso_data', iso_dtype, (num_iso,))]
         # Now assign these values
         iso_vals = [None] * num_iso
-        for i, iso in enumerate(self._isotopes):
+        for i in range(self.num_isotopes):
+            iso = self.isotope_obj(i)
             iso_vals[i] = (iso.name, iso.is_depleting, iso.xs_library)
         vals = \
             [(self._id, self._is_depleting, self._status, self.num_copies,
              self._density, vol, self._flux,
+             self._power_density, self._fission_density, self._burnup,
              self._default_xs_library, xslibs, self._atom_fractions,
              iso_vals)]
         data = np.array(vals, dtype=np.dtype(struct))
@@ -995,6 +1067,9 @@ class Material(object):
             volume = None
         flux = data['flux'][0]
         num_groups = flux.shape[0]
+        power_density = data['power_density'][0]
+        burnup = data['burnup'][0]
+        fission_density = data['fission_density'][0]
         default_xs_library = data['default_lib'][0].decode()
         thermal_xs_libraries = [s.decode() for s in data['thermal_libs'][0]]
         if thermal_xs_libraries == ['']:
@@ -1016,6 +1091,9 @@ class Material(object):
         # Set the attributes that are set after initialization
         this.flux = flux
         this.volume = volume
+        this.power_density = power_density
+        this.burnup = burnup
+        this.fission_density = fission_density
         # We will disreagrd isotopes_in_neutronics data since that will be
         # re-populated whenever the information is written to the neutronics
         # input
diff --git a/adder/mcnp/cell.py b/adder/mcnp/cell.py
index 0477e4b..ef97401 100644
--- a/adder/mcnp/cell.py
+++ b/adder/mcnp/cell.py
@@ -22,6 +22,9 @@ class Cell(object):
     ----------
     cell_id : int
         The cell's ID
+    parent_id: int
+        The parent cell's ID, from which the cell is duplicate.
+        None (default) corresponds to not duplicated cell
     material_id : int
         The id of the material in this cell
     density : float
@@ -44,6 +47,8 @@ class Cell(object):
         The type of fill, defaults to None
     fill_transforms : 3D Iterable of CoordTransform, or None, optional
         The id of the transform for each entry of the fill universe
+    initial_fill_transforms: 3D Iterable of CoordTransform, or None
+        The coordinate transform for the fill universe in the initial MCNP model
     fill_dims : 6-tuple of int, or None, optional
         if fill_type is "array", this is the index ranges in first z,
         y, and then x dimensions; defaults to None
@@ -67,6 +72,8 @@ class Cell(object):
         Volume of the region
     coord_transform : CoordTransform, optional
         The coordinate transform to apply to this cell; defaults to None
+    initial_coord_transform : CoordTransform, optional
+        The coordinate transform from the initial MCNP model; defaults to None
     universe_id : int
         The universe id of the region
     lattice : int
@@ -81,6 +88,8 @@ class Cell(object):
         The type of fill
     fill_transforms : 3D Iterable of CoordTransform, or None
         The id of the transform for each entry of the fill universe
+    initial_fill_transforms: 3D Iterable of CoordTransform, or None
+        The coordinate transform for the fill universe in the initial MCNP model
     fill_dims : 6-tuple of int, or None
         if fill_type is "array", this is the index ranges in first z,
         y, and then x dimensions
@@ -95,19 +104,31 @@ class Cell(object):
     def __init__(self, cell_id, material_id, density, surfaces, volume=None,
                  coord_transform=None, universe_id=ROOT_UNIV,
                  lattice=None, fill_ids=None, fill_type=None,
-                 fill_transforms=None, fill_dims=None,
-                 other_kwargs=OrderedDict()):
+                 fill_transforms=None, fill_dims=None, other_kwargs=OrderedDict(),
+                 parent_id=None):
         self.id = cell_id
+        self.parent_id=parent_id
         self.material_id = material_id
         self.material = None
         self.density = density
         self.surfaces = surfaces
         self.coord_transform = coord_transform
+        self.initial_coord_transform = coord_transform.clone(new_id=0) \
+            if coord_transform else None
         self.universe_id = universe_id
         self.lattice = lattice
         self.fill_type = fill_type
         self.fill_dims = fill_dims
         self.fill_transforms = fill_transforms
+        if (fill_transforms):
+            self.initial_fill_transforms = \
+                np.empty_like(fill_transforms).tolist()
+            for idz in range(len(fill_transforms)):
+                for idy in range(len(fill_transforms[idz])):
+                    for idx in range(len(fill_transforms[idz][idy])):
+                        ftr = self.fill_transforms[idz][idy][idx]
+                        self.initial_fill_transforms[idz][idy][idx] = \
+                            ftr.clone(new_id=0) if ftr else None
         self._fill = None
         self.fill_ids = fill_ids
         self.volume = volume
@@ -129,6 +150,21 @@ class Cell(object):
             self._id = id_
             Cell._USED_IDS.add(self._id)
 
+    @property
+    def parent_id(self):
+        return self._parent_id
+
+    @parent_id.setter
+    def parent_id(self, parent_id_):
+        if parent_id_ is not None:
+            check_type("parent_id", parent_id_, int)
+            check_greater_than("parent_id", parent_id_, 0, equality=False)
+            check_less_than("parent_id", parent_id_, CELL_MAX_ID, equality=True)
+            self._parent_id = parent_id_
+            Cell._USED_IDS.add(self._parent_id)
+        else:
+            self._parent_id = parent_id_
+
     @property
     def material(self):
         return self._material
@@ -333,10 +369,10 @@ class Cell(object):
                         if u not in [USE_LAT_IRREG, USE_LAT_MAT]:
                             statuses.append(u.status)
 
-        if np.all(np.asarray(statuses) == statuses[0]):
+        if np.all(np.asarray(statuses, dtype=int) == statuses[0]):
             return statuses[0]
         else:
-            msg = "Material and/or Universes of Cell {} do not have the" \
+            msg = "Material and/or Universes of Cell {} do not have the " \
                 "same status!"
             warn(msg.format(self.id))
 
@@ -495,7 +531,21 @@ class Cell(object):
                 for j in range(len(self.fill_transforms[k])):
                     for i in range(len(self.fill_transforms[k][j])):
                         if self.fill_transforms[k][j][i] == old_tr:
-                            self.fill_transforms[k][j][i] = new_tr
+                            self.fill_transforms[k][j][i] = new_tr  
+
+    def revert_fill_transforms(self, loc=None): 
+        # Reverts the fill_transforms attribute to initial_fill_transforms
+        if loc:
+            idz_range, idy_range, idx_range = ([loc[0]], [loc[1]], [loc[2]]) 
+        else:
+            Nx, Ny, Nz = np.array(self.fill_transforms).shape
+            idz_range, idy_range, idx_range = (range(Nz), range(Ny), range(Nx))
+        
+        for idz in idz_range:
+            for idy in idy_range:
+                for idx in idx_range:
+                    self.fill_transforms[idz][idy][idx] = \
+                        self.initial_fill_transforms[idz][idy][idx]
 
     def clone(self, depl_libs, model_univs, model_cells, model_mats):
         """Create a copy of this Cell with a new unique ID and new IDs
@@ -537,13 +587,17 @@ class Cell(object):
 
         # Now set the new id to be figured out by the setter
         cell_id = None
-
-        # Create the clone
+        if self.parent_id == None:
+            cell_parent_id = self.id
+        else:
+            cell_parent_id = self.parent_id
+        # Create the clone. None id creates a default id.
         clone = Cell(cell_id, material_id, density, surfaces, volume,
                      coord_transform, universe_id, lattice, fill_ids,
-                     fill_type, fill_transforms, fill_dims, other_kwargs)
+                     fill_type, fill_transforms, fill_dims, other_kwargs,
+                     cell_parent_id)
 
-        msg = "Cell {} cloned as {}".format(self.id, clone.id)
+        msg = "Cell {} cloned as {}".format(clone.parent_id, clone.id)
         logs = [("info_file", msg, None)]
         # Update the global cells
         model_cells[clone.id] = clone
diff --git a/adder/mcnp/constants.py b/adder/mcnp/constants.py
index 4ddf162..b5f3158 100644
--- a/adder/mcnp/constants.py
+++ b/adder/mcnp/constants.py
@@ -86,6 +86,9 @@ NOT_MAT_CARDS = ["mesh", "mgopt", "mode", "mphys", "mplot", "mx", "mp",
 
 # The tally id to use for ADDER-specific tallies
 ADDER_TALLY_ID = TALLY_MAX_ID - 10 + 1
+ADDER_USER_TALLY_ID = 10000000
+VALID_TALLY_TYPES = ["universe", "material", "unprocessed"]
+VALID_FCARD_TALLY_TYPES = ["cell", "surface", "point number", "no facet type assigned"]
 
 # The print tables that ADDER requires in MCNP output
 PRINT_TABLES = [60, 128, 130]
@@ -119,3 +122,5 @@ MAT_KW = ["gas", "estep", "hstep", "nlib", "plib", "pnlib", "elib", "hlib",
           "cond"]
 
 CELL_DENSITY_FMT = "{:.13E}"
+
+
diff --git a/adder/mcnp/coord_transform.py b/adder/mcnp/coord_transform.py
index dacc6b5..1c0c305 100644
--- a/adder/mcnp/coord_transform.py
+++ b/adder/mcnp/coord_transform.py
@@ -57,7 +57,8 @@ class CoordTransform(object):
     _USED_IDS = set([])
 
     def __init__(self, id_=None, displacement=None, rotation_angles=None,
-                 rotation_matrix=None, m_flag=True, in_degrees=False):
+                 rotation_matrix=None, m_flag=True, in_degrees=False, 
+                 matrix_notation="mcnp"):
         self.id = id_
         self.m_flag = m_flag
         self.displacement = displacement
@@ -75,20 +76,29 @@ class CoordTransform(object):
                 const = 1.  # No conversion
 
             # Now build the rotation matrices
-            alpha, beta, gamma = np.asarray(rotation_angles) * const
+            alpha, beta, gamma = np.asarray(rotation_angles, dtype=float) * const
             ca, sa = np.cos(alpha), np.sin(alpha)
             cb, sb = np.cos(beta), np.sin(beta)
             cg, sg = np.cos(gamma), np.sin(gamma)
 
+            	# Rotation matrix in "mcnp" matrix notation
             R = np.array([
-                [ca * cb, ca * sb * sg - sa * cg, ca * sb * cg + sa * sg],
-                [sa * cb, sa * sb * sg + ca * cg, sa * sb * cg - ca * sg],
-                [-sb, cb * sg, cb * cg]])
+                [ca * cb, sa * cb, -sb],
+                [ca * sb * sg - sa * cg, sa * sb * sg + ca * cg, cb * sg],
+                [ca * sb * cg + sa * sg, sa * sb * cg - ca * sg, cb * cg]])
+            
             # It is very likely for there to be values very nearly 0 (6e-17)
             # after the sin/cos. Just set them to zero
-            R[np.abs(R) < 5. * np.finfo(np.float).eps] = 0.
+            R[np.abs(R) < 5. * np.finfo(np.float64).eps] = 0.
             self._rotation_matrix = R
         else:
+            # Transpose of "common" matrix and check matrix notation
+            if matrix_notation=="common":
+                rotation_matrix=np.transpose(rotation_matrix)
+            elif matrix_notation!="common" and matrix_notation!="mcnp":  
+                msg="matrix_notation parameter \""+matrix_notation+ \
+                    "\" is wrong!" + " Use mcnp or common."
+                raise ValueError(msg)
             self.set_rotation_matrix(rotation_matrix, in_degrees)
 
     def __del__(self):
@@ -166,7 +176,7 @@ class CoordTransform(object):
             # Convert from degrees, if needed
             if in_degrees:
                 matrix = np.cos(matrix * np.pi / 180.)
-            matrix[np.abs(matrix) < 5. * np.finfo(np.float).eps] = 0.
+            matrix[np.abs(matrix) < 5. * np.finfo(np.float64).eps] = 0.
             # Now we can make an ndarray out of it and store, ensuring
             # it is a float64
             self._rotation_matrix = np.array(matrix, dtype=np.float64)
@@ -280,9 +290,9 @@ class CoordTransform(object):
         # Update displacement vector
         mod.displacement += that.displacement
 
-        # Update rotation matrix
-        mod.set_rotation_matrix(np.matmul(that.rotation_matrix,
-                                          mod.rotation_matrix), False)
+        # Update rotation matrix in MCNP matrix notation
+        mod.set_rotation_matrix(np.matmul(mod.rotation_matrix,
+                                          that.rotation_matrix), False)
 
         return mod
 
diff --git a/adder/mcnp/input_methods.py b/adder/mcnp/input_methods.py
index 101641a..acc65cf 100644
--- a/adder/mcnp/input_methods.py
+++ b/adder/mcnp/input_methods.py
@@ -12,6 +12,8 @@ from .coord_transform import CoordTransform
 from .input_utils import *
 from .sim_settings import SimSettings
 from .surface import Surface
+from .tally import Tally
+from adder.mcnp.tally import *
 
 # Note on lacking features:
 # This tool does not support:
@@ -20,11 +22,10 @@ from .surface import Surface
 
 
 def get_tallies(data_block):
-    """Obtain cards of tallies present in the input.
+    """Create new tallies objects, according to tally cards defined in the MCNP input.
 
-    No processing or extraction of information from these tally cards is
-    done; this method simply finds tallies and pulls them out of
-    data_block.
+    Here, extraction of information from the tally cards is
+    done.
 
     Parameters
     ----------
@@ -33,7 +34,7 @@ def get_tallies(data_block):
 
     Returns
     -------
-    List of str:
+    List of tally objects:
         Tally cards
     List of str:
         Remaining cards
@@ -45,11 +46,15 @@ def get_tallies(data_block):
         multipliers
     """
 
-    tally_cards = []
+    tally_dict = {}
+    default_tally_cards = {}
+    id_to_tally_cards = {}
+    tmesh_card = []
     other_cards = []
     multiplier_mat_ids = set()
     max_tally_id = 0
     active_tmesh_block = False
+    tally = Tally(id=TALLY_MAX_ID)
     for line in data_block:
         found_it = False
         # See if this line starts with any of our tally card identifiers
@@ -59,7 +64,8 @@ def get_tallies(data_block):
                 # This means we have the start of this tally type
                 # Also store it
                 found_it = True
-                tally_cards.append(line)
+                # add tmesh
+                tmesh_card.append(line)
                 # But we also should denote that this is an
                 # active tmesh block so that we store all others
                 # until we find the end of the tmesh block
@@ -71,7 +77,6 @@ def get_tallies(data_block):
                     # and sd* are possible, one is a tally, one isnt
                     if line.lower().startswith(key) and \
                         line[len(key)].isdigit():
-
                         # Then it is a tally
                         # Check if the tally ID is too large
                         # and if not, store the tally
@@ -87,6 +92,19 @@ def get_tallies(data_block):
                             # Remove the x/y/z
                             tally_dat = tally_dat[:-1]
                         tally_id = num_format(tally_dat[len(key):], 'int')
+                        tally_card = tally_dat[:len(key)].lower()
+                        # add default tally card and break
+                        if tally_id == 0:
+                            default_tally_cards[tally_card] = (
+                                line[len(tally_dat):]
+                            )
+                            found_it = True
+                            break
+                        # list of tally cards linked to tally ids
+                        if tally_id in id_to_tally_cards.keys():
+                            id_to_tally_cards[tally_id].append(tally_card)
+                        else:
+                            id_to_tally_cards[tally_id] = [tally_card]
                         if max_tally_id < tally_id:
                             max_tally_id = tally_id
                         if tally_id >= ADDER_TALLY_ID:
@@ -96,13 +114,49 @@ def get_tallies(data_block):
                             msg += "{}".format(ADDER_TALLY_ID - 1) + \
                                    "must be reduced "
                             raise ValueError(msg)
-                        tally_cards.append(line)
-                        found_it = True
 
-                        # Before we quit, lets analyze any FM cards to
-                        # see what multiplier material ids are used
-                        if key == "fm":
+                        # Creating and updating tally object to append to tally_cards_list. Each card type is assigned.
+                        # other_cards refers to the tally card types that don't require processing (En, Tn, FQn,
+                        # DEn, DFn, EMn, TMn, Fun/TALLYX, Fn, DDn, DXT, FTn, SPDTL)
+                        if key == "f":
+                            f_card_s = " ".join(line.split(" ")[1:])
+                            tally_dict = update_tally_dict(
+                                tally_id, "f_card", f_card_s, tally_dict
+                            )
+                            # get tracking particle, i.e. n, p, e or others.
+                            particles = (
+                                line.lower()
+                                .split(" ")[0]
+                                .split(":")[1]
+                                .split(",")
+                            )
+                            tally_dict[tally_id].particles = particles
+                        elif key == "fmesh":
+                            tally_dict = update_tally_dict(
+                                tally_id, "fmesh_card", line, tally_dict
+                            )
+                        elif key == "fc":
+                            tally_dict = update_tally_dict(
+                                tally_id, "fc_card", line, tally_dict
+                            )
+                        elif key == "cf":
+                            tally_dict = update_tally_dict(
+                                tally_id, "cf_card", line, tally_dict
+                            )
+                        elif key == "fm":
+                            # remove 'fm' or 'FM' followed by numbers & any extra space
+                            fm_line = re.sub(r'\bfm\d+\b|\bFM\d+\b', '', line)
+                            fm_line = re.sub(r'\s+', ' ', fm_line).strip()
                             multiplier_mat_ids.update(_analyze_fm_card(line))
+                            tally_dict = update_tally_dict(
+                                tally_id, "fm_card", fm_line, tally_dict
+                            )
+                        else:
+                            tally_dict = update_tally_dict(
+                                tally_id, "other_cards", line, tally_dict
+                            )
+
+                        found_it = True
                         break
 
             # Now if we got here and found_it is still false, then we
@@ -113,11 +167,30 @@ def get_tallies(data_block):
             # If we are here then we are in the midst of an active
             # tmesh block, and so we store all cards within the block
             # as tallies and have to check to see when the block ends
-            tally_cards.append(line)
+            tmesh_card.append(line)
             if line.lower().startswith(TMESH_CARDS[1]):
                 active_tmesh_block = False
 
-    return tally_cards, other_cards, max_tally_id, multiplier_mat_ids
+    # add default tally cards to user tallies, if not defined for tally n
+    for tally_card in default_tally_cards.keys():
+        for tally_id in id_to_tally_cards.keys():
+            if (
+                    "fmesh" in id_to_tally_cards[tally_id] and
+                    tally_card not in ["de", "df", "fc", "fm", "tr"]
+            ):
+                pass
+            elif tally_card not in id_to_tally_cards[tally_id]:
+                line = (
+                    tally_card + str(tally_id) +
+                    default_tally_cards[tally_card]
+                )
+                tally_dict = update_tally_dict(
+                    tally_id, "other_cards", line, tally_dict
+                )
+
+    tally_cards = list(tally_dict.values())
+
+    return tally_cards, tmesh_card, other_cards, max_tally_id, multiplier_mat_ids
 
 
 def get_output(data_block):
@@ -876,7 +949,14 @@ def convert_density(m_data, density):
             nucs.append(nuc)
             nuc_density_types.append("ao")
             nuc_densities.append(fraction)
-            numerator += fraction * adder.data.atomic_mass(nuc)
+            try:
+                numerator += fraction * adder.data.atomic_mass(nuc)
+            except TypeError:
+                element = re.match(r"([a-zA-Z]+)", nuc).group(1)
+                raise ValueError("Check metastable state for element '{}' "
+                                 "in MCNP input, as ADDER can't handle "
+                                 "ZAID of nuclides with metastable state "
+                                 "higher than 1.".format(element))
             denominator += fraction
         elif fraction < 0.:
             nucs.append(nuc)
@@ -921,7 +1001,7 @@ def convert_density(m_data, density):
     for n, nuc in enumerate(nucs):
         revised_m_data.append((nuc, nuc_fractions[n], m_data[n][-1]))
     # And add in the zero fraction isotopes in case they have meaning in
-    # the future [as an example of meaning, this may be a way to have the user
+    # the future [as example of meaning, this may be a way to have the user
     # input specific isotopes they wish to have new depletion library xs
     # gathered]
     for nuc, m_data_val in zero_frac_nuc_data:
@@ -1111,8 +1191,10 @@ def update_materials(universes, allowed_isotopes, materials,
         data = "m{}".format(mat_id)
         zaids_to_write = []
         fracs_to_write = []
-        for iso, frac, to_print in zip(mat.isotopes, mat.atom_fractions,
-                                       mat.isotopes_in_neutronics):
+        for i in range(mat.num_isotopes):
+            iso = mat.isotope_obj(i)
+            frac = mat.atom_fractions[i]
+            to_print = mat.isotopes_in_neutronics[i]
             zaid = _zam_to_mcnp(iso.Z, iso.A, iso.M, iso.xs_library)
             if to_print and frac > 0.:
                 zaids_to_write.append(zaid)
@@ -1152,8 +1234,10 @@ def update_materials(universes, allowed_isotopes, materials,
         data = "m{}".format(mat.id)
         zaids_to_write = []
         fracs_to_write = []
-        for iso, frac, to_print in zip(mat.isotopes, mat.atom_fractions,
-                                       mat.isotopes_in_neutronics):
+        for i in range(mat.num_isotopes):
+            iso = mat.isotope_obj(i)
+            frac = mat.atom_fractions[i]
+            to_print = mat.isotopes_in_neutronics[i]
             zaid = _zam_to_mcnp(iso.Z, iso.A, iso.M, iso.xs_library)
             if zaid in allowed_isotopes and to_print and frac > 0.:
                 zaids_to_write.append(zaid)
@@ -1222,7 +1306,7 @@ def create_material_flux_tallies(universes, depl_libs):
     cards.append(e4)
     cards.append("FC{} Flux tally for depletion".format(t_id))
 
-    return cards
+    return cards, t_id
 
 
 def create_rxn_rate_tallies(universes, allowed_isotopes, isos_and_rxn_keys,
@@ -1265,6 +1349,7 @@ def create_rxn_rate_tallies(universes, allowed_isotopes, isos_and_rxn_keys,
     # using a single tally with every isotope, rxn rate, and cell)
 
     model_cells = universes[ROOT_UNIV].nested_cells
+    tally_ids=[]
 
     # In the following loop we will determine the reactions we need to
     # tally from MCNP as well as gather the list of *all* isotopes for
@@ -1289,7 +1374,8 @@ def create_rxn_rate_tallies(universes, allowed_isotopes, isos_and_rxn_keys,
             continue
         rxn_keys = []
         rxn_strs = []
-        for key in xs_lib.keys():
+        for idx in range(xs_lib.num_types):
+            key = xs_lib.get_type_by_idx(idx)
             if key in MCNP_RXN_TALLY_IDS:
                 rxn_keys.append(key)
                 rxn_strs.append(
@@ -1318,7 +1404,8 @@ def create_rxn_rate_tallies(universes, allowed_isotopes, isos_and_rxn_keys,
 
         # Now only act on those materials we need to deplete
         if mat.is_depleting and not mat.is_default_depletion_library:
-            for i, iso in enumerate(mat.isotopes):
+            for i in range(mat.num_isotopes):
+                iso = mat.isotope_obj(i)
                 # Skip any isotopes that are not depleting, not in the neut
                 # model, and not in the library
                 if not iso.is_depleting or not mat.isotopes_in_neutronics[i]:
@@ -1413,13 +1500,14 @@ def create_rxn_rate_tallies(universes, allowed_isotopes, isos_and_rxn_keys,
             tally_map_mult_bins.append((iso_name, bin_ids))
         tally_map[t_id] = (cell_set, tally_map_mult_bins)
         tally_cards.append(fm4)
+        tally_ids.append(t_id)
 
     # So now we have the pseudo mat cards printed, the tally energy cards
     # printed, and the tally cards. We also have the map of where to find
     # the tally data as well.
 
     # At this stage we are set to return our results
-    return tally_cards, tally_map, isos_and_rxn_keys
+    return tally_ids, tally_cards, tally_map, isos_and_rxn_keys
 
 
 def create_output(user_output=None):
@@ -1537,14 +1625,24 @@ def _analyze_fm_card(line):
 
     # Now we need to extract the material id from each bin set
     for i in range(len(bin_sets)):
-        # Pull off the first two values from the bin data
-        bin_data = bin_sets[i].split(maxsplit=2)
+        # Split the string to get all bin data entries
+        bin_data = bin_sets[i].split(maxsplit=-1)
+        
         # The only type of bin set that does not have a material id is
         # the special multiplier set: "c k". This also happens to be the
         # only bin set type that has < 3 values and so we can use that
         # to discriminate (this is also the reason we use maxsplit=2)
         if len(bin_data) > 2:
-            # Then this has a material, store its id
-            mat_ids.add(num_format(bin_data[1], 'int'))
+            # Distinguish between multiplier and attenuator set
+            # to store material id
+            if bin_data[1]!='-1':
+                # take material id from multiplier set
+                mat_ids.add(num_format(bin_data[1], 'int'))             
+            elif bin_data[1]=='-1': 
+                # get the number of materials used by attenuator set
+                # and take their material ids
+                n_mats_att=int((len(bin_data)-2)/2)
+                for j in range(n_mats_att):
+                        mat_ids.add(num_format(bin_data[2*(1+j)], 'int')) 
 
     return mat_ids
diff --git a/adder/mcnp/input_utils.py b/adder/mcnp/input_utils.py
index dffb10b..e70b9eb 100644
--- a/adder/mcnp/input_utils.py
+++ b/adder/mcnp/input_utils.py
@@ -106,8 +106,8 @@ def split_data_and_keywords(input_params, allowed_keywords):
         if len(splits) == 1:
             # Then we had no equal, we split on space(s)
             splits = key_values.split(maxsplit=1)
-        key = splits[0]
-        value = splits[1]
+        key = splits[0].strip()
+        value = splits[1].strip()
         keywords[key] = value
     return data, keywords
 
@@ -202,7 +202,7 @@ def expand_jumps(values):
         # We either have #j or j
         if len(value) > 1:
             # Then we *may* have #j
-            if value[:-1].isdigit() and value[-1] == "j":
+            if value[:-1].isdigit() and value[-1] in ["j", "J"]:
                 # This is a #j!
                 num_jumps = num_format(value[:-1], 'int')
                 for j in range(num_jumps):
@@ -323,17 +323,35 @@ def combine_lines(block):
     i = 0
     while i < len(reduced_block):
         this_line = reduced_block[i]
+
         if this_line.rstrip().endswith(CONTINUATION):
-            # Then this line is a continuation, so we want to store
-            # this line and the next line as one
-            if i == len(reduced_block) - 1:
-                # Then there is no next line so raise this as an error
-                raise ValueError("Line continuation detected at the "
-                                 "end of a block!")
-            reduced_block_again.append(" ".join(
-                [this_line[:this_line.index(CONTINUATION)],
-                 reduced_block[i + 1].lstrip()]))
-            i += 2
+            line_continuation = True
+            reduced_line = this_line[:this_line.index(CONTINUATION)]
+
+            # Continue to read and process lines until one without a
+            # continuation character is found
+            while line_continuation:
+
+                if i == len(reduced_block) - 1:
+                    # Then there is no next line so raise this as an error
+                    raise ValueError("Line continuation detected at the "
+                                     "end of a block!")
+
+                i += 1
+                this_line = reduced_block[i]
+
+                if this_line.rstrip().endswith(CONTINUATION):
+                    reduced_line += (" " +
+                                     this_line[:this_line.index(CONTINUATION)])
+                    line_continuation = True
+                else:
+                    reduced_line += " " + this_line
+                    line_continuation = False
+
+            # Store the processed line
+            reduced_block_again.append(reduced_line)
+            i += 1
+
         else:
             # just store this line
             reduced_block_again.append(this_line.lstrip())
diff --git a/adder/mcnp/mcnp_neutronics.py b/adder/mcnp/mcnp_neutronics.py
index 38d6e90..0afbac3 100644
--- a/adder/mcnp/mcnp_neutronics.py
+++ b/adder/mcnp/mcnp_neutronics.py
@@ -5,20 +5,27 @@ import os
 import glob
 import copy
 import re
+from itertools import product
 
 import numpy as np
 
-from adder.isotope import update_isotope_depleting_status
+import adder.isotope
 from adder.material import Material
 from adder.neutronics import Neutronics
 from adder.constants import *
 from adder.type_checker import *
+from adder.mcnp.tally import *
 from adder.utils import get_transform_args
+from adder.data import get_metadata
+from adder.loggedclass import LoggedClass
+logger = LoggedClass(0, __name__)
+_INDENT = 2
+from .tally import Tally
 
 from . import input_methods
-from . import input_utils
 from . import initialize_data
 from . import output_methods
+from . import input_utils
 from .cell import Cell
 from .constants import MAX_LINE_LEN, TALLY_MAX_ID, MATL_MAX_ID, ROOT_UNIV, \
     NEWLINE_COMMENT, MCNP_OUT_SUFFIX, MCNP_OUT_NAMES, MCNP_FF_SUFFIX, CI_995, \
@@ -79,6 +86,9 @@ class McnpNeutronics(Neutronics):
         Whether or not to use the depletion library's cross sections
     base_input : None or OrderedDict
         The contents of the base input neutronics solver file.
+    user_tallies_d: dict
+        The user tally dict (key is tally id) get by filtering the original MCNP input tallies
+        with the ones selected in the ADDER input.
     inputs : Iterable of OrderedDict
         The input files produced at each time; the dimension of the
         iterable is the time index, and the dictionary contains the
@@ -111,6 +121,13 @@ class McnpNeutronics(Neutronics):
     VALID_SHUFFLE_TYPES = ("material", "universe")
     VALID_TRANSFORM_TYPES = ("universe", "cell", "surface")
 
+    def __init__(self, mpi_cmd, exec_cmd, base_input_filename, num_threads,
+                 num_procs, use_depletion_library_xs, reactivity_threshold,
+                 reactivity_threshold_initial):
+        super().__init__(mpi_cmd, exec_cmd, base_input_filename, num_threads, num_procs, use_depletion_library_xs,
+                         reactivity_threshold, reactivity_threshold_initial)
+
+
     @property
     def solver(self):
         return "mcnp"
@@ -230,7 +247,7 @@ class McnpNeutronics(Neutronics):
         # the univ/mat is not in the root universe, then it has a
         # status of supply
         root_univ_ids = [ROOT_UNIV] + \
-            self.universes[ROOT_UNIV].nested_universe_ids
+                        self.universes[ROOT_UNIV].nested_universe_ids
         for univ_id, univ in self.universes.items():
             if univ_id in root_univ_ids:
                 univ.status = IN_CORE
@@ -238,52 +255,285 @@ class McnpNeutronics(Neutronics):
                 univ.status = SUPPLY
 
         self._rxn_rate_tally_map = None
-        self._isos_and_rxn_keys = None   # This would need to be set back to 1
+        self._isos_and_rxn_keys = None  # This would need to be set back to 1
         # if somehow the isotopes in the depletion library change after
         # the first MCNP input is written w/ rxn rate tallies
 
-    def read_input(self, library_file, num_neutron_groups, user_mats_info,
-                   user_univ_info, shuffled_mats, shuffled_univs, depl_libs):
-        """Return parsed information about an MCNP input file, including
-        all the information needed to initialize adder.Material objects.
+    def process_user_tallies(self, user_tallies_adder_i, user_tallies_mcnp, tallies_ids):
+        """This method process user tallies considering the specification reported in
+        the ADDER input and user tallies defined in the MCNP input.
 
-        This method parses the given file to identify separate input
-        blocks, and gather pertinent cell and material information. All
-        comments will be removed and line continuations also removed.
+        Parameters
+        ----------
+        user_tallies_adder_i : dict
+            Dictionary containing specification in the adder input
+            under tally subsection
+        user_tallies_mcnp : dict
+            Dictionary contaning the information of the user tallies defined in
+            the MCNP input
 
-        Note the input file format is: an ordered dictionary of card
-        blocks (Lists of str) where the keys are: "message", "title",
-        "cell", "surface", "material", "tally", "output", and "other".
+        Returns
+        -------
+        tally_block: list
+        List of string containing the lines corresponding to the user tally
+        specification for the MCNP input
+        """
+
+
+        # set user tallies by filter orig. MCNP tallies as selected in ADDER input
+        if "user_tallies" not in self.__dir__():
+            self.user_tallies = {}
+            self.mats_ids_tally_cloned = set()
+            # change function to get user_tallies_process, user_tallies_to_copy
+            # get dictionary from and initialize user tally
+            self.user_tallies = {tally.id: tally for tally in user_tallies_mcnp}
+            self.ids_tally_proc = check_tally_ids(list(self.user_tallies.keys()),
+                                             list(user_tallies_adder_i.keys()))
+            self.ids_tally_copy = list(set(self.user_tallies.keys())-set(self.ids_tally_proc))
+            # assign tally type.
+            for tally_id in self.ids_tally_proc:
+                self.user_tallies[tally_id].type = user_tallies_adder_i[str(tally_id)]
+            # convert keys to string
+            keys_string = ', '.join([str(key) for key in user_tallies_adder_i.keys()])
+
+        # model cells, materials and their ids of the current mcnp geometry.
+        model_cells = self.universes[ROOT_UNIV].nested_cells
+        model_materials = self.universes[ROOT_UNIV].nested_materials
+        cell_ids = sorted(model_cells.keys())
+        material_ids = sorted(model_materials.keys())
+
+        # ids_list containing mcnp, adder and depletion tallies, and assign user_tallies
+        user_tallies_l = [self.user_tallies[key] for key in self.ids_tally_proc]
+        ids_list = [tally.id for tally in
+                    list(set(list(self.user_tallies.values()) + self.base_input["tally"]))]
+        ids_list.extend(tallies_ids)
+
+        """
+        cell_to_mat_map: mapping between cell and mat ids
+        model_*_map: mapping between children and parent ids for cells & mats
+        """
+        cell_to_mat_map = map_entities(model_cells, attr="material_id")
+        model_cells_map = map_entities(model_cells, attr="parent_id")
+        model_materials_map = map_entities(model_materials, attr="parent_id")
+
+        # initialize variable processed later
+        tally_block = ["c User tallies "]
+        # add tally as is to the block
+        for tally_id in self.ids_tally_copy:
+            tally_block.extend(self.user_tallies[tally_id].get_tally_block())
+        tally_user_clones_l = []
+        f_card_mat = ""
+        mats_ids_process = set()
+
+        for tally in user_tallies_l:
+            """
+            - entity group: entity is referred to a surface or a cell.
+                            Here, entity group is a group of cells or surfaces 
+                            as defined in the orig. mcnp input for Fn and CFn cards, 
+                            typically within parentheses. Below, their diff. forms: 
+                            * simple: Si, Ci,...
+                            * simple w/ parentheses: (Ci...Cn), (Si...Sn),... 
+                            * complex [rep. structure]: ((Si..Sn)<(Cm Cn[Ij..Ik])<(Cl Ck[Ij..Ik])...(Cp Co)),...
+                                where Si is surf or cell, Ci is cell
+            - entit_groups_l: list of entity groups, included in the tally
+                                line specification.
+            - tally_match: True if finding the match between all tally entity groups and 
+                            the entities in the mcnp geometry.
+                           False if at least one entity is not matched.
+            - tally_copy: True if finding match for parents and children ids 
+                          for all tally entity groups. In this case, a clone
+                          for the matching tally is generated.
+                          False if at least one entity is not matched
+            NB: if tally_copy is True, tally_match will be False and vice versa.
+                tally_match and tally_copy can be both False, and in this case 
+                no tally or clone is written in the generated mcnp input file.
+            NB2: entity types are "cell" or "surface", referring to the tally definition
+                through the mcnp syntax.
+                tally types are "universe" or "material", referring to the ADDER management
+                if universes or materials are processed
+            """
+
+            # assign entity type for f card processing
+            if tally.id_type == 4 or tally.id_type == 6 or tally.id_type == 7:
+                if tally.fmesh_card:
+                    tally_block.extend(tally.get_tally_block())
+                    continue
+                else:
+                    tally.entity_type_f_card = "cell"
+            else:
+                # in this case, tally not processed and just copied
+                tally.entity_type_f_card = "surface"
+                tally_block.extend(tally.get_tally_block())
+                continue
+
+            # dict., list to store and process tally clonation
+            # w/ Fn & CFn card. Set default match and copy to False
+            clone_entit_groups_d = {}
+            clone_entit_groups_cf_d = {}
+            tally_clones_l = []
+            tally_match, tally_copy = False, False
+            tally_match_cf, tally_copy_cf = False, False
+
+            # processing universe tally type
+            if tally.type == "universe":
+
+                # analyze and match identity groups for Fn and CFn cards
+                # Fn parsing
+                f_entit_groups_l = card_entities_parsing(tally.f_card)
+                # CFn card parsing
+                if tally.cf_card:
+                    cf_card = tally.cf_card
+                    cf_cells = ' '.join(cf_card.split()[1:])
+                    cf_entit_groups_l = card_entities_parsing(cf_cells)
+                else:
+                    cf_entit_groups_l = []
+
+                # tally match with Fn and CFn card
+                tally_match, tally_copy, clone_entit_groups_d = tally.analyze_entity_groups(f_entit_groups_l,
+                                                                                      model_cells_map, model_cells,
+                                                                                            tally, fcheck=True)
+                tally_match_cf, tally_copy_cf, clone_entit_groups_cf_d = tally.analyze_entity_groups(cf_entit_groups_l,
+                                                                                               model_cells_map,
+                                                                                                model_cells, tally,
+                                                                                                     fcheck=False)
+
+            # processing material tally type
+            elif tally.type == "material":
+
+                # the process requires assignment of tally to materials
+                # through the f_card_mat attribute, and changing f_card
+                # attribute accordingly
+                f_card, f_card_mat = tally.f_card, tally.f_card_mat
+
+                # tally not assigned to f_card_mat have just cells associated
+                # by the user in the original input
+                if not f_card_mat:
+
+                    # get f_card_mat and materials tally from f_card
+                    f_card_mat = substit_f_card(f_card, convert_map_to_int(cell_to_mat_map))
+                    # extract set of materials
+                    # Regular expression to match numbers not within square brackets
+                    pattern = r'(?<!\[)(?<!\d)(\b\d+\b)(?!\d)(?!\])'
+                    # Use re.findall to extract all matching numbers as strings
+                    numbers = re.findall(pattern, f_card_mat)
+                    # Convert the list of strings to a set of integers
+                    mats_ids = {int(num) for num in numbers}
+                    mats_ids_process.update(mats_ids)
+
+                    # tally is duplicate if not already duplicated,
+                    # and assigned to mats filling the cell to which the original f_card is referring
+                    tally_match, tally_copy, tally_clone, ids_list = tally.create_tally_clone_mat(tally.id + 10,
+                                                                                            ids_list, f_card_mat,
+                                                                                            user_tallies_l,
+                                                                                            mats_ids,
+                                                                                            self.mats_ids_tally_cloned)
+
+                    # extend to tally block and append to clone if cloned. There's no need to check if
+                    # match w/ mats at this depl. step, since it's cloned from cells filled w/ these
+                    # materials
+                    if tally_copy:
+                        tally_block.extend(tally_clone.get_tally_block())
+                        tally_user_clones_l.append(tally_clone)
+                        continue
+
+                else:
+                    # here, check for an already duplicated tally
+                    f_entit_groups_l = card_entities_parsing(tally.f_card_mat)
+                    tally_match, tally_copy, clone_entit_groups_d = tally.analyze_entity_groups(f_entit_groups_l,
+                                                                                          model_materials_map,
+                                                                                          model_cells, tally,
+                                                                                                fcheck=True)
+
+
+
+            """
+            Process. and generat. tally clones from clone_entit_groups_d dictionary.
+            """
+            if tally_copy:
+                # creating tally clone list
+                ids_list, tally_clones_l = tally.create_tally_clone_l(clone_entit_groups_d, user_tallies_l,
+                                                                ids_list)
+
+                # update cf card for clones of universe type tallies.
+                if clone_entit_groups_cf_d != {}:
+                    tally_clones_l = tally.update_cf_card(tally_match, tally_copy, tally_match_cf,
+                                                    tally_copy_cf, clone_entit_groups_cf_d, tally_clones_l)
+
+                # extend tally block for new tally clones
+                if tally_clones_l:
+                    # update fm clone card before printing tally block
+                    for tally_cl in tally_clones_l:
+                        logger.log("info_file",
+                                   f"Tally {tally.id} cloned as tally {tally_cl.id}", 10)
+                        if tally_cl.fm_card:
+                            tally_cl.check_fm_card(cell_to_mat_map, model_materials_map)
+
+                    # extend tally block to include tally_clones
+                    [tally_block.extend(tally_cl.get_tally_block()) for tally_cl in tally_clones_l]
+
+                    # add current tally clones to user tally clones
+                    tally_user_clones_l.extend(tally_clones_l.copy())
+
+            """
+            Processing match between existing tallies. The latter don't include 
+            new clones, but tallies from the orig. mcnp input or "old" clones.
+            """
+            if tally_match or tally.type == "unprocessed":
+                # update f_card, considering cells filled by mats in f_card_mat
+                if tally.type == "material":
+                    tally.f_card = substit_f_card(f_card_mat, convert_map_to_int(inverse_map_cells(cell_to_mat_map)))
+
+                tally_block.extend(tally.get_tally_block())
+
+            """
+            Pass no match between all tally entities & cells/mats
+            """
+            if not (tally_match and tally_copy):
+                tally.tally_block = []
+                tally.facet_ids = []
+                tally.tally_matrix = np.array([])
+                tally.tally_matrix_err = np.array([])
+                pass
+
+        # include clones in tally list
+        for tally_user_clone in tally_user_clones_l.copy():
+            self.user_tallies[tally_user_clone.id] = tally_user_clone
+            self.ids_tally_proc.append(tally_user_clone.id)
+
+        # update mats set for materials cloned with mats just processed
+        self.mats_ids_tally_cloned.update(mats_ids_process)
+
+        # include tally_block for tallies written in MCNP input.
+        if tally_block == ["c User tallies "]:
+            tally_block = []
+
+        return tally_block
+
+
+
+    def parse_library(self, library_data):
+        """Parses the neutronics library data for establishing the isotope
+        registry
 
         Parameters
         ----------
-        library_file : str
-            The filename and path to the xsdir file
-        num_neutron_groups : int
-            The number of energy groups
-        user_mats_info : OrderedDict
-            The keys are the ids in the neutronics solver and
-            the value is an OrderedDict of the name, depleting boolean,
-            ex_core_status, non_depleting_isotopes list, and
-            use_default_depletion_library flag.
-        user_univ_info : OrderedDict
-            The keys are the universe ids in the neutronics solver and
-            the value is an OrderedDict of the name.
-        shuffled_mats : set
-            The set of material names that are shuffled
-        shuffled_univs : set
-            The set of universe names that are shuffled
-        depl_libs : OrderedDict of DepletionLibrary
-            The depletion libraries in use in the model
+        library_data : str or None
+            The filename and path to the library data. If None, then it must
+            be obtained from the environment or input, depending on the solver.
 
         Returns
         -------
-        materials : Iterable of adder.Material
-            A Material object for each material in the model;
-            since no is_depleting (or isotope is_depleting) information is
-            available at this stage, this must be overwritten upstream.
+        neutronics_library_isos : dict
+            The keys are the isotope names in GND format and the values are an
+            Iterable of associated library names available in the neutronics
+            library
         """
 
+        # To properly process the xsdir data, we need to (1) see if we are
+        # supposed to get the xsdir from the messages header of the mcnp inp
+        # file, and (2) see if there are any XSn cards in the input that we
+        # need to be aware of.  So, lets just read it now and store the info
+        # for later
         filename = self.base_input_filename
 
         # Get the information from the input file
@@ -295,35 +545,123 @@ class McnpNeutronics(Neutronics):
         parsed_cells = input_methods.parse_cells(cell_block, parsed_transforms)
         m_data, m_default_nlib, mt_data, material_cards, other_cards = \
             input_methods.parse_materials(data)
-        tally_data, other_cards, max_tally_id, multiplier_mat_ids = \
+        tally_data, tmesh_card, other_cards, max_tally_id, multiplier_mat_ids = \
             input_methods.get_tallies(other_cards)
         output_data, other_cards = input_methods.get_output(other_cards)
         user_sim_settings, other_cards = \
             input_methods.get_sim_settings(other_cards)
 
-        # Handle xsdir information
+        self._input_data = messages, title, parsed_transforms, \
+            parsed_surfaces, parsed_cells, m_data, m_default_nlib, mt_data, \
+            material_cards, tally_data, max_tally_id, multiplier_mat_ids, \
+            output_data, user_sim_settings, tmesh_card, other_cards
+
         # See if there is an xsdir in the messages block
         message_xsdir = None
         for msg_line in messages:
             if "xsdir=" in msg_line:
                 message_xsdir = msg_line.split("xsdir=")[1].split()[0]
 
-        if library_file is None:
+        if library_data is None:
             # Either use message xsdir or the environment default
             if message_xsdir is not None:
                 self.xsdir_file = message_xsdir
             else:
                 self.xsdir_file = os.environ["DATAPATH"] + "/" + \
-                    _MCNP_XSDIR_FILENAME
+                                  _MCNP_XSDIR_FILENAME
         else:
             if message_xsdir is not None:
                 # Then we need to tell the user if the message xsdir
                 # conflicts
                 msg = "The MCNP input's MESSAGE block contains an xsdir " + \
-                    "file; this will be replaced with the " + \
-                    "'neutronics_library_file' provided in the ADDER input."
+                      "file; this will be replaced with the " + \
+                      "'neutronics_library_file' provided in the ADDER input."
                 self.log("INFO_FILE", msg)
-            self.xsdir_file = library_file
+            self.xsdir_file = library_data
+
+        # Get the information from our xsdir file
+        xs_updates, awtab_updates = input_methods.get_xs_awtab(other_cards)
+        self.neutronics_isotopes = \
+            initialize_data.parse_xsdir(self.xsdir_file, xs_updates,
+                                        awtab_updates)
+
+        # Finally lets create the desired return value
+        neutronics_library_isos = {}
+        for zaid in self.neutronics_isotopes.keys():
+            # Convert MCNP zaid.xyz* to an isotope name and lib name
+            index_separator = zaid.find(".")
+
+            if index_separator == -1:
+                msg = "xsdir contains data without a library identifier!"
+                raise ValueError(msg)
+
+            # Check to see if the prefix is for a zaid or s(a,b) library
+            library_prefix = zaid[:index_separator]
+            if library_prefix.isnumeric():
+                zaid_num = input_utils.num_format(library_prefix, 'int')
+                lib_name = zaid[index_separator + 1:]
+
+                iso_name, _, _, _, _ = \
+                    get_metadata(zaid_num, metastable_scheme="mcnp")
+
+                # Now include this in our data.
+                if iso_name in neutronics_library_isos:
+                    # Add lib_name to existing set
+                    neutronics_library_isos[iso_name].add(lib_name)
+                else:
+                    neutronics_library_isos[iso_name] = set([lib_name])
+
+        return neutronics_library_isos
+
+
+    def read_input(self, num_neutron_groups, user_mats_info, user_univ_info,
+                   shuffled_mats, shuffled_univs, depl_libs):
+        """Return parsed information about an MCNP input file, including
+        all the information needed to initialize adder.Material objects.
+
+        This method parses the given file to identify separate input
+        blocks, and gather pertinent cell and material information. All
+        comments will be removed and line continuations also removed.
+
+        Note the input file format is: an ordered dictionary of card
+        blocks (Lists of str) where the keys are: "message", "title",
+        "cell", "surface", "material", "tally", "output", and "other".
+
+        Parameters
+        ----------
+        num_neutron_groups : int
+            The number of energy groups
+        user_mats_info : OrderedDict
+            The keys are the ids in the neutronics solver and
+            the value is an OrderedDict of the name, depleting boolean,
+            volume, density, non_depleting_isotopes list, 
+            apply_reactivity_threshold_to_initial_inventory flag, and 
+            use_default_depletion_library flag.
+        user_univ_info : OrderedDict
+            The keys are the universe ids in the neutronics solver and
+            the value is an OrderedDict of the name.
+        shuffled_mats : set
+            The set of material names that are shuffled
+        shuffled_univs : set
+            The set of universe names that are shuffled
+        depl_libs : OrderedDict of DepletionLibrary
+            The depletion libraries in use in the model
+
+        Returns
+        -------
+        materials : Iterable of adder.Material
+            A Material object for each material in the model;
+            since no is_depleting (or isotope is_depleting) information is
+            available at this stage, this must be overwritten upstream.
+        """
+
+        messages, title, parsed_transforms, parsed_surfaces, parsed_cells, \
+            m_data, m_default_nlib, mt_data, material_cards, \
+            tally_data, max_tally_id, multiplier_mat_ids, \
+            output_data, user_sim_settings, tmesh_card, other_cards = \
+            self._input_data
+        # Lets not carry around input data anymore
+        del self._input_data
 
         # Now put the xsdir message in the message block
         if messages:
@@ -347,12 +685,6 @@ class McnpNeutronics(Neutronics):
             # Does not have anything, add
             messages.append("message: xsdir={}".format(self.xsdir_file))
 
-        # Get the information from our xsdir file
-        xs_updates, awtab_updates = input_methods.get_xs_awtab(other_cards)
-        self.neutronics_isotopes = \
-            initialize_data.parse_xsdir(self.xsdir_file, xs_updates,
-                                        awtab_updates)
-
         # Put all of our input data into an input dictionary
         input_cards = OrderedDict()
         input_cards["message"] = messages
@@ -360,6 +692,7 @@ class McnpNeutronics(Neutronics):
         input_cards["material"] = material_cards
         input_cards["tally"] = tally_data
         input_cards["output"] = output_data
+        input_cards["tmesh"] = tmesh_card
         input_cards["other"] = other_cards
         self.base_input = input_cards
         self.max_user_tally_id = max_tally_id
@@ -406,14 +739,16 @@ class McnpNeutronics(Neutronics):
             cell_densities = [self.cells[c_id].density for c_id in cell_ids]
 
             if len(cell_ids) > 0:
-                # We will initialize just the first one
-                density = cell_densities[0]
-                isotopic_data, new_cell_density = \
-                    input_methods.convert_density(data, density)
 
-                # But update all other cell densities after this conversion
-                for cell_id in cell_ids:
-                    self.cells[cell_id].density *= new_cell_density / density
+                # Set cell densities
+                for i, cell_id in enumerate(cell_ids):
+
+                    density = cell_densities[i]
+
+                    isotopic_data, new_cell_density = \
+                        input_methods.convert_density(data, density)
+
+                    self.cells[cell_id].density = new_cell_density
 
                 # Set to in-core, and we will have to let universe
                 # initialization assign correctly
@@ -439,8 +774,8 @@ class McnpNeutronics(Neutronics):
                 iso_name, fraction, nlib = isotopic_data[i]
                 if iso_name in iso_names:
                     msg = f"Material id: {mat_id} " \
-                        f"contains {iso_name} multiple times. " \
-                        "Only one entry is supported."
+                          f"contains {iso_name} multiple times. " \
+                          "Only one entry is supported."
                     self.log("ERROR", msg)
                 else:
                     iso_names.add(iso_name)
@@ -455,7 +790,7 @@ class McnpNeutronics(Neutronics):
                 density = self.cells[cell_ids[0]].density
                 volume = self.cells[cell_ids[0]].volume
             else:
-                density = 1.
+                density = 0.
                 volume = None
 
             depleting = True
@@ -480,13 +815,13 @@ class McnpNeutronics(Neutronics):
             # Since this is our initial input parsing, raise an error if the
             # material has isotopes that are not in the neutronics library
             for i in range(material.num_isotopes):
-                iso = material.isotopes[i]
+                iso = material.isotope_obj(i)
                 zaid = input_methods._zam_to_mcnp(
                     iso.Z, iso.A, iso.M, iso.xs_library)
                 if zaid not in self.neutronics_isotopes:
                     msg = f"Material {material.name} (id: {material.id}) " \
-                        f"contains {zaid} which is not present in the xsdir " \
-                        "file"
+                          f"contains {zaid} which is not present in the xsdir " \
+                          "file"
                     self.log("ERROR", msg)
 
             # If we are using the depletion library xs, then just set
@@ -512,16 +847,17 @@ class McnpNeutronics(Neutronics):
                 if len(user_mats_info[mat_id][key]) > 0:
                     # Then we have specific values
                     for i in range(material.num_isotopes):
-                        orig_iso = material.isotopes[i]
+                        orig_iso = material.isotope_obj(i)
+                        orig_iso_idx = material.isotopes[i]
                         if orig_iso.name in user_mats_info[mat_id][key]:
-                            new_iso = update_isotope_depleting_status(orig_iso,
-                                                                      False)
-                            material.isotopes[i] = new_iso
+                            material.isotopes[i] = \
+                                adder.isotope.ISO_REGISTRY.switch_iso_depleting_status(
+                                    orig_iso_idx, False)
 
                 # Now apply the reactivity_threshold_initial information
                 key = "apply_reactivity_threshold_to_initial_inventory"
                 if key in user_mats_info[mat_id] and \
-                    user_mats_info[mat_id][key] is not None:
+                        user_mats_info[mat_id][key] is not None:
                     mat_reactivity_threshold_initial = \
                         user_mats_info[mat_id][key]
                 else:
@@ -529,7 +865,7 @@ class McnpNeutronics(Neutronics):
                         self.reactivity_threshold_initial
             else:
                 mat_reactivity_threshold_initial = \
-                        self.reactivity_threshold_initial
+                    self.reactivity_threshold_initial
 
             material.establish_initial_isotopes(
                 mat_reactivity_threshold_initial)
@@ -548,14 +884,14 @@ class McnpNeutronics(Neutronics):
         # Now create the duplicate materials for the materials present
         # in multiple locations (if depleted or shuffled)
         self.log("info", "Cloning Depleting, Shuffled, or "
-                    "Cross-Universe Materials", 4)
+                         "Cross-Universe Materials", 4)
         Nmat = len(materials)
         for m in range(Nmat):
             mat = materials[m]
             mat_id = mat.id
             if mat_id in cell_ids_by_mat and len(cell_ids_by_mat[mat_id]) > 1:
                 if mat.is_depleting or mat.name in shuffled_mats or \
-                    len(univ_ids_by_mat[mat_id]) > 1:
+                        len(univ_ids_by_mat[mat_id]) > 1:
 
                     for c in cell_ids_by_mat[mat_id][1:]:
                         # Then we have multiple instances of a shuffled and/or
@@ -566,7 +902,11 @@ class McnpNeutronics(Neutronics):
                         msg = "Material {} cloned as material {}".format(
                             mat.name, new_mat.name)
                         self.log("info_file", msg)
-                        new_mat.density = self.cells[c].density
+                        if (mat.id in user_mats_info and 
+                            user_mats_info[mat.id]["density"] is not None):
+                            new_mat.density = user_mats_info[mat.id]["density"]
+                        else:
+                            new_mat.density = self.cells[c].density
                         if self.cells[c].volume:
                             new_mat.volume = self.cells[c].volume
                         self.cells[c].material_id = new_mat.id
@@ -625,6 +965,7 @@ class McnpNeutronics(Neutronics):
             for message in messages:
                 file_string += input_utils.card_format(message)
             file_string += "\nCONTINUE\n"
+            file_string += "\nCONTINUE\n"
 
         # Now just add in the modified kcode card
         file_string += input_utils.card_format(self.sim_settings.kcode_str)
@@ -632,10 +973,10 @@ class McnpNeutronics(Neutronics):
 
         with open(filename, "w") as file:
             file.write(file_string)
-
+    # insert tallies list
     def write_input(self, filename, label, materials, depl_libs, store_input,
-                    deplete_tallies, user_tallies, user_output,
-                    update_iso_status=True):
+                    deplete_tallies, user_tallies_adder_i, include_user_tallies,
+                    user_output, update_iso_status=True):
         """Updates the input for the particular run case
 
         Parameters
@@ -652,8 +993,12 @@ class McnpNeutronics(Neutronics):
             Whether or not to store the input file in :attrib:`inputs`
         deplete_tallies : bool
             Whether or not to write the tallies needed for depletion
-        user_tallies : bool
-            Whether or not to write the user tallies
+        user_tallies : dict
+            Dict of tally objects
+        user_tallies_adder_i : dictionary
+            Dictionary containing info from ADDER input
+        include_user_tallies : bool
+            Including or not user tallies in the input.
         user_output : bool
             Whether or not to write the user's output control cards
         update_iso_status : bool, optional
@@ -671,13 +1016,13 @@ class McnpNeutronics(Neutronics):
         messages = input_cards["message"]
         title = self.base_input["title"] + " " + label
         if len(title) > MAX_LINE_LEN:
-            title = self.base_input["title"][0:MAX_LINE_LEN - (len(label) + 6)]\
+            title = self.base_input["title"][0:MAX_LINE_LEN - (len(label) + 6)] \
                     + "[...] " + label
 
         model_mats = self.universes[ROOT_UNIV].nested_materials
         if update_iso_status:
             self.log("info_file",
-                    "Evaluating Which Isotopes to Include in MCNP Model", 10)
+                     "Evaluating Which Isotopes to Include in MCNP Model", 10)
             for mat_id, mat in model_mats.items():
                 mat = model_mats[mat_id]
                 # Update the isotopes in neutronics status
@@ -689,10 +1034,10 @@ class McnpNeutronics(Neutronics):
                     # isotopes carefully.
                     lib = depl_libs[mat.depl_lib_name]
                     mat.determine_important_isotopes(lib,
-                        self.reactivity_threshold)
+                                                     self.reactivity_threshold)
                     # Next only allow isotopes that we have MCNP libs for
                     for i in range(mat.num_isotopes):
-                        iso = mat.isotopes[i]
+                        iso = mat.isotope_obj(i)
                         if mat.isotopes_in_neutronics[i]:
                             zaid = input_methods._zam_to_mcnp(
                                 iso.Z, iso.A, iso.M, iso.xs_library)
@@ -700,37 +1045,45 @@ class McnpNeutronics(Neutronics):
                                 mat.isotopes_in_neutronics[i] = False
 
         self.log("info_file", "Preparing Tally Cards", 10)
-        tallies = []
+        tallies, tallies_ids = [], []
         # Add in the tallies that ADDER wants
         if deplete_tallies:
             # We are going to need the flux for the depletion, and
             # if needed, for normalizing the reaction rates, so lets get
             # that.
-            tallies.extend(
-                input_methods.create_material_flux_tallies(self.universes,
-                    depl_libs))
+            cards, t_id = input_methods.create_material_flux_tallies(self.universes, depl_libs)
+
+            tallies.extend(cards)
+            tallies_ids.append(t_id)
 
             if not self.use_depletion_library_xs:
                 # Now, if we are updating the depletion library, we
                 # also need to populate the tallies for the reaction
                 # rates of interest. Determine what these are, and add
                 # their tally cards.
-                rr_tallies, self._rxn_rate_tally_map, \
+                rr_tallies_ids, rr_tallies, self._rxn_rate_tally_map, \
                     self._isos_and_rxn_keys = \
-                        input_methods.create_rxn_rate_tallies(
-                            self.universes, self.neutronics_isotopes,
-                            self._isos_and_rxn_keys, depl_libs)
+                    input_methods.create_rxn_rate_tallies(
+                        self.universes, self.neutronics_isotopes,
+                        self._isos_and_rxn_keys, depl_libs)
                 # Store the tallies, and the unique cell sets for usage when
                 # getting results
                 tallies.extend(rr_tallies)
+                tallies_ids.extend(rr_tallies_ids)
+
+        # get tallies for fmesh
+        user_tallies_mcnp = self.base_input["tally"]
+        fmesh_block = []
+
+        # get tallies matching with the ones in [tallies] section in ADDER input.
+        if include_user_tallies:
+            user_tally_block = self.process_user_tallies(user_tallies_adder_i, user_tallies_mcnp, tallies_ids)
+            tallies.extend(user_tally_block)
 
-        # And put in the ones the user requested
-        # (these have already been verified to not have conflicting IDs with
-        #  the ADDER IDs)
-        if user_tallies:
-            # We have to use the tally card from the base input to get
-            # the user tallies, and not what ADDER has done to it since
-            tallies.extend(self.base_input["tally"])
+        # add tmesh block
+        tmesh_block = self.base_input["tmesh"]
+        if tmesh_block:
+            tallies.extend(tmesh_block)
 
         # Set the output cards while incorporating user output when needed
         if user_output:
@@ -742,8 +1095,8 @@ class McnpNeutronics(Neutronics):
 
         others = input_cards["other"]
 
-        # Get the materials in card form
-        if user_tallies:
+        # Get the materials multiplier ids
+        if user_tallies_adder_i:
             multiplier_mat_ids = self.multiplier_mat_ids
         else:
             multiplier_mat_ids = set()
@@ -761,28 +1114,28 @@ class McnpNeutronics(Neutronics):
             # The tallies array contains lines for each new pseudo-mat
             # but also one for the flux tally, so take that off
             num_mat_for_rxn_tallies = len(tallies) - 1
-            if user_tallies:
+            if include_user_tallies:
                 # Then we also should take this off.
                 num_mat_for_rxn_tallies -= len(self.base_input["tally"])
 
             if len(mat_cards) + num_mat_for_rxn_tallies > MATL_MAX_ID:
                 msg = "The number of materials in the model and the " + \
-                    "maximum number of pseudo-materials for reaction rate " + \
-                    "tallies exceeds the MCNP Material Limit of " + \
-                    "{};\n\t".format(MATL_MAX_ID) + \
-                    "Either reduce materials or set the " + \
-                    "`use_depletion_library_xs` to True in the input."
+                      "maximum number of pseudo-materials for reaction rate " + \
+                      "tallies exceeds the MCNP Material Limit of " + \
+                      "{};\n\t".format(MATL_MAX_ID) + \
+                      "Either reduce materials or set the " + \
+                      "`use_depletion_library_xs` to True in the input."
                 self.log("error", msg)
 
             # Also, now that we know the number of tallies, we can identify
             # possible tally ID collisions
-            if user_tallies:
+            if user_tallies_adder_i:
                 min_rr_t_id = min(self._rxn_rate_tally_map.keys()) + 10
                 if self.max_user_tally_id >= min_rr_t_id:
                     msg = "The user's tally IDs in the model conflict with the " + \
-                        "IDs used for reaction rate tallies. Please modify user " + \
-                        "tallies so the tally ID is less than " + \
-                        "{}".format(min_rr_t_id)
+                          "IDs used for reaction rate tallies. Please modify user " + \
+                          "tallies so the tally ID is less than " + \
+                          "{}".format(min_rr_t_id)
                     self.log("error", msg)
 
         # Now we can write the input
@@ -968,7 +1321,7 @@ class McnpNeutronics(Neutronics):
                 # Then this list is not empty, and thus there are rxn rates
                 self.log("info_file", "Obtaining Rxn Rates from MCTAL", 10)
                 output_methods._get_material_wise_rxn_rates(mctal, model_cells,
-                    flux, self._rxn_rate_tally_map, depl_libs)
+                                                            flux, self._rxn_rate_tally_map, depl_libs)
         # Clear the storage used by _rxn_rate_tally_map as it may be large and
         # we dont need that info anymore
         self._rxn_rate_tally_map = None
@@ -982,9 +1335,44 @@ class McnpNeutronics(Neutronics):
                     mat_id = cell.material_id
                     volumes[mat_id] = volumes_by_cell[cell.id]
 
+        # Get user tallies results
+        # Get tally ids list
+        if "user_tallies" in self.__dir__():
+            user_tallies_ids = self.user_tallies.keys()
+            user_tally_res = output_methods._get_user_tally_res(mctal, user_tallies_ids)
+            # update user tally res with tally inp. information
+            model_materials = self.universes[ROOT_UNIV].nested_materials
+            for tally_id in user_tally_res.keys():
+                facet_ids, material_names, universe_names = [], [], []
+                facet_type = self.user_tallies[tally_id].entity_type_f_card
+                if facet_type in ("cell", "surface"):
+                    for facet_id in user_tally_res[tally_id]["facet_ids"]:
+                        facet_ids.append(int(facet_id))
+                        if facet_type == "cell" and int(facet_id) != 0:
+                            cell = model_cells[int(facet_id)]
+                            #get mat and univ ids to get names
+                            mat_id, univ_id = cell.material_id, cell.universe_id
+                            material_names.append(model_materials[mat_id].name)
+                            universe_names.append(self.universes[univ_id].name)
+                        elif facet_type == "cell" and int(facet_id) == 0:
+                            mat_id, univ_id = 0, 0
+                            material_names.append("0")
+                            universe_names.append("0")
+                # update user_tally_res
+                user_tally_res[tally_id]["facet_ids"] = facet_ids
+                user_tally_res[tally_id]["material_names"] = material_names
+                user_tally_res[tally_id]["universe_names"] = universe_names
+
+
+
+
+
+        else:
+            user_tally_res = {}
+
         self.log("info_file", "Completed MCNP Post-Processing", 10)
 
-        return keff, keff_stddev, flux, nu, volumes
+        return keff, keff_stddev, flux, nu, volumes, user_tally_res
 
     def calc_volumes(self, materials, vol_data, target_unc, max_hist,
                      only_depleting):
@@ -1043,7 +1431,7 @@ class McnpNeutronics(Neutronics):
                                  vol_data["lower_left"])
             V_tot = deltas[0] * deltas[1] * deltas[2]
         elif vol_data["type"] == "cylinder":
-            V_tot = np.pi * vol_data["height"] * vol_data["radius"]**2
+            V_tot = np.pi * vol_data["height"] * vol_data["radius"] ** 2
 
         # Get the current version of the input
         if len(self.inputs) == 0:
@@ -1195,7 +1583,7 @@ class McnpNeutronics(Neutronics):
         shuffle_type : str
             The type of shuffle to perform; this depends on the actual
             neutronics solver type; this could be "material" or
-            "universe", for example.
+            "universe", example.
         materials : List of Material
             The materials to work with
         depl_libs : OrderedDict of DepletionLibrary
@@ -1258,6 +1646,11 @@ class McnpNeutronics(Neutronics):
         # (and also update our quick access dictionaries with it)
         if mat_by_name[mat_name].status == SUPPLY:
             orig_mat = mat_by_name[mat_name]
+            if not orig_mat.density or orig_mat.density == 0.0:
+                # Error: supply element without a density value assigned
+                msg = f"Supply material {orig_mat.name} was not assigned a " \
+                       "density in the ADDER input file"
+                self.log("error", msg)
             start_mat = orig_mat.clone(depl_libs)
             msg = "Material {} cloned as material {}".format(orig_mat.name,
                                                              start_mat.name)
@@ -1273,7 +1666,7 @@ class McnpNeutronics(Neutronics):
         for to_mat in to_mats:
             if mat_by_name[to_mat].status == SUPPLY:
                 msg = "Supply Materials can only be the first entry of a " \
-                    "shuffle (see Material {})".format(to_mat)
+                      "shuffle (see Material {})".format(to_mat)
                 self.log("error", msg)
 
         # mat_set now contains the names of the materials in this set
@@ -1312,7 +1705,7 @@ class McnpNeutronics(Neutronics):
             self.log("warning", msg)
         elif not np.allclose(volumes[0], volumes[1:], rtol=VOLUME_PRECISION):
             msg = "Material volumes within this shuffle set are not " + \
-                "within {}% of each other!".format(VOLUME_PRECISION * 100.)
+                  "within {}% of each other!".format(VOLUME_PRECISION * 100.)
             self.log("warning", msg)
 
         # Now we can step through and perform the actual move
@@ -1364,7 +1757,7 @@ class McnpNeutronics(Neutronics):
         for univ in univs_set:
             if univ not in self.universes:
                 msg = "Universe {} does not exist".format(univ) + \
-                    " and thus cannot be shuffled!"
+                      " and thus cannot be shuffled!"
                 self.log("error", msg)
 
             if univ == ROOT_UNIV:
@@ -1375,7 +1768,7 @@ class McnpNeutronics(Neutronics):
         start_univ = self.universes[univ_id]
         if start_univ.status == SUPPLY:
             start_univ = self.clone_universe(univ_id, depl_libs,
-                materials, new_status=IN_CORE)
+                                             materials, new_status=IN_CORE)
 
         start_id = start_univ.id
 
@@ -1386,7 +1779,7 @@ class McnpNeutronics(Neutronics):
         for t, to_univ in enumerate(to_univs):
             if self.universes[to_univ].status == SUPPLY:
                 msg = "Supply Universes can only be the first entry of a " \
-                    "shuffle (see Universe {})".format(to_univ_names[t])
+                      "shuffle (see Universe {})".format(to_univ_names[t])
                 self.log("error", msg)
 
         # Find the cells which own these universes (i.e., one level up)
@@ -1404,7 +1797,7 @@ class McnpNeutronics(Neutronics):
             # this universe as that would be non-mass-conserving.
             if len(cell_ids) > 1:
                 msg = "Cannot move a universe which is present in " \
-                    "multiple cells!"
+                      "multiple cells!"
                 self.log("error", msg)
             elif len(cell_ids) == 0:
                 univ_cells.append(None)
@@ -1439,16 +1832,50 @@ class McnpNeutronics(Neutronics):
             if cell_id is not None:
                 target_cell = self.cells[cell_id]
                 if target_cell.fill_type == "single":
+                    outbound_universe = target_cell.fill[0][0][0]
                     target_cell.fill[0][0][0] = self.universes[univ_set[i]]
                 elif target_cell.fill_type == "array":
+                    outbound_universe = target_cell.fill\
+                        [locs[j][0]][locs[j][1]][locs[j][2]]
                     target_cell.fill[locs[j][0]][locs[j][1]][locs[j][2]] = \
                         self.universes[univ_set[i]]
+                # This universe is in-core and needs to be set as such
+                self.universes[univ_set[i]].status = IN_CORE
+
+                # Check if the universe in the target cell was transformed,
+                # if it was, it is necessary to reset the fill_transforms
+                origin_universe = self.universes[univ_set[i]]
+                ask_for_new_tr = False
+                if outbound_universe.transform:  
+                    target_cell.revert_fill_transforms(locs[j])
+                    if target_cell.initial_fill_transforms\
+                            [locs[j][0]][locs[j][1]][locs[j][2]]:
+                        # If the initial fill transform exists (i.e., is not 
+                        # None), then I need a new transform ID
+                        ask_for_new_tr = True
+
+                if origin_universe.transform:
+                    # Re-applies the transformations of the origin universe
+                    # to this new location
+                    displacement = origin_universe.transform.displacement
+                    matrix = origin_universe.transform.rotation_matrix
+                    self._transform_universes([origin_universe.name],
+                                               None, None,
+                                               matrix, displacement, False)
+                elif ask_for_new_tr:
+                    # Necessary to get a unique ID out of the transform 
+                    # if it was reverted to its initial values but no transform
+                    # was applied
+                    self._transform_universes([origin_universe.name],
+                                               None, None,
+                                               None, None, False)
+                    
             else:
                 # Then this is going to storage
                 self.universes[univ_set[i]].status = STORAGE
 
     def clone_universe(self, u_id, depl_libs, model_mats, new_name=None,
-        new_status=None):
+                       new_status=None):
         """Create a copy of this Universe with a new unique ID and new
         IDs for all constituents, who are also cloned.
 
@@ -1493,7 +1920,8 @@ class McnpNeutronics(Neutronics):
             if num_cells_after_clone > num_cells_before_clone:
                 msg = "There are more cells in universe {} than the universe " \
                       "it was cloned from due to a lattice structure being " \
-                      "split up. The volumes for cells in universe {} should " \
+                      "split up. The volumes for cells in universe {} " \
+                      "and any user tallies should " \
                       "be checked.".format(clone.id, clone.id)
                 self.log("warning", msg)
 
@@ -1508,9 +1936,10 @@ class McnpNeutronics(Neutronics):
         return clone
 
     def geom_search(self, transform_type, axis, names, angle_units, k_target,
-                    bracket_interval, target_interval, uncertainty_fraction,
+                    bracket_interval, reference_position, target_interval,
+                    uncertainty_fraction,
                     initial_guess, min_active_batches, max_iterations,
-                    materials, case_idx, operation_idx, depl_libs):
+                    materials, case_idx, operation_idx, depl_libs, user_tallies_adder_i):
         """Performs a search of geometric transformations to identify that
         which yields the target k-eigenvalue within the specified interval.
 
@@ -1531,14 +1960,20 @@ class McnpNeutronics(Neutronics):
             The target k-eigenvalue to search for
         bracket_interval : Iterable of float
             The lower and upper end of the ranges to search.
+        reference_position: str or float
+            The reference point for the bracket_interval values.
+            'initial' denotes the initial position of the
+            control group in the neutronics input; whereas
+            'last' referes to the last known position of the
+            control group. If float, the value is the reference.
         target_interval : float
             The range around the k_target for which is considered success
         uncertainty_fraction : float
             This parameter sets the stochastic uncertainty to target when the
             initial computation of an iteration reveals that a viable solution
             may exist.
-        initial_guess : float
-            The starting point to search
+        initial_guess : float or str
+            The starting point to search. If "last", use last position
         min_active_batches : int
             The starting number of batches to run to ensure enough keff samples
             so that it follows the law of large numbers. This is the number of
@@ -1555,6 +1990,8 @@ class McnpNeutronics(Neutronics):
             The operation index, for printing
         depl_libs : OrderedDict of DepletionLibrary
             The depletion libraries in use in the model
+        user_tallies_adder_i : dict
+            User tallies in the ADDER input
 
         Returns
         -------
@@ -1582,7 +2019,7 @@ class McnpNeutronics(Neutronics):
             matrix = None
             this.transform(names, yaw, pitch, roll, angle_units, matrix,
                            displacement, transform_type,
-                           transform_in_place=False)
+                           transform_in_place=False, reset=False)
 
             # Swap out the sim settings data for the minimum case
             orig_sim_settings = this.sim_settings
@@ -1599,13 +2036,14 @@ class McnpNeutronics(Neutronics):
                 update_iso_status = True
             else:
                 update_iso_status = False
+            include_user_tallies = False
             this.write_input(inp_name, step_label, materials, depl_libs,
-                store_input, deplete_tallies, user_tallies, user_output,
-                update_iso_status)
+                             store_input, deplete_tallies, user_tallies_adder_i,
+                             include_user_tallies, user_output,update_iso_status)
             this._exec_solver(inp_name, fname, keep_runtpe=True)
-            keff, keff_stddev, _, _, _ = \
+            keff, keff_stddev, _, _, _, _ = \
                 this._read_results(fname, materials, depl_libs,
-                    deplete_tallies)
+                                   deplete_tallies)
 
             # Cleanup the files
             for out_type in MCNP_OUT_SUFFIX:
@@ -1639,10 +2077,15 @@ class McnpNeutronics(Neutronics):
                 new_active_batches = \
                     (min_sim_settings.batches - min_sim_settings.inactive) * \
                     (CI_95 * keff_stddev /
-                     (target_interval * uncertainty_fraction))**2
+                     (target_interval * uncertainty_fraction)) ** 2
+
+                # If statement to check number of active batches.
+                # Minimum fixed at 4, where MCNP starts to plot col/abs/tr-len keff
+                if new_active_batches < VALID_GEOM_SEARCH_MIN_ACTIVE_BATCHES:
+                    new_active_batches = VALID_GEOM_SEARCH_MIN_ACTIVE_BATCHES
 
                 new_batches = this.sim_settings.inactive + \
-                    round(new_active_batches)
+                              round(new_active_batches)
 
                 # Now re-run with this batch estimate
                 this.sim_settings.batches = new_batches
@@ -1651,9 +2094,9 @@ class McnpNeutronics(Neutronics):
                 this._exec_solver(inp_name, fname, is_continue=True)
                 os.remove(fname + "_runtpe")
 
-                keff, keff_stddev, _, _, _ = \
+                keff, keff_stddev, _, _, _, _ = \
                     this._read_results(fname, materials, depl_libs,
-                        deplete_tallies)
+                                       deplete_tallies)
 
                 # Cleanup all the files
                 for out_type in MCNP_OUT_SUFFIX:
@@ -1675,13 +2118,12 @@ class McnpNeutronics(Neutronics):
             yaw, pitch, roll, displacement = get_transform_args(-val, axis)
             this.transform(names, yaw, pitch, roll, angle_units, matrix,
                            displacement, transform_type,
-                           transform_in_place=False)
+                           transform_in_place=False, reset=False)
 
             return keff, keff_stddev
 
         # Save constants used for each case
         store_input = False
-        user_tallies = True
         user_output = True
         deplete_tallies = False
         iterations = 0
@@ -1690,7 +2132,7 @@ class McnpNeutronics(Neutronics):
         # of histories
         min_sim_settings = copy.deepcopy(self.sim_settings)
         min_sim_settings.batches = min_active_batches + \
-            min_sim_settings.inactive
+                                   min_sim_settings.inactive
 
         # First we need to evaluate the lower bracket point
         val_old = bracket_interval[0]
@@ -1757,7 +2199,8 @@ class McnpNeutronics(Neutronics):
         return converged, iterations, val_new, keff_new, keff_std_new
 
     def transform(self, names, yaw, pitch, roll, angle_units, matrix,
-                  displacement, transform_type, transform_in_place=False):
+                  displacement, transform_type, transform_in_place=False,
+                  matrix_notation="mcnp", reset=False):
         """Transforms the universe named `name` according to the angles in
         yaw, pitch, and roll and the translation in displacement.
 
@@ -1788,11 +2231,20 @@ class McnpNeutronics(Neutronics):
         transform_in_place : bool, optional
             If the existing transform should be updated (True) or a new
             transform created. Defaults to False.
+        matrix_notation : {"common", "mcnp"}
+            The notation used to define the rotation matrix. The matrix with
+            the MCNP notation corresponds to the transpose of the matrix defined
+            w/ the common mathematical notation ("common") to perform geometrical 
+            rotation. Default to common.
+        reset : bool
+            If True, the position of the entity is reset to the initial one 
+            provided in the MCNP base input file.
         """
 
         # Use the base class' type checking
         super().transform(names, yaw, pitch, roll, angle_units, matrix,
-                          displacement, transform_type, transform_in_place)
+                          displacement, transform_type, transform_in_place,
+                          matrix_notation=matrix_notation, reset=reset)
 
         # Now check the transform_type value
         check_value("transform_type", transform_type,
@@ -1806,26 +2258,59 @@ class McnpNeutronics(Neutronics):
             ypr = None
 
         if transform_type == "universe":
+            self._update_universe_transform(names, ypr, angle_units, matrix,
+                                            displacement, reset=reset)
             self._transform_universes(names, ypr, angle_units, matrix,
-                                      displacement, transform_in_place)
+                                      displacement, transform_in_place,
+                                      matrix_notation=matrix_notation,
+                                      reset=reset)
         elif transform_type == "cell":
             self._transform_cells(names, ypr, angle_units, matrix,
-                                  displacement, transform_in_place)
+                                  displacement, transform_in_place,
+                                  matrix_notation=matrix_notation,
+                                  reset=reset)
         elif transform_type == "surface":
             self._transform_surfaces(names, ypr, angle_units, matrix,
-                                     displacement, transform_in_place)
+                                     displacement, transform_in_place,
+                                     matrix_notation=matrix_notation,
+                                     reset=reset)
 
         # Now we have to merge and clean all of our transforms so the IDs
         # in the model does not grow with each transform operation
         CoordTransform.merge_and_clean(self.coord_transforms,
                                        self.cells, self.surfaces)
 
+    def _update_universe_transform(self, names, ypr, angle_units, matrix,
+                                   displacement, reset=False):
+        """ Update the universe-specific transform (CoordTransform) when the
+        transform operation is performed on an universe.
+
+        The universes are the ones in 'names' according to the angles in yaw,
+        pitch, and roll (or the provided matrix) and the translation in
+        displacement.
+        """
+
+        # Create the transform to give universes
+        transform = CoordTransform(0, displacement, ypr, matrix,
+                                   in_degrees=angle_units == "degrees")
+
+        # Get the universes from names
+        universes = [self.universe_by_name(n) for n in names]
+        for universe in universes:
+            # This is always in_place, we don't need to
+            # allocate new tr_ids. Then transform universe
+            tfu = universe.transform
+            if tfu and not reset:
+                universe.transform = tfu.combine(transform, in_place=True)
+            else:
+                universe.transform = transform
 
     def _transform_universes(self, names, ypr, angle_units, matrix,
-                             displacement, transform_in_place):
+                             displacement, transform_in_place,
+                             matrix_notation="mcnp", reset=False):
         """Transforms the universe named `name` according to the angles in
-        yaw, pitch, and roll (or the provided matrix) and the translation in
-        displacement.
+        yaw, pitch, and roll (or the provided matrix and notation) and the 
+        translation in displacement.
 
         Note that this will operate on all instances of the universe,
         even if that is not desired.
@@ -1833,7 +2318,8 @@ class McnpNeutronics(Neutronics):
 
         # Create the transform to potentially be used by all
         transform = CoordTransform(None, displacement, ypr, matrix,
-                                   in_degrees=angle_units == "degrees")
+                                   in_degrees=angle_units == "degrees",
+                                   matrix_notation=matrix_notation)
         used_transform = False
 
         # Convert the universe names to the identifiers
@@ -1846,6 +2332,19 @@ class McnpNeutronics(Neutronics):
                 msg = "Cannot transform root universe"
                 self.log("error", msg)
 
+            # Do not allow transforms of storage and supply universes before
+            # they are moved to in-core
+            u_trans = self.universes[u_id]
+            if u_trans.status == SUPPLY:
+                msg =   "Supply Universes can not be transformed. "
+                msg += f"Use an in-core instance instead "
+                msg += f"(e.g., {u_trans.name}[42])."
+                self.log("error", msg)
+            elif u_trans.status == STORAGE:
+                msg =   "Storage Universes can not be transformed. "
+                msg += f"Move universe {u_trans.name} to in-core first. "
+                self.log("error", msg)
+
             # Find the cells which own this universe (i.e., one level up)
             # Look at all cells in the root universe to find out which
             # owns the universe whose id is u_id
@@ -1863,6 +2362,10 @@ class McnpNeutronics(Neutronics):
                         for n_idx in range(len(index[0])):
                             idx = (index[0][n_idx], index[1][n_idx],
                                    index[2][n_idx])
+                            # Reset transform if reset is True
+                            if reset:
+                                cell.revert_fill_transforms(idx)
+                                transform_in_place = False
                             # See if there is a transform here already
                             tf = cell.fill_transforms[idx[0]][idx[1]][idx[2]]
                             if tf is not None:
@@ -1884,10 +2387,10 @@ class McnpNeutronics(Neutronics):
             self.coord_transforms[transform.id] = transform
 
     def _transform_cells(self, names, ypr, angle_units, matrix, displacement,
-                         transform_in_place):
+                         transform_in_place, matrix_notation, reset=False):
         """Transforms the cells named `name` according to the angles in
-        yaw, pitch, and roll (or the provided matrix) and the translation in
-        displacement.
+        yaw, pitch, and roll (or the provided matrix and notation) and the 
+        translation in displacement.
         """
 
         # Convert names to ids
@@ -1896,11 +2399,17 @@ class McnpNeutronics(Neutronics):
 
         # Create the transform to potentially be used by all
         transform = CoordTransform(None, displacement, ypr, matrix,
-                                   in_degrees=angle_units == "degrees")
+                                   in_degrees=angle_units == "degrees",
+                                   matrix_notation=matrix_notation)
         used_transform = False
         for c_id in ids:
             cell = self.cells[c_id]
 
+            # Reset transform if reset is True
+            if reset:
+                cell.coord_transform = cell.initial_coord_transform
+                transform_in_place = False
+
             # See if there is a transform already here
             tf = cell.coord_transform
             if tf is not None:
@@ -1924,10 +2433,11 @@ class McnpNeutronics(Neutronics):
             self.coord_transforms[transform.id] = transform
 
     def _transform_surfaces(self, names, ypr, angle_units, matrix,
-                            displacement, transform_in_place):
+                            displacement, transform_in_place,
+                            matrix_notation, reset=False):
         """Transforms the surfaces named `name` according to the angles in
-        yaw, pitch, and roll (or the provided matrix) and the translation in
-        displacement.
+        yaw, pitch, and roll (or the provided matrix and notation) and the 
+        translation in displacement.
         """
 
         # Convert names to ids
@@ -1936,11 +2446,17 @@ class McnpNeutronics(Neutronics):
 
         # Create the transform to potentially be used by all
         transform = CoordTransform(None, displacement, ypr, matrix,
-                                   in_degrees=angle_units == "degrees")
+                                   in_degrees=angle_units == "degrees",
+                                   matrix_notation=matrix_notation)
         used_transform = False
         for surf_id in ids:
             surf = self.surfaces[surf_id]
 
+            # Reset transform if reset flag is True
+            if reset:
+                surf.coord_transform = surf.initial_coord_transform
+                transform_in_place = False
+
             # See if there is a transform already here
             tf = surf.coord_transform
             if tf is not None:
@@ -1965,7 +2481,6 @@ class McnpNeutronics(Neutronics):
 
 def _run_volume(messages, title, this, mat_cards, output, others,
                 seed, first_pass, cells_to_obtain):
-
     other_cards = others + ["rand gen=2 seed={}".format(seed)]
 
     # Get the list of files that exist before we execute
diff --git a/adder/mcnp/output_methods.py b/adder/mcnp/output_methods.py
index 05313a2..aae7903 100644
--- a/adder/mcnp/output_methods.py
+++ b/adder/mcnp/output_methods.py
@@ -8,6 +8,10 @@ import mcnptools
 from .constants import *
 from .input_utils import num_format
 from adder.type_checker import *
+from adder.loggedclass import LoggedClass
+
+logger = LoggedClass(0, __name__)
+_INDENT = 15
 
 
 def reverse_readline(filename, buf_size=8192):
@@ -93,8 +97,14 @@ def _extract_results(mctal, tally_ids):
         The requested tallies
     """
 
-    tallies = [mctal.GetTally(i) for i in tally_ids]
-
+    tallies = []
+    for i in tally_ids:
+        # check if user tallies matched with the one in mctal
+        try:
+            value = mctal.GetTally(i)
+            tallies.append(value)
+        except Exception:
+            pass
     return tallies
 
 
@@ -374,7 +384,7 @@ def _get_material_wise_rxn_rates(mctal, nested_cells, flux, tally_map, depl_libs
         for cell_id in cell_set:
             # Get some shorthand objects
             cell = nested_cells[cell_id]
-            mat = cell.material   # Assume mat is depleting and is a real mat
+            mat = cell.material  # Assume mat is depleting and is a real mat
             depl_lib = depl_libs[mat.depl_lib_name]
             cell_flux = flux[mat.id]
             cell_index = cell_bins.index(num_format(cell_id, 'float'))
@@ -387,15 +397,77 @@ def _get_material_wise_rxn_rates(mctal, nested_cells, flux, tally_map, depl_libs
                     for g in range(depl_lib.num_neutron_groups):
                         xs[g] = tally.GetValue(cell_index, tfc, tfc, tfc,
                                                rxn_bin_index, tfc, g, tfc)
-                    # Divide by the flux to yield xs from rxn rate
-                    xs /= cell_flux
+                        if cell_flux[g] != 0:
+                            # Divide by the flux to yield xs from rxn rate.
+                            # if zero flux (group g), rxn rate already zero,
+                            # then no division needed.
+                            xs[g] /= cell_flux[g]
+                        else:
+                            xs[g] = 0
 
                     # Incorporate into the library
                     # We will assume the reaction type already
                     # exists and thus no checking is necessary
                     # Get the reaction tuple
-                    _, targets_, yields_, q_value = \
-                        iso_xs._products[rxn_type]
-                    # Now re-build the tuple with the new yield
-                    iso_xs._products[rxn_type] = \
-                        (xs, targets_, yields_, q_value)
+                    _, targets_yields, q_value = \
+                        iso_xs.get_product_data_by_type(rxn_type)
+                    # Now update the new xs
+                    iso_xs.update_type(rxn_type, xs, targets_yields, q_value)
+
+
+            # check flux zero and info message
+            for g in range(depl_lib.num_neutron_groups):
+                if cell_flux[g] == 0:
+                    msg = f"Zero flux (group {g + 1}) in material {mat.name}: " \
+                          f"flux-weighted cross-sections set to 0. "
+                    logger.log("info", msg, indent=_INDENT)
+
+
+def _get_user_tally_res(mctal, tally_ids):  # user_tallies_list to add
+    """Gets the results for user tallies from the MCTAL file
+    Parameters
+    ----------
+    mctal : mcnptools.Mctal
+        The MCTAL file interface object
+    tally_ids: list
+        List of tally ids to retrieve from the MCTAL file.
+
+    Returns
+    -------
+    user_tallies_res : dict
+        Dictionary where the key corresponds to the following data extracted:
+        tally_matrix, tally_matrix_err, facet_ids.
+    """
+
+    tallies_res = _extract_results(mctal, tally_ids)
+
+    user_tallies_res = {}
+    for tally in tallies_res:
+
+        # getting bins and dimensions for tally matrix. For details, see MCNPtools user guide.
+        fbins, cbins, mbins, sbins, ebins, dbins, ubins, tbins = (
+            tally.GetFBins(), tally.GetCBins(), tally.GetMBins(), tally.GetSBins(), tally.GetEBins(), tally.GetDBins(),
+            tally.GetUBins(), tally.GetTBins())
+        f_dim, d_dim, u_dim, s_dim, m_dim, c_dim, e_dim, t_dim, p_dim = (len(fbins), len(dbins), len(ubins), len(sbins),
+                                                                  len(mbins), len(cbins), len(ebins), len(tbins), 1)
+        p_dim = 1 # pert. number
+        # Create an empty array of the required shape
+        result_array = np.zeros((f_dim, d_dim, u_dim, s_dim, m_dim, c_dim, e_dim, t_dim, p_dim))
+        result_array_err = np.zeros((f_dim, d_dim, u_dim, s_dim, m_dim, c_dim, e_dim, t_dim, p_dim))
+
+        # Fill the array by iterating over all combinations of i, j, k, l using np.ndindex
+        for idx in np.ndindex(f_dim, d_dim, u_dim, s_dim, m_dim, c_dim, e_dim, t_dim, p_dim):
+            f, d, u, s, m, c, e, t, p = idx  # unpack the index tuple
+            result_array[f, d, u, s, m, c, e, t, p] = tally.GetValue(f, d, u, s, m, c, e, t, p)
+            result_array_err[f, d, u, s, m, c, e, t, p] = tally.GetError(f, d, u, s, m, c, e, t, p)
+
+        # assign values to tally id
+        id = tally.ID()
+        user_tallies_res[id] = {}
+        user_tallies_res[id]["tally_matrix"] = result_array
+        user_tallies_res[id]["tally_matrix_err"] = result_array_err
+        user_tallies_res[id]["facet_ids"] = tally.GetFBins()
+
+    # user_tally = [10, 20, 30]
+    return user_tallies_res
+
diff --git a/adder/mcnp/surface.py b/adder/mcnp/surface.py
index 7045409..e378be8 100644
--- a/adder/mcnp/surface.py
+++ b/adder/mcnp/surface.py
@@ -43,6 +43,8 @@ class Surface(object):
         The surface ID
     coord_transform: CoordTransform or None
         The transformation associated with this surface
+    initial_coord_transform: CoordTransform or None
+        The transformation associated with this surface in the base MCNP input
     type : _SURF_TYPES
         The surface type ("cz", e.g.)
     params : str
@@ -63,6 +65,8 @@ class Surface(object):
         # Assign the parameters
         self.id = surf_id
         self.coord_transform = transform
+        self.initial_coord_transform = \
+            transform.clone(new_id=0) if transform else None
         self.type = surf_type
         self.params = surf_params
         self.boundary_type = boundary_type
diff --git a/adder/mcnp/universe.py b/adder/mcnp/universe.py
index d66156e..e654b90 100644
--- a/adder/mcnp/universe.py
+++ b/adder/mcnp/universe.py
@@ -31,6 +31,8 @@ class Universe(object):
     cells : OrderedDict
         The cells contained by this universe; indexed by cell id,
         value is the Cell
+    transform : CoordTransform or None
+        ADDER universe transform. Transferred to new ceels when shuffled.
     nested_materials : OrderedDict
         All nested materials contained in this universe; indexed by cell id,
         and a value of the Material
@@ -48,6 +50,7 @@ class Universe(object):
         self.id = id_
         self.num_copies = 0
         self.cells = OrderedDict()
+        self.transform = None
 
     @property
     def name(self):
@@ -78,7 +81,7 @@ class Universe(object):
     def status(self):
         statuses = [cell.status for cell in self.cells.values()]
 
-        if np.all(np.asarray(statuses) == statuses[0]):
+        if np.all(np.asarray(statuses, dtype=int) == statuses[0]):
             return statuses[0]
         else:
             msg = "Material and/or Universes of Cell {} do not have the" \
diff --git a/adder/msr/msr_component.py b/adder/msr/msr_component.py
index 30cb32f..279f712 100644
--- a/adder/msr/msr_component.py
+++ b/adder/msr/msr_component.py
@@ -244,7 +244,7 @@ class MSRComponent(object):
 
         # Now we can build the decay matrix
         self._library.set_atomic_mass_vector()
-        self.decay_matrix = self._library.build_decay_matrix()
+        self.decay_matrix = ss.csr_matrix(self._library.build_decay_matrix())
 
     def init_A_matrix(self, solve_method, flux=None):
         if self._in_core and flux is None:
@@ -263,7 +263,7 @@ class MSRComponent(object):
         else:
             self._A_matrix = \
                 self._library.build_depletion_matrix(
-                    flux, matrix_format=mat_fmt, dk_matrix=self.decay_matrix)
+                    flux, self.decay_matrix, matrix_format=mat_fmt)
 
     def init_T_matrix(self, time_step, solver_func, use_cram=True):
         dt = self.delta_t
diff --git a/adder/msr/msr_depletion.py b/adder/msr/msr_depletion.py
index 487b124..cbd5306 100644
--- a/adder/msr/msr_depletion.py
+++ b/adder/msr/msr_depletion.py
@@ -106,6 +106,7 @@ class MSRDepletion(CRAMDepletion, LoggedClass):
             The materials from the reactor definition
         depl_libs : OrderedDict of DepletionLibrary
             The depletion libraries in use in the model
+
         """
 
         self.systems = []
@@ -121,6 +122,8 @@ class MSRDepletion(CRAMDepletion, LoggedClass):
                 if comp.in_core:
                     self.fluid_mats.append(comp.mat_name)
 
+        return
+
     @property
     def solver(self):
         return "MSR_cram" + str(self.order)
diff --git a/adder/msr/msr_system.py b/adder/msr/msr_system.py
index a61a93a..bcd0188 100644
--- a/adder/msr/msr_system.py
+++ b/adder/msr/msr_system.py
@@ -2,6 +2,7 @@ import math
 from collections import deque
 
 import numpy as np
+import scipy.sparse as sp
 
 from adder.depletionlibrary import DepletionLibrary, DecayData
 from adder.material import Material
@@ -374,7 +375,7 @@ class MSRSystem(object):
         self.path_offsets = \
             np.subtract(np.floor_divide(self.path_times,
                                         self.min_transport_time),
-                        1).astype(np.int)
+                        1).astype(int)
 
     def update_path_weights(self):
         # This method updates the weighting of the paths based on mass flow
@@ -643,7 +644,8 @@ class MSRSystem(object):
                 iso_xs = iso.neutron_xs
                 if iso_xs is not None:
                     # Iterate over every rxn channel
-                    for type_ in iso_xs.keys():
+                    for idx in range(iso_xs.num_types):
+                        type_ = iso_xs.get_type_by_idx(idx)
                         rxn = np.zeros(num_groups)
                         # Now get the data for each component
                         for step in path:
@@ -651,7 +653,7 @@ class MSRSystem(object):
                                 mat = materials_by_name[step.mat_name]
                                 mat_n_xs = \
                                     step.library.isotopes[iso_name].neutron_xs
-                                ref_xs = mat_n_xs._products[type_][0]
+                                ref_xs = mat_n_xs.get_xs_by_idx(idx)
                                 # All xs will be in consistent units as the
                                 # libraries will be sourced from the same lib,
                                 # so unit conversions/checks are absent here.
@@ -663,8 +665,8 @@ class MSRSystem(object):
                         # Now normalize rxn by the flux and total time
                         rxn /= (pathflux[p] * self.path_times[p])
                         # Store the xs in our path's library
-                        _, t, y, q = iso_xs[type_]
-                        iso_xs._products[type_] = (rxn, t, y, q)
+                        _, ty, q = iso_xs.get_product_data_by_idx(idx)
+                        iso_xs.update_type(type_, rxn, ty, q)
 
                 # Repeat for the decay constants. In this code we are making
                 # the pretty bulletproof assumption that the decay constants
@@ -686,7 +688,10 @@ class MSRSystem(object):
                     iso.removal.add_type("removal", 1., child)
 
         # Now create the depletion matrices
-        matrices = [lib.build_depletion_matrix(pathflux[p], matrix_format="csr")
+        decay_matrices = [sp.csr_matrix(
+            lib.build_decay_matrix()) for lib in libs]
+        matrices = [lib.build_depletion_matrix(pathflux[p], decay_matrices[p],
+                                               matrix_format="csr")
                     for p, lib in enumerate(libs)]
 
         # Create some initial information we need for all depletions
diff --git a/adder/msr_reactor/msr_reactor.py b/adder/msr_reactor/msr_reactor.py
index f4f6699..a9900fe 100644
--- a/adder/msr_reactor/msr_reactor.py
+++ b/adder/msr_reactor/msr_reactor.py
@@ -2,10 +2,10 @@ import multiprocessing as mp
 import traceback
 import weakref
 
-from adder.reactor import Reactor, depletion_worker, par_depl_init, \
-    library_worker
+from adder.reactor import Reactor, parallel_worker, parallel_init
 from adder.cram import CRAMDepletion
-from adder.constants import SUPPLY, BASE_LIB
+from adder.constants import SUPPLY, BASE_LIB, CHUNKSIZE_FACTOR
+from adder.isotope import ISO_REGISTRY
 
 
 class MSRReactor(Reactor):
@@ -96,6 +96,12 @@ class MSRReactor(Reactor):
         The standard deviation of the calculated k-eigenvalue for the
         current state point; value is 0.0 if a deterministic solver is
         used.
+    control_groups : dict
+        The set of control group information from the input file, including
+        the current perturbation status. The key to the dict is the name and
+        the value is an instance of a ControlGroup object.
+    fast_forward : bool
+        Whether this is a fast forward run (True) or not (False).
     fixed_fuel_depletion : adder.Depletion
         The depletion solver interface for the fixed fuel
 
@@ -158,7 +164,9 @@ class MSRReactor(Reactor):
         user_mats_info : OrderedDict
             The keys are the ids in the neutronics solver and
             the value is an OrderedDict of the name, depleting boolean,
-            ex_core_status, and non_depleting_isotopes list.
+            volume, density, non_depleting_isotopes list, 
+            apply_reactivity_threshold_to_initial_inventory flag, and 
+            use_default_depletion_library flag.
         user_univ_info : OrderedDict
             The keys are the universe ids in the neutronics solver and
             the value is an OrderedDict of the name.
@@ -202,12 +210,39 @@ class MSRReactor(Reactor):
                         self.depletion_libs[new_lib.name] = new_lib
                         mat.depl_lib_name = new_lib.name
 
+        # Get the new isotopes
+        new_isos = {}
+        for system in self.depletion.systems:
+            sys_lib = system.library
+            sys_isos = [
+                iso_name for iso_name, index in
+                    sys_lib.isotope_indices.items()
+                    if index >= system.num_original_isotopes]
+            for iso in sys_isos:
+                for mat in fluid_mats:
+                    xs_lib = mat.default_xs_library
+                    if iso in new_isos:
+                        new_isos[iso].add(xs_lib)
+                    else:
+                        new_isos[iso] = set([xs_lib])
+        # Now we can add it
+        for iso_name, iso_xs_libs in new_isos.items():
+            for xs_lib in iso_xs_libs:
+                for is_depleting in (True, False):
+                    ISO_REGISTRY.register_isotope(iso_name, xs_lib,
+                    is_depleting)
+
     def _parallel_depletion_manager(self, dt, depletion_step, num_substeps):
         """Executes the depletion in parallel"""
 
         if dt <= 0.:
             return
 
+        # Determine the number of depleting materials
+        num_depl_mats = len(list((i for i, mat in enumerate(self._materials) if
+                     (mat.name not in self.depletion.fluid_mats and
+                      mat.is_depleting and mat.status != SUPPLY))))
+
         # Deplete the flowing fluid materials
         self.log("info", "Depleting Fluid System Materials", 8)
         self.depletion.execute(self.materials, self.depletion_libs, dt,
@@ -215,15 +250,12 @@ class MSRReactor(Reactor):
 
         # And now deplete the remaining materials
         # Update the materials that are not fluids
-        other_mats = []
-        for i, mat in enumerate(self.materials):
-            if mat.name not in self.depletion.fluid_mats:
-                if mat.is_depleting and mat.status != SUPPLY:
-                    lib = self.depletion_libs[mat.depl_lib_name]
-                    other_mats.append((i, mat, lib))
+        mat_idxs = (i for i, mat in enumerate(self._materials) if
+                     (mat.name not in self.depletion.fluid_mats and
+                      mat.is_depleting and mat.status != SUPPLY))
 
-        msg = "Depleting {:,} Remaining Materials with {} Thread".format(
-            len(other_mats), self.fixed_fuel_depletion.num_threads)
+        msg = "Depleting Remaining Materials with {} Thread".format(
+            self.fixed_fuel_depletion.num_threads)
         if self.fixed_fuel_depletion.num_threads > 1:
             # Make it plural
             msg += "s"
@@ -231,79 +263,82 @@ class MSRReactor(Reactor):
 
         self.fixed_fuel_depletion.compute_decay(self.depletion_libs[BASE_LIB])
 
-        self.log("info", "Computing Libraries", 10)
-        data = []
+        # Perform the depletion
+        self.log("info", "Executing Depletion", 10)
         weak_deplete = weakref.proxy(self.fixed_fuel_depletion)
-        args_list = ((i, weak_deplete, mat.flux, lib)
-                     for i, mat, lib in other_mats)
-        if self.fixed_fuel_depletion.num_threads == 1:
-            for args in args_list:
-                i, mtx, idxs, inv_idxs = library_worker(args)
-                data.append((i, self.materials[i], mtx, idxs, inv_idxs))
-        else:
-            chunksize = self.fixed_fuel_depletion.chunksize
-            tasksperchild = 1
-            with mp.Pool(processes=self.fixed_fuel_depletion.num_threads,
-                         maxtasksperchild=tasksperchild) as pool:
-                for i, mtx, idxs, inv_idxs in pool.imap(library_worker,
-                                                        args_list,
-                                                        chunksize=chunksize):
-                    data.append((i, self.materials[i], mtx, idxs, inv_idxs))
+        if self.depletion.num_threads == 1:
+            for i_mat in mat_idxs:
+                mat = self._materials[i_mat]
+                lib = self.depletion_libs[mat.depl_lib_name]
+                matrix = weak_deplete.compute_library(lib, mat._flux)
 
-        self.log("info", "Executing Depletion", 10)
-        # Provide a single-threaded case for much easier debugging
-        if self.fixed_fuel_depletion.num_threads == 1:
-            for i, mat, mtx, idxs, inv_idxs in data:
                 try:
                     new_isos, new_fracs, new_density = \
-                        self.fixed_fuel_depletion.execute(
-                            mat, mtx, idxs, inv_idxs, dt,
-                            depletion_step, num_substeps, True)
+                        weak_deplete.execute(mat, matrix,
+                                             lib.isotope_indices,
+                                             lib.inverse_isotope_indices, dt,
+                                             depletion_step, num_substeps,
+                                             True)
                 except Exception:
                     error_msg = traceback.format_exc()
-                    self.log("error", error_msg)
-                mat.apply_new_composition(new_isos, new_fracs, new_density)
+                    print(error_msg)
+                self._materials[i_mat].apply_new_composition(
+                    new_isos, new_fracs, new_density)
         else:
-            # Do the parallel processing of depletion
+
+            # Calculate chunksize
+            if weak_deplete.chunksize == 0:
+                chunksize, extra = divmod(num_depl_mats,
+                                    weak_deplete.num_threads * CHUNKSIZE_FACTOR)
+                if extra:
+                    chunksize += 1
+
+                # Check to make sure chunksize is an integer greater than zero
+                chunksize = int(chunksize)
+                if chunksize < 1:
+                    chunksize = 1
+
+            else:
+                chunksize = weak_deplete.chunksize
+
+            # Do the parallel processing
             errors = []
-            chunksize = self.fixed_fuel_depletion.chunksize
-            tasksperchild = 1
+
             with mp.Pool(
-                    processes=self.fixed_fuel_depletion.num_threads,
-                    initializer=par_depl_init,
-                    initargs=(weak_deplete, dt, depletion_step, num_substeps),
-                    maxtasksperchild=tasksperchild) as pool:
-                for i, new_isos, new_fracs, new_density \
-                    in pool.imap_unordered(depletion_worker, data,
+                    processes=weak_deplete.num_threads,
+                    initializer=parallel_init,
+                    initargs=(weak_deplete, dt, depletion_step, num_substeps)) as pool:
+                for i_mat, new_isos, new_fracs, new_density \
+                    in pool.imap_unordered(parallel_worker, mat_idxs,
                                            chunksize=chunksize):
                     if isinstance(new_isos, str):
-                        errors.append((i, new_isos))
+                        errors.append((i_mat, new_isos))
                     else:
-                        self.materials[i].apply_new_composition(
+                        self._materials[i_mat].apply_new_composition(
                             new_isos, new_fracs, new_density)
+
             # Now we handle the errors. They *may* be due to parallel system
-            # issues (file I/O, etc), so lets just run the few cases in
-            # parallel
+            # issues (file I/O, etc), so lets just run the few cases in serial
             if len(errors) > 0:
                 # Now raise the error messages
-                msg = "The Following Solid Materials Encountered Errors " + \
-                    "While Processed in Parallel:"
+                msg = "The Following Materials Encountered Errors While " + \
+                    "Processed in Parallel:"
                 self.log("info_file", msg)
-                for i, error in errors:
+                for i_mat, error in errors:
                     self.log("info_file", error)
                 self.log("info", "Rerunning Failed Depletions", 8)
                 # And re-run in serial
-                for i, _ in errors:
-                    mat = self.materials[i]
+                for i_mat, _ in errors:
+                    mat = self._materials[i_mat]
                     lib = self.depletion_libs[mat.depl_lib_name]
                     mtx = self.depletion.compute_library(lib, mat.flux),
                     idxs = lib.isotope_indices
                     inv_idxs = lib.inverse_isotope_indices
                     try:
                         new_isos, new_fracs, new_density = \
-                            self.fixed_fuel_depletion.execute(mat, mtx, idxs,
-                                inv_idxs, dt, depletion_step, num_substeps,
-                                True)
+                            self.depletion.execute(
+                                mat, mtx, idxs, inv_idxs,
+                                dt, depletion_step, num_substeps, True)
                     except Exception:
                         error_msg = traceback.format_exc()
                         self.log("error", error_msg)
diff --git a/adder/neutronics.py b/adder/neutronics.py
index 084d1f6..423baad 100644
--- a/adder/neutronics.py
+++ b/adder/neutronics.py
@@ -5,11 +5,11 @@ import shlex
 
 import numpy as np
 
-from adder.isotope import update_isotope_depleting_status
+import adder.isotope
 from adder.material import Material
 from adder.loggedclass import LoggedClass
 from adder.type_checker import *
-from adder.constants import IN_CORE
+from adder.constants import IN_CORE, SUPPLY
 
 
 class Neutronics(LoggedClass):
@@ -94,6 +94,8 @@ class Neutronics(LoggedClass):
         self.neutronics_isotopes = OrderedDict()
         self.reactivity_threshold = reactivity_threshold
         self.reactivity_threshold_initial = reactivity_threshold_initial
+        #self.user_tallies = OrderedDict()
+
 
         # Set up the logger and log that we initialized our Neutronics
         # solver
@@ -195,6 +197,7 @@ class Neutronics(LoggedClass):
                            equality=True)
         self._reactivity_threshold = reactivity_threshold
 
+
     @property
     def reactivity_threshold_initial(self):
         return self._reactivity_threshold_initial
@@ -265,11 +268,11 @@ class Neutronics(LoggedClass):
         """
 
         # Store the runtime options as root attributes
-        h5_file.attrs["neutronics_solver"] = np.string_(self.solver)
-        h5_file.attrs["neutronics_mpi_cmd"] = np.string_(self.mpi_cmd)
-        h5_file.attrs["neutronics_exec"] = np.string_(self.exec_cmd)
+        h5_file.attrs["neutronics_solver"] = np.bytes_(self.solver)
+        h5_file.attrs["neutronics_mpi_cmd"] = np.bytes_(self.mpi_cmd)
+        h5_file.attrs["neutronics_exec"] = np.bytes_(self.exec_cmd)
         h5_file.attrs["base_neutronics_input_filename"] = \
-            np.string_(self.base_input_filename)
+            np.bytes_(self.base_input_filename)
         h5_file.attrs["num_neutronics_threads"] = self.num_threads
         h5_file.attrs["num_mpi_procs"] = self.num_procs
         h5_file.attrs["use_depletion_library_xs"] = \
@@ -278,7 +281,37 @@ class Neutronics(LoggedClass):
         h5_file.attrs["reactivity_threshold_initial"] = \
             np.bool_(self.reactivity_threshold_initial)
 
-    def read_input(self, library_data, num_neutron_groups, user_mats_info,
+    def parse_library(self, library_data):
+        """Parses the neutronics library data for establishing the isotope
+        registry
+
+        Parameters
+        ----------
+        library_data : str or None
+            The filename and path to the library data. If None, then it must
+            be obtained from the environment or input, depending on the solver.
+
+        Returns
+        -------
+        neutronics_library_isos : dict
+            The keys are the isotope names in GND format and the values are an
+            Iterable of associated library names available in the neutronics
+            library
+        """
+
+        self.library_data = library_data
+
+        neutronics_library_isos = {}
+        if library_data == "test_lib_file.txt":
+            neutronics_library_isos['H1'] = set(['70c'])
+            neutronics_library_isos['U235'] = set(['70c'])
+            neutronics_library_isos['U238'] = set(['72c'])
+        else:
+            neutronics_library_isos['U235'] = set(['70c'])
+
+        return neutronics_library_isos
+
+    def read_input(self, num_neutron_groups, user_mats_info,
                    user_univ_info, shuffled_mats, shuffled_univs, depl_libs):
         """Return parsed information about the neutronics input file,
         including all the information needed to initialize
@@ -290,14 +323,13 @@ class Neutronics(LoggedClass):
 
         Parameters
         ----------
-        library_data : str
-            The filename and path to the library data
         num_neutron_groups : int
             The number of energy groups
         user_mats_info : OrderedDict
             The keys are the ids in the neutronics solver and
             the value is an OrderedDict of the name, depleting boolean,
-            ex_core_status, non_depleting_isotopes list, and
+            volume, density, non_depleting_isotopes list, 
+            apply_reactivity_threshold_to_initial_inventory flag, and 
             use_default_depletion_library flag.
         user_univ_info : OrderedDict
             The keys are the universe ids in the neutronics solver and
@@ -316,7 +348,6 @@ class Neutronics(LoggedClass):
             model; since no is_depleting (or isotope is_depleting)
             information is available at this stage, this must be
             overwritten upstream.
-
         """
 
         # Set default testing values
@@ -325,12 +356,12 @@ class Neutronics(LoggedClass):
         input_file["runmode"] = ["fast"]
         self.base_input = input_file
 
-        # Create two test material objects
+        # Create three test material objects
         name = "1"
         id_ = 1
         density = 1.
         # Differentiate for our two unit test types
-        if library_data == "test_lib_file.txt":
+        if self.library_data == "test_lib_file.txt":
             # Then this is the test_reactor case
             isotope_data = [("H1", "70c", False), ["U235", "70c"],
                             ["U238", "72c"]]
@@ -361,11 +392,13 @@ class Neutronics(LoggedClass):
             key = "non_depleting_isotopes"
             if len(user_mats_info[id_][key]) > 0:
                 # Then we have specific values
-                for i, iso in enumerate(mat1.isotopes):
+                for i in range(mat1.num_isotopes):
+                    iso = mat1.isotope_obj(i)
+                    iso_idx = mat1.isotopes[i]
                     if iso.name in user_mats_info[id_][key]:
                         mat1.isotopes[i] = \
-                            update_isotope_depleting_status(iso, False)
-            key = "reactivity_threshold_initial"
+                            adder.isotope.ISO_REGISTRY.switch_iso_depleting_status(iso_idx, False)
+            key = "apply_reactivity_threshold_to_initial_inventory"
             if key in user_mats_info[id_]:
                 mat_reactivity_threshold_initial = \
                     user_mats_info[id_][key]
@@ -376,7 +409,7 @@ class Neutronics(LoggedClass):
 
         name = "2"
         id_ = 2
-        if library_data != "test_lib_file.txt":
+        if self.library_data != "test_lib_file.txt":
             atom_fractions = [2.]
         mat2 = Material(name, id_, density, isotope_data,
                         atom_fractions, is_depleting,
@@ -396,11 +429,13 @@ class Neutronics(LoggedClass):
             key = "non_depleting_isotopes"
             if len(user_mats_info[id_][key]) > 0:
                 # Then we have specific values
-                for i, iso in enumerate(mat2.isotopes):
+                for i in range(mat2.num_isotopes):
+                    iso = mat2.isotope_obj(i)
+                    iso_idx = mat2.isotopes[i]
                     if iso.name in user_mats_info[id_][key]:
                         mat2.isotopes[i] = \
-                            update_isotope_depleting_status(iso, False)
-            key = "reactivity_threshold_initial"
+                            adder.isotope.ISO_REGISTRY.switch_iso_depleting_status(iso_idx, False)
+            key = "apply_reactivity_threshold_to_initial_inventory"
             if key in user_mats_info[id_]:
                 mat_reactivity_threshold_initial = \
                     user_mats_info[id_][key]
@@ -409,7 +444,57 @@ class Neutronics(LoggedClass):
                     self.reactivity_threshold_initial
             mat2.establish_initial_isotopes(mat_reactivity_threshold_initial)
 
-        materials = [mat1, mat2]
+        # A third test material is added to test storage materials
+        name = "supply_123_test"
+        id_ = 7
+        # Differentiate for our two unit test types
+        if self.library_data == "test_lib_file.txt":
+            # Then this is the test_reactor case
+            isotope_data = [("H1", "70c", False), ["U235", "70c"],
+                            ["U238", "72c"]]
+            atom_fractions = [4., 5., 1.]
+        else:
+            # Then this is an integral test
+            isotope_data = [("U235", "70c")]
+            atom_fractions = [1.]
+        is_depleting = True
+        default_xs_library = "71c"
+        thermal_xs_libraries = []
+        mat3 = Material(name, id_, density, isotope_data, atom_fractions,
+                        is_depleting, default_xs_library, 1,
+                        thermal_xs_libraries, SUPPLY)
+
+        if id_ in user_mats_info:
+            mat3.name = user_mats_info[id_]["name"]
+            mat3.is_depleting = user_mats_info[id_]["depleting"]
+            if "density" in user_mats_info[id_] and user_mats_info[id_]["density"] is not None:
+                mat3.density = user_mats_info[id_]["density"]
+            if "volume" in user_mats_info[id_] and user_mats_info[id_]["volume"] is not None:
+                mat3.volume = user_mats_info[id_]["volume"]
+            if not self.use_depletion_library_xs:
+                mat3.is_default_depletion_library = \
+                    user_mats_info[id_]["use_default_depletion_library"]
+            else:
+                mat3.is_default_depletion_library = True
+            key = "non_depleting_isotopes"
+            if len(user_mats_info[id_][key]) > 0:
+                # Then we have specific values
+                for i in range(mat3.num_isotopes):
+                    iso = mat3.isotope_obj(i)
+                    iso_idx = mat3.isotopes[i]
+                    if iso.name in user_mats_info[id_][key]:
+                        mat3.isotopes[i] = \
+                            adder.isotope.ISO_REGISTRY.switch_iso_depleting_status(iso_idx, False)
+            key = "apply_reactivity_threshold_to_initial_inventory"
+            if key in user_mats_info[id_]:
+                mat_reactivity_threshold_initial = \
+                    user_mats_info[id_][key]
+            else:
+                mat_reactivity_threshold_initial = \
+                    self.reactivity_threshold_initial
+            mat3.establish_initial_isotopes(mat_reactivity_threshold_initial)
+
+        materials = [mat1, mat2, mat3]
 
         for mat in materials:
             self.update_logs(mat.logs)
@@ -418,8 +503,8 @@ class Neutronics(LoggedClass):
         return materials
 
     def execute(self, filename, label, materials, depl_libs, store_input,
-                deplete_tallies, user_tallies, user_output, fast_forward,
-                update_iso_status=True):
+                deplete_tallies, user_tallies_adder_i, include_user_tallies, user_output,
+                fast_forward, update_iso_status=True):
         """Writes the input file, executes the neutronics solver, and
         then reads the results
 
@@ -437,8 +522,10 @@ class Neutronics(LoggedClass):
             Whether or not to store the input file in :attrib:`inputs`
         deplete_tallies : bool
             Whether or not to write the tallies needed for depletion
-        user_tallies : bool
-            Whether or not to write the user tallies
+        user_tallies_adder_i : dict
+            Dictionary containing info from ADDER input
+        include_user_tallies : bool
+            Including or not user tallies in the input.
         user_output : bool
             Whether or not to write the user's output control cards
         fast_forward : bool
@@ -453,19 +540,19 @@ class Neutronics(LoggedClass):
 
         inp_name = filename + ".inp"
         self.write_input(inp_name, label, materials, depl_libs, store_input,
-                         deplete_tallies, user_tallies, user_output,
-                         update_iso_status)
+                         deplete_tallies, user_tallies_adder_i,
+                         include_user_tallies, user_output, update_iso_status)
 
         self._exec_solver(inp_name, filename, fast_forward=fast_forward)
 
-        keff, keff_uncertainty, flux, nu, volumes = \
+        keff, keff_uncertainty, flux, nu, volumes, user_tally_res = \
             self._read_results(filename, materials, depl_libs, deplete_tallies)
 
-        return keff, keff_uncertainty, flux, nu, volumes
+        return keff, keff_uncertainty, flux, nu, volumes, user_tally_res
 
     def write_input(self, filename, label, materials, depl_libs, store_input,
-                    deplete_tallies, user_tallies, user_output,
-                    update_iso_status=True):
+                    deplete_tallies, user_tallies_adder_i, include_user_tallies,
+                    user_output, update_iso_status=True):
         """Updates the input for the particular run case.
 
         Parameters
@@ -482,8 +569,10 @@ class Neutronics(LoggedClass):
             Whether or not to store the input file in :attrib:`inputs`
         deplete_tallies : bool
             Whether or not to write the tallies needed for depletion
-        user_tallies : bool
-            Whether or not to write the user tallies
+        user_tallies_adder_i : dict
+            Dictionary containing info from ADDER input
+        include_user_tallies : bool
+            Including or not user tallies in the input.
         user_output : bool
             Whether or not to write the user's output control cards
         update_iso_status : bool, optional
@@ -552,8 +641,12 @@ class Neutronics(LoggedClass):
         volumes = OrderedDict()
         volumes[1] = 0.4
         volumes[2] = 0.6
+        user_tally_res = OrderedDict()
+        user_tally_res["1"] = {}
+        user_tally_res["1"]["tally_matrix"] = np.array([[1., 0., 0., 0., 0., 0., 0., 0]])
+        user_tally_res["1"]["tally_matrix_err"] = np.array([[1., 0., 0., 0., 0., 0., 0., 0]])
 
-        return keff, keff_uncertainty, flux, nu, volumes
+        return keff, keff_uncertainty, flux, nu, volumes, user_tally_res
 
     def calc_volumes(self, materials, vol_data, target_unc, max_hist,
                      only_depleting):
@@ -620,7 +713,8 @@ class Neutronics(LoggedClass):
         check_iterable_type("materials", materials, Material)
 
     def transform(self, names, yaw, pitch, roll, angle_units, matrix,
-                  displacement, transform_type, transform_in_place=False):
+                  displacement, transform_type, transform_in_place=False, 
+                  matrix_notation="mcnp", reset=False):
         """Transforms the universe named `name` according to the angles in
         yaw, pitch, and roll and the translation in displacement.
 
@@ -651,6 +745,14 @@ class Neutronics(LoggedClass):
         transform_in_place : bool, optional
             If the existing transform should be updated (True) or a new
             transform created. Defaults to False.
+        matrix_notation : {"common", "mcnp"}
+            The notation used to define the rotation matrix. The matrix with
+            the MCNP notation corresponds to the transpose of the matrix defined
+            w/ the common mathematical notation ("common") to perform geometrical 
+            rotation.
+        reset : bool
+            If True, the position of the entity is reset to the initial one 
+            provided in the MCNP base input file.
         """
 
         # Perform type checking
@@ -665,11 +767,13 @@ class Neutronics(LoggedClass):
         check_iterable_type("displacement", displacement, float)
         check_length("displacement", displacement, 3)
         check_type("transform_in_place", transform_in_place, bool)
+        check_type("reset", reset, bool)
 
     def geom_search(self, transform_type, axis, names, angle_units, k_target,
-                    bracket_interval, target_interval, uncertainty_fraction,
+                    bracket_interval, reference_position, target_interval, 
+                    uncertainty_fraction,
                     initial_guess, min_active_batches, max_iterations,
-                    materials, case_idx, operation_idx, depl_libs):
+                    materials, case_idx, operation_idx, depl_libs, user_tallies_adder_i):
         """Performs a search of geometric transformations to identify that
         which yields the target k-eigenvalue within the specified interval.
 
@@ -688,6 +792,12 @@ class Neutronics(LoggedClass):
             The units of the above angles
         k_target : float
             The target k-eigenvalue to search for
+        reference_position: str or float
+            The reference point for the bracket_interval values.
+            'initial' denotes the initial position of the
+            control group in the neutronics input; whereas
+            'last' referes to the last known position of the
+            control group. If float, the float is the position.
         bracket_interval : Iterable of float
             The lower and upper end of the ranges to search.
         target_interval : float
@@ -696,8 +806,8 @@ class Neutronics(LoggedClass):
             This parameter sets the stochastic uncertainty to target when the
             initial computation of an iteration reveals that a viable solution
             may exist.
-        initial_guess : float
-            The starting point to search
+        initial_guess : float or str
+            The starting point to search. If "last" use the last position
         min_active_batches : int
             The starting number of batches to run to ensure enough keff samples
             so that it follows the law of large numbers. This is the number of
@@ -714,6 +824,8 @@ class Neutronics(LoggedClass):
             The operation index, for printing
         depl_libs : OrderedDict of DepletionLibrary
             The depletion libraries in use in the model
+        user_tallies_adder_i : dict
+            User tallies to be processed, assigned in the ADDER input
 
         Returns
         -------
diff --git a/adder/origen22/depletionlibrary_origen.py b/adder/origen22/depletionlibrary_origen.py
index c253f9a..8bb477e 100644
--- a/adder/origen22/depletionlibrary_origen.py
+++ b/adder/origen22/depletionlibrary_origen.py
@@ -131,7 +131,7 @@ def to_origen(this, isotope_types, filepath, flux=None, start_lib_id=1,
         file.write(xs_nfy_lib)
 
 
-# TODO: When ORIGEN non-std rxns are understood, re-enable this
+# TODO: When ORIGEN non-std rxns are understood, review and re-enable this
 # def create_nonstandard_rxn_lib(this, filename, flux=None, overwrite=True):
 #     """Determine if this library contains any reactions which are not
 #     considered standard by ORIGEN2.2; if so return their number and
@@ -180,7 +180,7 @@ def to_origen(this, isotope_types, filepath, flux=None, start_lib_id=1,
 #         # Not every isotope has xs data, if it doesnt then no need
 #         # to worry
 #         if iso.neutron_xs is not None:
-#             xs_lib_rxn_types = set(iso.neutron_xs._products.keys())
+#             xs_lib_rxn_types = set(iso.neutron_xs._product_types)
 #             # Find the values in xs_lib_rxn_types not in STANDARD_RXNS
 #             non_std_rxn_types = xs_lib_rxn_types - STANDARD_RXNS
 #         else:
@@ -197,7 +197,12 @@ def to_origen(this, isotope_types, filepath, flux=None, start_lib_id=1,
 #             parent_id = GND_to_origen_nucid(iso_name)
 #             for rxn in non_std_rxn_types:
 #                 # Get children names
-#                 for type_, (xs, targets, yields, _) in iso.neutron_xs.items():
+#                 for type_ in iso.neutron_xs._product_types:
+#                     xs, targets_yields, _ = \
+#                         iso.neutron_xs.get_product_data_by_type(type_)
+#                     targets = np.array(targets_yields['targets'],
+#                                        dtype=np.string_)
+#                     yields = targets_yields['yields']
 #                     xs_val = np.dot(xs, the_flux)
 #                     for t, target in enumerate(targets):
 #                         child_id = GND_to_origen_nucid(target)
@@ -340,11 +345,11 @@ def _write_decay(this, lib_id, iso_name):
         # Then denote this as stable
         data_units = ORIGEN_TIME_UNITS["stable"]
         # Origen just uses a 0 for thalf and friends if it is a
-        # stable isotopeq
+        # stable isotope
         thalf = 0.
     else:
-        def find_state(targets, yields, find_m):
-            for i, target in enumerate(targets):
+        def find_state(target_yields, find_m):
+            for i, target in enumerate(target_yields['targets']):
                 if target == "fission":
                     return i
                 _, _, m = adder.data.zam(target)
@@ -353,10 +358,12 @@ def _write_decay(this, lib_id, iso_name):
             # if we got here we didnt find it
             return None
 
-        for type_ in data.keys():
-            br, targets, yields = data[type_]
-            t0 = find_state(targets, yields, 0)
-            t1 = find_state(targets, yields, 1)
+        for idx in range(data.num_types):
+            type_ = data.get_type_by_idx(idx)
+            br, target_yields = data.get_product_data_by_idx(idx)
+            t0 = find_state(target_yields, 0)
+            t1 = find_state(target_yields, 1)
+            yields = target_yields['yields']
 
             if type_ == "beta-":
                 if t0 is not None:
@@ -412,6 +419,14 @@ def _get_xs(lib, iso_name, xs_type, flux):
         if lib.isotopes[iso_name].neutron_xs is not None:
             xs = lib.isotopes[iso_name].neutron_xs.get_xs(type_, "b", m)
             flux_tot = np.sum(flux)
+            if xs is None:
+                alt_types = lib.isotopes[iso_name].\
+                                neutron_xs.equivalent_rx_type(type_)
+                for alt_type in alt_types:
+                    xs = lib.isotopes[iso_name]\
+                            .neutron_xs.get_xs(alt_type, "b", m)
+                    if xs is not None:
+                        break
             if xs is not None:
                 if flux_tot == 0.:
                     return_val = np.sum(xs)
diff --git a/adder/origen22/origen22.py b/adder/origen22/origen22.py
index 194aea0..ab76feb 100644
--- a/adder/origen22/origen22.py
+++ b/adder/origen22/origen22.py
@@ -64,13 +64,13 @@ class Origen22Depletion(Depletion):
 
     def compute_library(self, depl_lib, flux):
         """Computes and returns the total library,
-        decay + flux-induces reactions. For ORIGEN this is a lib string,
-        for CRAM this is the sparse matrix"""
+        decay + flux-induces reactions. This method requires that the decay
+        data already be computed via Depletion.compute_decay().
+        For ORIGEN this is a lib string, for CRAM this is the sparse matrix."""
 
-        if self.decay_data is None:
-            self.compute_decay(depl_lib)
         rxn_lib = make_origen_xs_nfy_lib(depl_lib, self.isotope_types, flux)
-        return "".join((zlib.decompress(self.decay_data).decode(), rxn_lib))
+        full_lib = "".join((zlib.decompress(self.decay_data).decode(), rxn_lib))
+        return full_lib
 
     @property
     def solver(self):
@@ -129,12 +129,11 @@ class Origen22Depletion(Depletion):
             all_zero = True
             if xs is not None:
                 for xs_type in sigmas:
-                    val = xs[xs_type]
-                    if val is not None:
+                    idx = xs.get_type_index(xs_type)
+                    if idx is not None:
                         # Then just peel off the 1-group
-                        # (unit flux weighted) xs from the
-                        # (xs, targets_, yields_, q_value) tuple
-                        sigmas[xs_type] = np.sum(val[0])
+                        # (unit flux weighted) xs
+                        sigmas[xs_type] = np.sum(xs.get_xs_by_idx(idx))
                         if sigmas[xs_type] >= 0.:
                             all_zero = False
             # Now do the actinide evaluation
@@ -154,11 +153,12 @@ class Origen22Depletion(Depletion):
                 # Filter out stable isotopes
                 if decay.decay_constant > 0.:
                     # Filter out onnly those with sf decays
-                    if "sf" in decay:
-                        sf_data = decay["sf"]
+                    idx = decay.get_type_index('sf')
+                    if idx is not None:
+                        sf_br = decay.get_br_by_idx(idx)
                         # Make sure the branching ratio isn't 0
                         # the BR is the 0th index of the sf_data tuple
-                        if sf_data[0] > 0.:
+                        if sf_br > 0.:
                             has_sf_decay = True
 
             if nfy is not None and (sigmas['fission'] > 0. or has_sf_decay):
@@ -192,13 +192,16 @@ class Origen22Depletion(Depletion):
                         valid_types = valid_types + ("(n,3n)",)
                     else:
                         valid_types = valid_types + ("(n,a)", "(n,p)")
-                    for xs_type in nxs.keys():
-                        if xs_type in valid_types:
-                            xs, targets, yields, _ = nxs[xs_type]
+                    for xs_type in valid_types:
+                        idx = nxs.get_type_index(xs_type)
+                        if idx is not None:
+                            xs = nxs.get_xs_by_idx(idx)
                             onegrp_xs = np.sum(xs)
                             if onegrp_xs > 0.:
+                                targets, yields_ = \
+                                    nxs.get_targets_and_yields_by_idx(idx)
                                 for t in range(len(targets)):
-                                    if yields[t] > 0.:
+                                    if yields_[t] > 0.:
                                         next_level.add(targets[t])
 
                 # Now do the same for the decays
@@ -209,13 +212,15 @@ class Origen22Depletion(Depletion):
                                    "beta-,n")
                     if dk.decay_constant > 0.:
                         # Now just look for all non-zero yield targets
-                        for dk_type in dk.keys():
-                            # Filter to only the valid rxn types
-                            if dk_type in valid_types:
-                                br, targets, yields = dk[dk_type]
+                        for dk_type in valid_types:
+                            idx = dk.get_type_index(dk_type)
+                            if idx is not None:
+                                br = dk.get_br_by_idx(idx)
                                 if br > 0.:
+                                    targets, yields_ = \
+                                        dk.get_targets_and_yields_by_idx(idx)
                                     for t in range(len(targets)):
-                                        if yields[t] > 0.:
+                                        if yields_[t] > 0.:
                                             next_level.add(targets[t])
                 return next_level
 
@@ -299,9 +304,8 @@ class Origen22Depletion(Depletion):
 
         Returns
         -------
-        new_isos : Iterable of 3-tuple (str, str, bool)
-            A list of the isotope name (str), the xs library (str), and whether
-            it is depleting (bool). There is one of these 3-tuples per isotope.
+        new_isos : np.ndarray
+            The IsotopeRegistry indices of each isotope
         new_fracs : np.ndarray
             A 1-D vector containing the depleted atom fractions for each of
             the isotopes in new_isos
diff --git a/adder/reactor.py b/adder/reactor.py
index 69eee4e..6a5d3dd 100644
--- a/adder/reactor.py
+++ b/adder/reactor.py
@@ -16,12 +16,13 @@ import adder.cram as cram
 from adder.depletionlibrary import DepletionLibrary
 from adder.msr import MSRDepletion
 from adder.material import Material
+from adder.mcnp.tally import Tally
 from adder.neutronics import Neutronics
 from adder.depletion import Depletion
 from adder.type_checker import *
 from adder.control_group import ControlGroup
 from adder.utils import get_transform_args
-from adder.isotope import isotope_factory
+import adder.isotope
 
 
 class Reactor(LoggedClass):
@@ -114,10 +115,22 @@ class Reactor(LoggedClass):
         The standard deviation of the calculated k-eigenvalue for the
         current state point; value is 0.0 if a deterministic solver is
         used.
+    nu : float
+        Average number of neutrons per fission (if power > 0)
+    flux_normalization : float
+        Flux normalization factor if power set for depletion step
+        (otherwise = 1.0)
+    power_renormalization : float
+        Power re-normalization factor if renormalize_power_density flag is
+        set to True (otherwise = 1.0)
     control_groups : dict
         The set of control group information from the input file, including
         the current perturbation status. The key to the dict is the name and
         the value is an instance of a ControlGroup object.
+    user_tallies_adder_i : dict
+        The dict containing the information read from the ADDER input for user tallies
+    user_tally_res : dict
+        The dict containing the information read from the mctal output file for user tallies
     fast_forward : bool
         Whether this is a fast forward run (True) or not (False).
     """
@@ -157,8 +170,13 @@ class Reactor(LoggedClass):
         self.Q_recoverable = 200.0
         self.keff = 0.0
         self.keff_stddev = 0.0
+        self.nu = 0.0
+        self.flux_normalization = 1.0
+        self.power_renormalization = 1.0
         self.materials = None
         self.control_groups = {}
+        self.user_tallies_adder_i = {}
+        self.user_tally_res = {}
         self.fast_forward = False
 
         self.end_time = None
@@ -194,6 +212,25 @@ class Reactor(LoggedClass):
         check_type("depletion", depletion, Depletion)
         self._depletion = depletion
 
+    @property
+    def depletion_libs(self):
+        return self._depletion_libs
+
+    @depletion_libs.setter
+    def depletion_libs(self, libs):
+        check_type("depletion_libs", libs, dict)
+        self._depletion_libs = libs
+        # For our parallel region to be efficient, we do not want to have
+        # pickling of our massive data for each parallel region. Instead, if
+        # we make the libraries be globally accessible, then the Linux OS will
+        # use a copy-on-write technique so that no actual copies are done unless
+        # we write to the objects. We don't plan on writing these in the
+        # parallel region so that is fine. The items to pass to the library are
+        # the material and depletion libs.
+        global global_libs
+        global_libs = self._depletion_libs
+
+
     @property
     def materials(self):
         return self._materials
@@ -204,6 +241,15 @@ class Reactor(LoggedClass):
             check_iterable_type("materials", materials, Material,
                                 min_depth=1, max_depth=1)
         self._materials = materials
+        # For our parallel region to be efficient, we do not want to have
+        # pickling of our massive data for each parallel region. Instead, if
+        # we make the libraries be globally accessible, then the Linux OS will
+        # use a copy-on-write technique so that no actual copies are done unless
+        # we write to the objects. We don't plan on writing these in the
+        # parallel region so that is fine. The items to pass to the library are
+        # the material and depletion libs.
+        global global_mats
+        global_mats = self._materials
 
     @property
     def h5_filename(self):
@@ -313,6 +359,33 @@ class Reactor(LoggedClass):
         check_type("keff_stddev", keff_stddev, float)
         self._keff_stddev = keff_stddev
 
+    @property
+    def nu(self):
+        return self._nu
+
+    @nu.setter
+    def nu(self, nu):
+        check_type("nu", nu, float)
+        self._nu = nu
+
+    @property
+    def flux_normalization(self):
+        return self._flux_normalization
+
+    @flux_normalization.setter
+    def flux_normalization(self, flux_normalization):
+        check_type("flux_normalization", flux_normalization, float)
+        self._flux_normalization = flux_normalization
+
+    @property
+    def power_renormalization(self):
+        return self._power_renormalization
+
+    @power_renormalization.setter
+    def power_renormalization(self, power_renormalization):
+        check_type("power_renormalization", power_renormalization, float)
+        self._power_renormalization = power_renormalization
+
     @property
     def control_groups(self):
         return self._control_groups
@@ -322,6 +395,24 @@ class Reactor(LoggedClass):
         check_type("control_groups", control_groups, dict)
         self._control_groups = control_groups
 
+    @property
+    def user_tallies_adder_i(self):
+        return self._user_tallies_adder_i
+
+    @user_tallies_adder_i.setter
+    def user_tallies_adder_i(self, user_tallies_adder_i):
+        check_type("user_tallies_adder_i", user_tallies_adder_i, dict)
+        self._user_tallies_adder_i = user_tallies_adder_i
+
+    @property
+    def user_tally_res(self):
+        return self._user_tally_res
+
+    @user_tally_res.setter
+    def user_tally_res(self, user_tally_res):
+        check_type("user_tally_res", user_tally_res, dict)
+        self._user_tally_res = user_tally_res
+
     @property
     def total_volume(self):
         total_volume = 0.
@@ -340,18 +431,21 @@ class Reactor(LoggedClass):
         self.h5_file = h5py.File(self.h5_filename, "w", libver="latest")
 
         # Set the filetype and version
-        self.h5_file.attrs['filetype'] = np.string_(FILETYPE_REACTOR_H5)
+        self.h5_file.attrs['filetype'] = np.bytes_(FILETYPE_REACTOR_H5)
         self.h5_file.attrs['version'] = [VERSION_REACTOR_H5, 0]
 
         # Store the runtime options as root attributes
-        self.h5_file.attrs["name"] = np.string_(self.name)
+        self.h5_file.attrs["name"] = np.bytes_(self.name)
         self.neutronics.init_h5_file(self.h5_file)
         self.depletion.init_h5_file(self.h5_file)
 
         self.h5_file.attrs["begin_time"] = \
-            np.string_(self.begin_time.strftime(TIME_STRINGF))
+            np.bytes_(self.begin_time.strftime(TIME_STRINGF))
         self.h5_initialized = True
 
+        # TODO: Should add Isotope Registry to file before implementing a full
+        # restart capability
+
     def _open_h5(self):
         if self.h5_initialized:
             self.h5_file = h5py.File(self.h5_filename, "r+", libver="latest")
@@ -376,8 +470,8 @@ class Reactor(LoggedClass):
 
         # Create the group and assign attributes
         group = self.h5_file.create_group(group_name)
-        group.attrs["case_label"] = np.string_(self.case_label)
-        group.attrs["operation_label"] = np.string_(self.operation_label)
+        group.attrs["case_label"] = np.bytes_(self.case_label)
+        group.attrs["operation_label"] = np.bytes_(self.operation_label)
         group.attrs["step_idx"] = self.step_idx
         group.attrs["time"] = self.time
         group.attrs["power"] = self.power
@@ -385,15 +479,35 @@ class Reactor(LoggedClass):
         group.attrs["Q_recoverable"] = self.Q_recoverable
         group.attrs["keff"] = self.keff
         group.attrs["keff_stddev"] = self.keff_stddev
+        group.attrs["nu"] = self.nu
+        group.attrs["flux_normalization"] = self.flux_normalization 
+        group.attrs["power_renormalization"] = self.power_renormalization
         end_time = datetime.datetime.now()
         group.attrs["step_end_time"] = \
-            np.string_(end_time.strftime(TIME_STRINGF))
+            np.bytes_(end_time.strftime(TIME_STRINGF))
 
         # Materials info
         mats_group = group.create_group("materials")
+        # write dataset material
         for material in self.materials:
             material.to_hdf5(mats_group)
 
+        # Tallies info
+        # write dataset tallies
+        tallies_group = group.create_group("user_tallies")
+        if "user_tallies" in self.neutronics.__dir__():
+            for tally_id in self.neutronics.user_tallies.keys():
+                if tally_id not in self.user_tally_res.keys():
+                    # assignment of empty values to tally not simulated in MCNP
+                    self.neutronics.user_tallies[tally_id].tally_block = []
+                    self.neutronics.user_tallies[tally_id].facet_ids = []
+                    self.neutronics.user_tallies[tally_id].tally_matrix = np.array([])
+                    self.neutronics.user_tallies[tally_id].tally_matrix_err = np.array([])
+                # each tally, simulated or not, is saved into HDF5 file
+                self.neutronics.user_tallies[tally_id].to_hdf5(tallies_group)
+            self.user_tally_res = {}
+
+
         # Control group info
         ctrl_group = group.create_group("control_groups")
         for ctrl_object in self.control_groups.values():
@@ -409,7 +523,7 @@ class Reactor(LoggedClass):
         # Finalize H5
         self._open_h5()
         self.h5_file.attrs["end_time"] = \
-            np.string_(self.end_time.strftime(TIME_STRINGF))
+            np.bytes_(self.end_time.strftime(TIME_STRINGF))
         self.h5_file.close()
 
     def _flux_scaling_constant(self, nu, keff, use_power):
@@ -459,7 +573,7 @@ class Reactor(LoggedClass):
 
         return C
 
-    def _update_material_fluxes(self, flux, nu, keff, use_power):
+    def _update_material_fluxes(self, flux, nu, keff, use_power, is_zero_power):
         """Given a fluxes array, this method sets the fluxes within
         each current material object
 
@@ -475,38 +589,151 @@ class Reactor(LoggedClass):
             solve.
         use_power : bool
             Whether or not to use power (True) or flux (False).
+        is_zero_power : bool
+            Whether this is a zero power step (True) or not (False).
         """
 
-        zero_power = False
         if use_power:
-            if self.power == 0.:
-                zero_power = True
             # Reset the flux level attribute so we can accumulate it
             # here
             self.flux_level = 0.
-        else:
-            if self.flux_level == 0.:
-                zero_power = True
 
-        if not zero_power:
+        if not is_zero_power:
             flux_scaling = self._flux_scaling_constant(nu, keff, use_power)
+        else:
+            flux_scaling = 0.0
 
         for material in self.materials:
             if material.is_depleting and material.status == IN_CORE:
-                if not zero_power:
+                if not is_zero_power:
                     material.flux = flux[material.id] * flux_scaling
                 else:
                     material.flux = np.zeros(material.num_groups)
-                if use_power and not zero_power:
+                if use_power and not is_zero_power:
                     # Then we need to update the total flux level
                     self.flux_level += material.flux_1g * material.volume
             else:
                 material.flux = np.zeros(material.num_groups)
 
         # The last step is to normalize flux level by the total volume
-        if use_power and not zero_power:
+        if use_power and not is_zero_power:
             self.flux_level /= self.total_volume
 
+        # Update constants and normalizations
+        self.nu = nu
+        self.flux_normalization = flux_scaling
+
+    def _update_user_tallies(self, user_tally_res):
+        """Given the results read and processed from mctal, this method sets for tally objects
+        material_names, universe_names, facet_ids, tally_matrix and tally_matrix_err
+        Parameters
+        ----------
+        user_tally_res: dict
+        The results for user tallies, where the key is the tally id and nested dictionaries contain the results.
+        Tally results are normalized according to the flux normalization.
+        """
+
+        for tally_id in user_tally_res.keys():
+            self.neutronics.user_tallies[tally_id].tally_matrix = user_tally_res[tally_id]["tally_matrix"] * \
+                                                                  self.flux_normalization
+            self.neutronics.user_tallies[tally_id].tally_matrix_err = user_tally_res[tally_id]["tally_matrix_err"]
+            self.neutronics.user_tallies[tally_id].facet_ids = user_tally_res[tally_id]["facet_ids"]
+            self.neutronics.user_tallies[tally_id].material_names = user_tally_res[tally_id]["material_names"]
+            self.neutronics.user_tallies[tally_id].universe_names = user_tally_res[tally_id]["universe_names"]
+
+
+
+
+    def _update_material_fission_quantities(self, dt, 
+            renormalize_power_density=False):
+        """Given a depletion step duration, this method calculates the
+        power density (in W/cm3), fission density (in fissions/cm3) and
+        burnup (in MWd) for every material.
+
+        Parameters
+        ----------
+        dt : float
+            Duration (in days) of the depletion step, used to calculated
+            fission density and burnup
+        renormalize_power_density : bool, optional
+            If True, power density is renormalized to total input power
+        """
+        
+        reactor_power_check = 0.0
+        step_fiss_density = np.zeros(len(self.materials))
+
+        # Loop through materials and calculate fission-Q and fission rate 
+        for imat, material in enumerate(self.materials):
+            material_power = 0.0
+            material.power_density = 0.0
+            if material.is_depleting and material.status == IN_CORE:
+                # The flux has already been updated, so it only checks total
+                if self.flux_level > 0.0:
+                    # Calculate power density and fission density
+                    lib = self.depletion_libs[material.depl_lib_name]
+                    tot_Q, tot_fiss_rate = material.compute_Q(lib) 
+                    # Get power in MeV/s, convert to MW, divide by volume
+                    # to get power density in W/cm3
+                    material_power = tot_Q * JOULE_PER_EV
+                    reactor_power_check += material_power
+                    material.power_density = material_power * EV_PER_MEV \
+                                           / material.volume 
+                    # Calculate material fission density
+                    step_fiss_density[imat] = tot_fiss_rate * \
+                        dt * SECONDS_PER_DAY / material.volume
+                else:
+                    # Power density is 0
+                    # Fission density and burnup are unchanged
+                    material.power_density = 0.0
+        
+        # Calculate rel. diff. to input reactor power (if >0)
+        power_rel_diff = abs(reactor_power_check/self.power-1.) \
+                         if self.power else 0.0
+
+        # Now get re-normalization factor
+        norm_factor = 1.
+        if renormalize_power_density and self.power > 0.0:
+            norm_factor = self.power / reactor_power_check
+
+        # Provide user warnings
+        msgs = []
+        if power_rel_diff > POWER_PRECISION:
+            # If the cross-sections were *NOT* calculated notify user
+            if self.neutronics.use_depletion_library_xs:  
+                msgs.append("XS not updated at this step")
+            if renormalize_power_density:
+                # Warn user of the re-normalization
+                msg = "Power re-normalized from" + \
+                     f" {reactor_power_check:.2f} MW to" + \
+                     f" {self.power:.2f} MW"
+                msgs.append(msg)
+                msgs.append(f"  ({power_rel_diff*100.0:.2f}% diff.)")
+            else:
+                # Warn user of the power difference
+                msg = "Calculated power sums to" + \
+                     f" {reactor_power_check:.2f} MW," + \
+                     f" input power is {self.power:.2f} MW" 
+                msgs.append(msg)
+                msgs.append(f"  ({power_rel_diff*100.0:.2f}% diff.)")
+            for msg in msgs:
+                self.log("warning", msg, 10)
+
+        # Loop through materials to update power density and calculate burnup
+        reactor_power_check = 0
+        reactor_burnup_check = 0
+        for imat, material in enumerate(self.materials):
+            if step_fiss_density[imat]:
+                material.power_density *= norm_factor
+                material_power = \
+                    material.power_density * material.volume / EV_PER_MEV
+                material.fission_density += step_fiss_density[imat]
+                material.burnup += material_power * dt
+                reactor_power_check += material_power
+                reactor_burnup_check += material.burnup
+
+        # Record power renormalization factor
+        self.power_renormalization = norm_factor
+
     def _update_Q_recoverable(self):
         """Updates the recoverable energy from fission
         """
@@ -524,6 +751,8 @@ class Reactor(LoggedClass):
                     self.log("error", msg.format(material.name))
                 lib = self.depletion_libs[material.depl_lib_name]
                 mat_Q, mat_fiss_rate = material.compute_Q(lib)
+                self.update_logs(material.logs)
+                material.clear_logs()
                 tot_Q += mat_Q
                 tot_fiss_rate += mat_fiss_rate
 
@@ -533,14 +762,16 @@ class Reactor(LoggedClass):
         else:
             self.Q_recoverable = 0.
 
-    def _update_depletion_constants(self, flux, nu, keff, use_power, volumes):
+
+    def _update_depletion_constants(self, flux, nu, keff, use_power, volumes, user_tally_res,
+                          is_zero_power, dt, renormalize_power_density=False):
         """This method calculates Q_recoverable, scales and sets the
         fluxes for each material object.
 
         Parameters
         ----------
         flux : OrderedDict of np.ndarray
-            Dictionay where the key is the material id and the value is
+            Dictionary where the key is the material id and the value is
             the calculated group-wise flux for each material instance.
         nu : float
             Average number of neutrons produced per fission.
@@ -551,6 +782,18 @@ class Reactor(LoggedClass):
             Whether or not to use power (True) or flux (False).
         volumes : OrderedDict
             The material id is the key, the value is the volume in cm^3
+        user_tally_res : OrderedDict
+            The results for user tallies, listed for tally ids and for each
+            tally id: - multi-dimensional array with results,
+                      - cell ids, material ids, material names, related to the components
+                        "followed" by the tally
+        is_zero_power : bool
+            Whether this is a zero power step (True) or not (False).
+        dt : float
+            Duration of the depletion time step, used to calculated
+            fission densities and burnup values
+        renormalize_power_density : bool, optional
+            If True, power density is renormalized to total input power
         """
 
         # The fluxes are to be set using the scaling factor, and the
@@ -573,11 +816,20 @@ class Reactor(LoggedClass):
                 # Do it for every instance of the material in the model
                 material.volume = volumes[material.id]
 
-        # Now compute Q
-        self._update_Q_recoverable()
+        # Now compute Q if not a zero power step or simply set to zero otherwise
+        if is_zero_power:
+            self.Q_recoverable = 0.
+        else:
+            self._update_Q_recoverable()
 
         # Now we can determine the scaling factor and set the flux
-        self._update_material_fluxes(flux, nu, keff, use_power)
+        self._update_material_fluxes(flux, nu, keff, use_power, is_zero_power)
+        self._update_material_fission_quantities(dt,
+            renormalize_power_density=renormalize_power_density)
+
+        # Now update tallies
+        if "user_tallies" in self.neutronics.__dir__():
+            self._update_user_tallies(user_tally_res)
 
     def init_library(self, filename, library_name):
         """Initializes the depletion library
@@ -610,7 +862,7 @@ class Reactor(LoggedClass):
         for msg in msgs:
             self.log("info_file", msg, None)
 
-    def init_materials_and_input(self, neutronics_lib_file, depletion_lib_file,
+    def   init_materials_and_input(self, neutronics_lib_file, depletion_lib_file,
                                  depletion_lib_name, user_mats_info,
                                  user_univ_info, shuffled_mats, shuffled_univs):
         """Reads the base neutronics input file, stores the parsed
@@ -633,7 +885,9 @@ class Reactor(LoggedClass):
         user_mats_info : OrderedDict
             The keys are the ids in the neutronics solver and
             the value is an OrderedDict of the name, depleting boolean,
-            ex_core_status, and non_depleting_isotopes list.
+            volume, density, non_depleting_isotopes list, 
+            apply_reactivity_threshold_to_initial_inventory flag, and 
+            use_default_depletion_library flag.
         user_univ_info : OrderedDict
             The keys are the universe ids in the neutronics solver and
             the value is an OrderedDict of the name.
@@ -650,17 +904,26 @@ class Reactor(LoggedClass):
         check_type("user_mats_info", user_mats_info, OrderedDict)
         check_type("user_univ_info", user_univ_info, OrderedDict)
 
-        # Initialize the library information
+        # Initialize the depletion library information
         self.init_library(depletion_lib_file, depletion_lib_name)
         default_depl_lib = self.depletion_libs[BASE_LIB]
 
         # Define the materials and other information from the neutronics
         # model definitinon
         self.log("info", "Processing Neutronics Input", 4)
+        neutronics_library_isos = self.neutronics.parse_library(
+            neutronics_lib_file)
+
+        # Set up the isotope registry [we do this after printing
+        # Processing Neutronics Input bc self.neutronics.parse_library does the
+        # input parsing and that can take a while, but we need to do before
+        # self.neutronics.read_input too]
+        adder.isotope.ISO_REGISTRY = \
+            adder.isotope.IsotopeRegistry(neutronics_library_isos)
+
         materials = self.neutronics.read_input(
-            neutronics_lib_file, default_depl_lib.num_neutron_groups,
-            user_mats_info, user_univ_info, shuffled_mats, shuffled_univs,
-            self.depletion_libs)
+            default_depl_lib.num_neutron_groups, user_mats_info,
+            user_univ_info, shuffled_mats, shuffled_univs, self.depletion_libs)
 
         # Now add the materials to the Reactor class
         self.materials = materials
@@ -681,18 +944,49 @@ class Reactor(LoggedClass):
                     pass
         self.log_materials()
 
+        # Finally ensure the isotope registry has the depletion library info
+        # for each and every type of isotope we expect
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            self.depletion_libs, self.materials)
+
+    def validate_storage_materials(self):
+        """Cycle through the materials list and check whether there are any 
+        storage materials that:
+        - have no density assigned: ADDER should exit with an error
+        - have no unique depletion library assigned: this is all the supply
+            materials that are re-defined as storage in the ADDER input file 
+        Materials are modified in place.
+        """
+        # Cycle through materials
+        for mat in self.materials:
+            if mat.status == STORAGE:
+                # Check if density was assigned to material
+                if not mat.density:
+                    # Error: storage element without a density value assigned
+                    msg = f"Storage material {mat.name} was not assigned a "\
+                           "density in the ADDER input file"
+                    self.log("error", msg)
+                # Initialize depletion libraries for storage materials
+                elif (not self.neutronics.use_depletion_library_xs and
+                    not mat.is_default_depletion_library):
+                    default_depl_lib = self.depletion_libs[BASE_LIB]
+                    new_lib = default_depl_lib.clone(new_name=mat.name)
+                    self.depletion_libs[new_lib.name] = new_lib
+                    mat.depl_lib_name = new_lib.name
+
     def _parallel_depletion_manager(self, dt, depletion_step, num_substeps):
         """Executes the depletion in parallel"""
 
         if dt <= 0.:
             return
 
-        # Gather an iterator of all of the materials to deplete
-        depl_mats = ((i, mat, self.depletion_libs[mat.depl_lib_name])
-                     for i, mat in enumerate(self.materials) if
-                     (mat.is_depleting and mat.status != SUPPLY))
+        # Determine the number of depleting materials
+        num_depl_mats = len(list((i for i, mat in enumerate(self._materials) if
+                                  (mat.is_depleting and
+                                   mat.status != adder.constants.SUPPLY))))
+
         msg = "Depleting {:,} Materials with {} Thread".format(
-            len(self.materials), self.depletion.num_threads)
+            num_depl_mats, self.depletion.num_threads)
         if self.depletion.num_threads > 1:
             # Make it plural
             msg += "s"
@@ -704,72 +998,76 @@ class Reactor(LoggedClass):
         # every time
         self.depletion.compute_decay(self.depletion_libs[BASE_LIB])
 
-        # Compute the actual libraries
-        self.log("info", "Computing Libraries", 10)
-        data = []
+        # Perform the depletion
+        self.log("info", "Executing Depletion", 10)
         weak_deplete = weakref.proxy(self.depletion)
-        args_list = ((i, weak_deplete, mat.flux, lib)
-                     for i, mat, lib in depl_mats)
+        mat_idxs = (i for i, mat in enumerate(self._materials) if
+                    (mat.is_depleting and mat.status != adder.constants.SUPPLY))
         if self.depletion.num_threads == 1:
-            for args in args_list:
-                i, mtx, idxs, inv_idxs = library_worker(args)
-                data.append((i, self.materials[i], mtx, idxs, inv_idxs))
-        else:
-            chunksize = self.depletion.chunksize
-            tasksperchild = 1
-            with mp.Pool(processes=self.depletion.num_threads,
-                         maxtasksperchild=tasksperchild) as pool:
-                for i, mtx, idxs, inv_idxs in pool.imap(library_worker,
-                                                        args_list,
-                                                        chunksize=chunksize):
-                    data.append((i, self.materials[i], mtx, idxs, inv_idxs))
+            for i_mat in mat_idxs:
+                mat = self._materials[i_mat]
+                flux = mat.flux
+                lib = self.depletion_libs[mat.depl_lib_name]
+                matrix = weak_deplete.compute_library(lib, flux)
 
-        self.log("info", "Executing Depletion", 10)
-        # Provide single-threaded case for debugging
-        if self.depletion.num_threads == 1:
-            for i, mat, mtx, idxs, inv_idxs in data:
                 try:
                     new_isos, new_fracs, new_density = \
-                        self.depletion.execute(
-                            mat, mtx, idxs, inv_idxs, dt,
-                            depletion_step, num_substeps, True)
+                        weak_deplete.execute(mat, matrix,
+                                             lib.isotope_indices,
+                                             lib.inverse_isotope_indices, dt,
+                                             depletion_step, num_substeps,
+                                             True)
                 except Exception:
                     error_msg = traceback.format_exc()
-                    self.log("error", error_msg)
-                mat.apply_new_composition(new_isos, new_fracs, new_density)
+                    print(error_msg)
+                self._materials[i_mat].apply_new_composition(
+                    new_isos, new_fracs, new_density)
         else:
-            # Do the parallel processing of depletion
+
+            # Calculate chunksize
+            if weak_deplete.chunksize == 0:
+                chunksize, extra = divmod(num_depl_mats,
+                                    weak_deplete.num_threads * CHUNKSIZE_FACTOR)
+                if extra:
+                    chunksize += 1
+
+                # Check to make sure chunksize is an integer greater than zero
+                chunksize = int(chunksize)
+                if chunksize < 1:
+                    chunksize = 1
+
+            else:
+                chunksize = weak_deplete.chunksize
+
+            # Do the parallel processing
             errors = []
-            chunksize = self.depletion.chunksize
-            tasksperchild = 1
+
             with mp.Pool(
-                    processes=self.depletion.num_threads,
-                    initializer=par_depl_init,
-                    initargs=(weak_deplete, dt, depletion_step, num_substeps),
-                    maxtasksperchild=tasksperchild) as pool:
-                for i, new_isos, new_fracs, new_density \
-                    in pool.imap_unordered(depletion_worker, data,
+                processes=weak_deplete.num_threads,
+                initializer=parallel_init,
+                initargs=(weak_deplete, dt, depletion_step, num_substeps)) as pool:
+                for i_mat, new_isos, new_fracs, new_density \
+                    in pool.imap_unordered(parallel_worker, mat_idxs,
                                            chunksize=chunksize):
                     if isinstance(new_isos, str):
-                        errors.append((i, new_isos))
+                        errors.append((i_mat, new_isos))
                     else:
-                        self.materials[i].apply_new_composition(
+                        self._materials[i_mat].apply_new_composition(
                             new_isos, new_fracs, new_density)
 
             # Now we handle the errors. They *may* be due to parallel system
-            # issues (file I/O, etc), so lets just run the few cases in
-            # parallel
+            # issues (file I/O, etc), so lets just run the few cases in serial
             if len(errors) > 0:
                 # Now raise the error messages
                 msg = "The Following Materials Encountered Errors While " + \
                     "Processed in Parallel:"
                 self.log("info_file", msg)
-                for i, error in errors:
+                for i_mat, error in errors:
                     self.log("info_file", error)
                 self.log("info", "Rerunning Failed Depletions", 8)
                 # And re-run in serial
-                for i, _ in errors:
-                    mat = self.materials[i]
+                for i_mat, _ in errors:
+                    mat = self.materials[i_mat]
                     lib = self.depletion_libs[mat.depl_lib_name]
                     mtx = self.depletion.compute_library(lib, mat.flux),
                     idxs = lib.isotope_indices
@@ -784,12 +1082,15 @@ class Reactor(LoggedClass):
                     mat.apply_new_composition(new_isos, new_fracs, new_density)
 
     def _deplete_step(self, log_msg, dt, depletion_step, use_power,
-                      num_substeps, is_zero_power, is_endpoint=False,
-                      is_corrector_step=False, label=None):
+                      num_substeps, is_zero_power, user_tallies_adder_i,
+                      include_user_tallies, is_endpoint=False, is_corrector_step=False,
+                      is_cecm=False, label=None,
+                      renormalize_power_density=False):
         """Advances one step, factoring in if the neutronics computation
         is necessary or not."""
 
         self.log("info", log_msg, 8)
+        user_tally_res={}
 
         if label is None:
             step_label = "{}; {}: {}".format(self.case_label,
@@ -800,7 +1101,6 @@ class Reactor(LoggedClass):
         if not is_zero_power:
             # Set the defaults, applicable primarily to predictor step
             store_input = True
-            user_tallies = True
             user_output = True
             deplete_tallies = True
             fname = \
@@ -813,21 +1113,24 @@ class Reactor(LoggedClass):
                                           self.step_idx) + "e"
             elif is_corrector_step:
                 store_input = False
-                user_tallies = False
+                user_tallies_adder_i = {}
+                include_user_tallies = False
                 user_output = False
                 fname = STEP_FNAME.format(self.case_idx, self.operation_idx,
                                           self.step_idx) + "c"
 
             # Execute the neutronics solver and get the results
-            keff, keff_stddev, flux, nu, volumes = \
+            keff, keff_stddev, flux, nu, volumes, user_tally_res = \
                 self.neutronics.execute(fname, step_label, self.materials,
                                         self.depletion_libs, store_input,
-                                        deplete_tallies, user_tallies,
-                                        user_output, self.fast_forward)
+                                        deplete_tallies, user_tallies_adder_i,
+                                        include_user_tallies, user_output,
+                                        self.fast_forward)
+            self.user_tally_res = user_tally_res
         else:
             # Set the dummy values we need to so the rest of the
             # processing can proceed
-            keff, keff_stddev = 0.0, 0.0
+            keff, keff_stddev, nu = 0.0, 0.0, 0.0
 
             # Create a flux result that has 0s, and get the volumes
             # from the last time
@@ -842,9 +1145,8 @@ class Reactor(LoggedClass):
             # time through the above loop just to get the num of groups
             flux = OrderedDict.fromkeys(mat_ids,
                                         value=np.zeros(material.num_groups))
-
-            # Nu will just be 1.0 since it doesnt matter
-            nu = 1.0
+            # user tally res to zero
+            user_tally_res = {}
             fname = "none"
 
         # Store the output filename
@@ -856,8 +1158,14 @@ class Reactor(LoggedClass):
 
         # Update the depletion constants before we print to file
         if not is_endpoint:
-            self._update_depletion_constants(flux, nu, keff, use_power,
-                                             volumes)
+            if is_cecm:
+                dt_fission = 0. if is_corrector_step else dt*2.
+            else:
+                dt_fission = dt
+            self._update_depletion_constants(flux, nu, keff, use_power,volumes,
+                                              user_tally_res, is_zero_power, dt_fission,
+                                             renormalize_power_density=renormalize_power_density)
+
 
         if not is_corrector_step:
             # Store the results to the HDF5 file
@@ -871,7 +1179,8 @@ class Reactor(LoggedClass):
 
         return output_name
 
-    def _deplete_cecm(self, dt, depletion_step, use_power, num_substeps):
+    def _deplete_cecm(self, dt, depletion_step, use_power, num_substeps,
+                      user_tallies_adder_i, include_user_tallies, renormalize_power_density=False):
         """Performs the CE/CM method (constant extrap on predictor and
         constant midpoint on corrector, i.e., predictor-corrector."""
 
@@ -890,7 +1199,9 @@ class Reactor(LoggedClass):
                                                      self.operation_label, dt)
         fname = self._deplete_step(log_msg, 0.5 * dt, depletion_step,
                                    use_power, num_substeps, False,
-                                   label=step_label)
+                                   user_tallies_adder_i, include_user_tallies,
+                                   is_cecm = True, label = step_label,
+                                   renormalize_power_density = renormalize_power_density)
 
         # Now with the inventories from the half-time step
         # (from predictor), we re-compute the fluxes in the next
@@ -900,8 +1211,10 @@ class Reactor(LoggedClass):
         step_label = "{}; {}: {} [corrector]".format(self.case_label,
                                                      self.operation_label, dt)
         fname = self._deplete_step(log_msg, dt, depletion_step, use_power,
-                                   num_substeps, False, is_corrector_step=True,
-                                   label=step_label)
+                                   num_substeps, False,  user_tallies_adder_i,
+                                   include_user_tallies, is_corrector_step=True,
+                                   is_cecm = True, label = step_label,
+                                   renormalize_power_density = renormalize_power_density)
 
         # Now put the original material inventories back in so we can
         # do the corrector step depletion
@@ -919,8 +1232,10 @@ class Reactor(LoggedClass):
         return fname
 
     def deplete(self, delta_ts, cumulative_time_steps, powers,
-                fluxes, num_substeps=0, solution_method="cecm",
-                execute_endpoint=True):
+                fluxes,  user_tallies_adder_i, include_user_tallies,
+                num_substeps=0, solution_method="cecm", execute_endpoint=True,
+                renormalize_power_density=False):
+
         """Deplete the model according to a given power history.
 
         Parameters
@@ -947,6 +1262,10 @@ class Reactor(LoggedClass):
             option, the classical predictor-corrector approach.
         execute_endpoint : bool, optional
             Whether the last neutronics computation should be computed or not.
+        user_tallies: dict
+            Dictionary of tally objects with keys corresponding to their identifiers.
+        renormalize_power_density : bool, optional
+            If True, power density is renormalized to total input power.
         """
 
         # Handle selection of power or flux as an input
@@ -1007,7 +1326,9 @@ class Reactor(LoggedClass):
                 log_msg = "Executing Zero-Power Depletion"
                 output_file = \
                     self._deplete_step(log_msg, delta_ts[i], depletion_step,
-                                       use_power, num_substeps, True)
+                                       use_power, num_substeps, True,
+                                       user_tallies_adder_i, include_user_tallies,
+                                       renormalize_power_density = renormalize_power_density)
             else:
 
                 if delta_ts[i] == 0.:
@@ -1015,20 +1336,25 @@ class Reactor(LoggedClass):
                     output_file = \
                         self._deplete_step(log_msg, delta_ts[i],
                                            depletion_step, use_power,
-                                           num_substeps, False)
-
+                                           num_substeps, False,
+                                           user_tallies_adder_i, include_user_tallies,
+                                           renormalize_power_density = renormalize_power_density)
                 else:
                     if solution_method == "predictor":
                         log_msg = "Executing Predictor"
                         output_file = \
                             self._deplete_step(log_msg, delta_ts[i],
                                                depletion_step, use_power,
-                                               num_substeps, False)
+                                               num_substeps, False,
+                                               user_tallies_adder_i, include_user_tallies,
+                                               renormalize_power_density = renormalize_power_density)
 
                     elif solution_method == "cecm":
                         output_file = \
                             self._deplete_cecm(delta_ts[i], depletion_step,
-                                               use_power, num_substeps)
+                                               use_power, num_substeps,
+                                               user_tallies_adder_i, include_user_tallies,
+                                               renormalize_power_density = renormalize_power_density)
 
             # Advance our time and update states accordingly
             start_time = end_time
@@ -1056,7 +1382,9 @@ class Reactor(LoggedClass):
             log_msg = "Evaluating {} End Point".format(self.operation_label)
             output_file = self._deplete_step(log_msg, 0., depletion_step,
                                             use_power, num_substeps,
-                                            zero_power, is_endpoint=True)
+                                            zero_power, user_tallies_adder_i,
+                                            include_user_tallies, is_endpoint=True,
+                                            renormalize_power_density = renormalize_power_density)
             self.step_idx += 1
 
     def shuffle(self, start_name, to_names, shuffle_type):
@@ -1099,7 +1427,7 @@ class Reactor(LoggedClass):
                                 self.materials, self.depletion_libs)
 
     def transform(self, names, yaw, pitch, roll, angle_units, matrix,
-                  displacement, transform_type):
+                  displacement, transform_type, matrix_notation, reset):
         """Transforms the universe named `name` according to the angles in
         yaw, pitch, and roll and the translation in displacement.
 
@@ -1127,7 +1455,14 @@ class Reactor(LoggedClass):
             The type of object to transform; this depends on the actual
             neutronics solver type; this could be "material" or
             "universe", for example.
-
+        matrix_notation : {"common", "mcnp"}
+            The notation used to define the rotation matrix. The matrix with
+            the MCNP notation corresponds to the transpose of the matrix defined
+            w/ the common mathematical notation ("common") to perform geometrical 
+            rotation.
+        reset : bool
+            If True, the position of the entity is reset to the initial one 
+            provided in the MCNP base input file.
         """
 
         if transform_type == "group":
@@ -1143,6 +1478,8 @@ class Reactor(LoggedClass):
             msg += ")"
         else:
             msg = "Transforming {} {}".format(transform_type, names[0])
+        if reset:
+            msg += " (after being reset to initial location)"
         self.log("info", msg, 6)
 
         # Extract group info, if provided
@@ -1159,24 +1496,26 @@ class Reactor(LoggedClass):
                 yaw_, pitch_, roll_, displacement_ = \
                     get_transform_args(val, axis_)
                 matrix_ = None
+                matrix_notation_="mcnp"
             else:
                 msg = "Invalid Control Group {}".format(names)
                 self.log("error", msg)
         else:
             # Just provide the re-name of variables
             names_, yaw_, pitch_, roll_, angle_units_, matrix_, displacement_, \
-                transform_type_ = \
+                transform_type_, matrix_notation_ = \
                 names, yaw, pitch, roll, angle_units, matrix, displacement, \
-                transform_type
+                transform_type, matrix_notation
 
         self.neutronics.transform(names_, yaw_, pitch_, roll_, angle_units_,
-                                  matrix_, displacement_, transform_type_)
+                                  matrix_, displacement_, transform_type_,
+                                  matrix_notation=matrix_notation_,reset=reset)
 
         # Modify group displacement as needed
         if transform_type == "group":
             self.control_groups[names].displacement = val
 
-    def geom_sweep(self, group_name, values):
+    def geom_sweep(self, group_name, values, user_tallies_adder_i):
         """Performs a sweep of geometric transformations and executes the
         neutronics solver on each, storing the results for the user. This is
         useful for performing rod sweeps, for example.
@@ -1215,7 +1554,7 @@ class Reactor(LoggedClass):
 
         # Set the default values to use for each case
         store_input = False
-        user_tallies = True
+        include_user_tallies = False
         user_output = True
         deplete_tallies = False
         # Sweep through each of the deltas, setup our transform,
@@ -1227,7 +1566,7 @@ class Reactor(LoggedClass):
             # Perform the transform
             self.neutronics.transform(names, yaw, pitch, roll, angle_units,
                                       matrix, displacement, transform_type,
-                                      transform_in_place=False)
+                                      transform_in_place=False, reset=False)
 
             # Execute the neutronics solver for this case
             fname = STEP_FNAME.format(self.case_idx, self.operation_idx,
@@ -1238,12 +1577,12 @@ class Reactor(LoggedClass):
                 update_iso_status = True
             else:
                 update_iso_status = False
-            keff, keff_stddev, _, _, _ = \
+            keff, keff_stddev, _, _, _, _ = \
                 self.neutronics.execute(fname, step_label, self.materials,
                                         self.depletion_libs, store_input,
-                                        deplete_tallies, user_tallies,
-                                        user_output, self.fast_forward,
-                                        update_iso_status)
+                                        deplete_tallies, user_tallies_adder_i,
+                                        include_user_tallies, user_output,
+                                        self.fast_forward,update_iso_status)
 
             # And store results
             self.keff = keff
@@ -1259,11 +1598,12 @@ class Reactor(LoggedClass):
         yaw, pitch, roll, displacement = get_transform_args(-values[-1], axis)
         self.neutronics.transform(names, yaw, pitch, roll, angle_units,
                                   matrix, displacement, transform_type,
-                                  transform_in_place=False)
+                                  transform_in_place=False, reset=False) 
 
-    def geom_search(self, group_name, k_target, bracket_interval,
-                    target_interval, uncertainty_fraction, initial_guess,
-                    min_active_batches, max_iterations):
+    def geom_search(self, group_name, k_target, bracket_interval, 
+                    reference_position, target_interval, 
+                    uncertainty_fraction, 
+                    initial_guess, min_active_batches, max_iterations):
         """Performs a search of geometric transformations to identify that
         which yields the target k-eigenvalue within the specified interval.
 
@@ -1275,14 +1615,20 @@ class Reactor(LoggedClass):
             The target k-eigenvalue to search for
         bracket_interval : Iterable of float
             The lower and upper end of the ranges to search.
+        reference_position : str or float
+            The reference point for the bracket_interval values.
+            'initial' denotes the initial position of the
+            control group in the neutronics input; whereas
+            'last' referes to the last known position of the
+            control group. If float, the value is the position.
         target_interval : float
             The range around the k_target for which is considered success
         uncertainty_fraction : float
             This parameter sets the stochastic uncertainty to target when the
             initial computation of an iteration reveals that a viable solution
             may exist.
-        initial_guess : float
-            The starting point to search
+        initial_guess : float or str
+            The starting point to search. If "last", use the last position.
         min_active_batches : int
             The starting number of batches to run to ensure enough keff samples
             so that it follows the law of large numbers. This is the number of
@@ -1303,23 +1649,62 @@ class Reactor(LoggedClass):
             axis = grp.axis
             transform_type = grp.type
             angle_units = grp.angle_units
-            val = -grp.displacement
-            if val != 0.:
-                yaw, pitch, roll, displacement = get_transform_args(val, axis)
-                self.neutronics.transform(names, yaw, pitch, roll,
-                                          angle_units, matrix, displacement,
-                                          transform_type,
-                                          transform_in_place=False)
+            # Define reference position for the bracket_interval 
+            # and set initial_guess
+            if reference_position == "initial": 
+                val = 0.0
+                reset = True
+                msg =  'Reference position (0.0 of interval) set to "initial".'
+                if initial_guess == "last":
+                    attempt_guess = grp.displacement
+            elif reference_position == "last":
+                val = 0.0
+                reset = False
+                msg = 'Reference position (0.0 of interval) set to "last".'
+                if initial_guess == "last":
+                    attempt_guess = 0.0
+            else:
+                val = float(reference_position)
+                reset = True
+                msg = 'Reference position (0.0 of interval) set to specific value.'
+                if initial_guess == "last":
+                    attempt_guess = grp.displacement - val
+            self.log("info", msg, 6)
+
+
+            yaw, pitch, roll, displacement = get_transform_args(val, axis)
+            self.neutronics.transform(names, yaw, pitch, roll,
+                                      angle_units, matrix, displacement,
+                                      transform_type,
+                                      transform_in_place=False, reset=reset)
         else:
             msg = "Invalid Control Group {}".format(group_name)
             self.log("error", msg)
 
+        # Reset the attempt_guess to the upper limit of the bracket_interval 
+        # if the last position is not within it
+        if initial_guess == "last":
+            if (attempt_guess <= bracket_interval[0] or 
+                attempt_guess > bracket_interval[1]):
+                attempt_guess = bracket_interval[1]
+                msg = 'Last position outside of bracket interval. '
+                msg += 'Using upper bound as initial guess.'
+                initial_guess = bracket_interval[1]
+            else:
+                msg = 'Using last position as initial guess.'
+                initial_guess = attempt_guess
+            self.log("info", msg, 6)
+        elif not initial_guess == bracket_interval[1]:
+            self.log("info", f'Using {initial_guess:.3f} as initial guess.', 6)
+        
+        # Perform search
         converged, iterations, value, keff, keff_stddev = \
             self.neutronics.geom_search(transform_type, axis, names,
-                angle_units, k_target, bracket_interval, target_interval,
+                angle_units, k_target, bracket_interval, reference_position, 
+                target_interval,
                 uncertainty_fraction, initial_guess, min_active_batches,
                 max_iterations, self.materials, self.case_idx,
-                self.operation_idx, self.depletion_libs)
+                self.operation_idx, self.depletion_libs, self.user_tallies_adder_i)
 
         # Print the log messages
         if converged and value not in bracket_interval:
@@ -1343,11 +1728,11 @@ class Reactor(LoggedClass):
         yaw, pitch, roll, displacement = get_transform_args(value, axis)
         self.neutronics.transform(names, yaw, pitch, roll, angle_units,
                                   matrix, displacement, transform_type,
-                                  transform_in_place=False)
+                                  transform_in_place=False, reset=False)
 
         # Update results
         self.keff = keff
-        self.keff_stddev = self.keff
+        self.keff_stddev = keff_stddev
         self.control_groups[group_name].displacement = value
         self.update_hdf5()
 
@@ -1575,8 +1960,8 @@ class Reactor(LoggedClass):
 
         return this
 
-    def write_neutronics_input(self, fname, deplete_tallies, user_tallies,
-                               user_output):
+    def write_neutronics_input(self, fname, deplete_tallies, user_tallies_adder_i,
+                               include_user_tallies, user_output):
         """This method writes the neutronics input to disk
 
         Parameters
@@ -1587,7 +1972,9 @@ class Reactor(LoggedClass):
             The options relevant to each neutronics solver
         deplete_tallies : bool
             Whether or not to write the tallies needed for depletion
-        user_tallies : bool
+        user_tallies_adder_i : dict
+            Whether or not to write the user tallies
+        include_user_tallies : dict
             Whether or not to write the user tallies
         user_output : bool
             Whether or not to write the user's output control cards
@@ -1598,7 +1985,8 @@ class Reactor(LoggedClass):
                                   self.step_idx)
         self.neutronics.write_input(fname, label, self.materials,
                                     self.depletion_libs, False,
-                                    deplete_tallies, user_tallies, user_output)
+                                    deplete_tallies, user_tallies_adder_i,
+                                    include_user_tallies, user_output)
         self.update_hdf5()
 
     def process_operations(self, ops, no_deplete, fast_forward):
@@ -1630,19 +2018,30 @@ class Reactor(LoggedClass):
         # Now process the operations
         self.log("info", "Processing Operations", 0)
         self.operation_idx = 0
+
+        current_case = ""
         for op in ops:
             self.step_idx = 1
             if len(op) == 4:
-                # Then this includs the case label too, so lets print and assign it
+                current_op = ""
+                # Then this include the case label too, so lets print and assign it
                 case_label, op_label, method_name, method_args = op[:]
-                self.log("info", "Executing Case Block: {}".format(case_label))
-                # And update the case label
-                self.case_label = case_label
-                self.case_idx += 1
-                self.operation_idx = 1
+                # if statement to avoid multiple increment on the same case subsection
+                if current_case != case_label:
+                    current_case = case_label
+                    self.log("info", "Executing Case Block: {}".format(case_label))
+                    # And update the case label
+                    self.case_label = case_label
+                    self.case_idx += 1
+                    self.operation_idx = 1
+
             else:
                 op_label, method_name, method_args = op[:]
-                self.operation_idx += 1
+                # if to avoid multiple increment on the same operation subsection
+                if current_op != op_label:
+                    current_op = op_label
+                    self.operation_idx += 1
+
             # Assign the operation label
             self.operation_label = op_label
             self.log("info", "Executing Operation: {}".format(op_label), 4)
@@ -1723,7 +2122,7 @@ def get_depletion(solver_type, exec_cmd, num_threads, num_procs, chunksize):
         return Depletion(exec_cmd, num_threads, num_procs, chunksize)
 
 
-def par_depl_init(my_depletion, my_dt, my_depletion_step, my_num_substeps):
+def parallel_init(my_depletion, my_dt, my_step, my_substeps):
     # Pre-load the variables for the depletion worker, this is one way that
     # is used to pass multiple arguments to a parallelized function (here,
     # that parallelized func is depletion_worker). Separate benchmarking
@@ -1736,25 +2135,22 @@ def par_depl_init(my_depletion, my_dt, my_depletion_step, my_num_substeps):
 
     depletion = my_depletion
     dt = my_dt
-    depletion_step = my_depletion_step
-    num_substeps = my_num_substeps
+    depletion_step = my_step
+    num_substeps = my_substeps
 
 
-def depletion_worker(args):
-    i, mat, mtx, idxs, inv_idxs = args
+def parallel_worker(i_mat):
+    mat = global_mats[i_mat]
+    lib = global_libs[mat.depl_lib_name]
+    matrix = depletion.compute_library(lib, mat._flux)
 
-    # Handle exceptions gracefully at the highest level.
     try:
-        result = depletion.execute(mat, mtx, idxs, inv_idxs, dt,
+        result = depletion.execute(mat, matrix, lib.isotope_indices,
+                                   lib.inverse_isotope_indices, dt,
                                    depletion_step, num_substeps, False)
-        result = (i, *result)
+        result = (i_mat, *result)
     except Exception:
         # instead, convert the traceback to an error string
         error = traceback.format_exc()
-        result = (i, error, None, None)
+        result = (i_mat, error, None, None)
     return result
-
-def library_worker(args):
-    i, depletion, flux, lib = args
-    return (i, depletion.compute_library(lib, flux),
-            lib.isotope_indices, lib.inverse_isotope_indices)
diff --git a/scripts/adder_extract_materials.py b/scripts/adder_extract_materials.py
index fca9d97..48c1f1c 100755
--- a/scripts/adder_extract_materials.py
+++ b/scripts/adder_extract_materials.py
@@ -54,6 +54,9 @@ def get_data(h5_file, mat_name):
     keffs_stddev = []
     powers = []
     fluxes_1grp = []
+    power_densities = []
+    burnups = []
+    fission_densities = []
     Q_recs = []
     isotope_data = []
     isotope_set = set()
@@ -71,11 +74,14 @@ def get_data(h5_file, mat_name):
             powers.append(grp.attrs["power"])
             Q_recs.append(grp.attrs["Q_recoverable"])
             fluxes_1grp.append(np.sum(material.flux))
+            power_densities.append(material.power_density)
+            burnups.append(material.burnup)
+            fission_densities.append(material.fission_density)
 
             isotope_info = defaultdict(lambda: 0.0)
-            for i in range(len(material.isotopes)):
-                isotope_info[material.isotopes[i].name] = \
-                    material.number_densities[i]
+            for i in range(material.num_isotopes):
+                iso = material.isotope_obj(i)
+                isotope_info[iso.name] = material.number_densities[i]
             isotope_set.update(isotope_info.keys())
             isotope_data.append(isotope_info)
 
@@ -88,6 +94,9 @@ def get_data(h5_file, mat_name):
     results['keffs'] = keffs
     results['keffs_stddev'] = keffs_stddev
     results['fluxes_1grp'] = fluxes_1grp
+    results['power_densities'] = power_densities 
+    results['burnups'] = burnups
+    results['fission_densities'] = fission_densities
     results['Q_recs'] = Q_recs
     results['isotope_data'] = isotope_data
     results['isotope_set'] = sorted(list(isotope_set))
diff --git a/setup.py b/setup.py
index f0fec24..2c04f65 100644
--- a/setup.py
+++ b/setup.py
@@ -22,8 +22,8 @@ kwargs = {
     'scripts': glob.glob('scripts/adder_*'),
 
     # Metadata
-    'author': 'Adam Nelson',
-    'author_email': 'agnelson@anl.gov',
+    'author': 'Research and Test Reactor Department - Argonne National Laboratory',
+    'author_email': 'adder@anl.gov',
     'description': 'ADDER',
     'url': 'https://svn.inside.anl.gov/repos/adder/',
     'classifiers': [
@@ -34,12 +34,12 @@ kwargs = {
         'Natural Language :: English',
         'Topic :: Scientific/Engineering'
         'Programming Language :: Python :: 3',
-        'Programming Language :: Python :: 3.7',
+        'Programming Language :: Python :: 3.8',
     ],
 
     # Required dependencies
     'install_requires': [
-        'numpy', 'h5py', "configobj", "scipy", "pytest"
+        'numpy', 'h5py', "configobj", "scipy", "pytest", "pyparsing"
     ],
 
     # Optional dependencies
diff --git a/tests/__init__.py b/tests/__init__.py
index 6387736..5a730fa 100644
--- a/tests/__init__.py
+++ b/tests/__init__.py
@@ -175,7 +175,21 @@ si2 0 20
 sp2 0 1
 si3 0 20
 sp3 0 1
+f14:n 11 12
+e14 1. 20
+fc24 testing
+f24:n 41
+fm24 (1. 11 (-1 103))
+fc44 flux in mat cell replaced by supply
+f44:n 42
+f6:n,p 42
+tm44 4 6
 FMESH4:n ORIGIN=0,0,0 IMESH=10,20 JMESH=10,20 KMESH=10,20 TYPE=FLUX
+E0:n 1E-5 1E-3
+tm0 1 2
+c0 -.866 -.5 0 .5 .866 1
+t0 2 4
+DF0 IC 40 IU 1 LIN FAC 123.4
 """
 
 
@@ -188,7 +202,7 @@ mcnp_lattice = """simple lattice
      10  2(2)  5  6 10
      10  7  8  9 10
      10 10 10 10 10
-11 1 2.0 -10 u=1 imp:n=1 vol=0.528101
+11 1 2.0 -10 u=1 imp:n=1 vol = 0.528101
 21 2 2.0 -10 u=2 imp:n=1 vol=0.528101
 31 3 2.0 -10 u=3 imp:n=1 vol=0.528101
 41 4 2.0 -10 u=4 imp:n=1 vol=0.528101
@@ -203,7 +217,7 @@ mcnp_lattice = """simple lattice
 20 like 10 but u=2
 30 10 1.0 +10 u=3 imp:n=1 vol=1.059498275
 40 10 1.0 +10 u=4 imp:n=1 vol=1.059498275
-50 10 1.0 +10 u=5 imp:n=1 vol=1.059498275
+50 10 -9.9690819326845300 +10 u=5 imp:n=1 vol=1.059498275
 60 10 1.0 +10 u=6 imp:n=1 vol=1.059498275
 70 10 1.0 +10 u=7 imp:n=1 vol=1.059498275
 80 10 1.0 +10 u=8 imp:n=1 vol=1.059498275
@@ -243,18 +257,28 @@ tr1 0 0 0 1 0  0 0 0 1 0 -1 0 1
 c tr2: 90 deg about y, w/o m
 tr2 0 0 0 0 0 -1 0 1 0 1  0 0
 c
-kcode 100 1.0 10 100
-ksrc -.63 -.63 0. -.63 0. 0. -.63 .63 0.
-       0. -.63 0.   0. 0. 0.   0. .63 0.
-      .63 -.63 0.  .63 0. 0.  .63 .63 0.
+kcode 100 1.0 10 100 2J 6500
+ksrc -.63 -.63 0. -.63 0. 0. -.63 .63 0. &
+0. -.63 0.   0. 0. 0.   0. .63 0. &
+.63 -.63 0.  .63 0. 0.  .63 .63 0.
 mode n
 DBCN 1
-f4:n 11 21 31 41 51 61 71 81 91
+f4:n 11 21 31 51 61 71 81 91
 e4 1. 20.
 fc4 testing
 f14:n 11
 m15 92235.70c 1.0
 fm14 (1. 15 (-1 103))
+fc24 flux in storage element
+f24:n 95
+fc34 flux in supply element
+f34:n 91
+tm34 4 6
+f6:n,p 91
+e0 1E-5 1E-3
+tm0 1 2
+C0 -.866 -.5 0 .5 .866 1
+t0 2 4
 """
 
 mcnp_plate_lattice = """Plate Lattice
@@ -315,12 +339,78 @@ kcode 1000 1.0 25 100
 ksrc 0 0 5
 """
 
+mcnp_cubes = """4 cubes grid with large transformation IDs
+c Universes
+101 11  1.0 101 -102 201 -202 301 -302 imp:n=1 u=1
+501 99  1.0 -101:102:-201:202:-301:302 imp:n=1 u=1
+102 12  1.0 101 -102 201 -202 301 -302 imp:n=1 u=2
+502 99  1.0 -101:102:-201:202:-301:302 imp:n=1 u=2
+103 13  1.0 101 -102 201 -202 301 -302 imp:n=1 u=3
+503 99  1.0 -101:102:-201:202:-301:302 imp:n=1 u=3
+104 14  1.0 101 -102 201 -202 301 -302 imp:n=1 u=4
+504 99  1.0 -101:102:-201:202:-301:302 imp:n=1 u=4
+c Supply universe
+105 11  1.0 101 -102 201 -202 301 -302 imp:n=1 u=5
+505 99  1.0 -101:102:-201:202:-301:302 imp:n=1 u=5
+c Cubes cells
+111 0 11  -13  21  -23  31  -32 imp:n=1 *fill=1 (995)
+112 0 13  -12  21  -23  31  -32 imp:n=1 *fill=2 (996)
+114 0 11  -13  23  -22  31  -32 imp:n=1 *fill=3 (999)
+113 0 13  -12  23  -22  31  -32 imp:n=1 *fill=4 (997)
+c Outside world
+999 0 -11:12:-21:22:-31:32 imp:n=0
+
+c Main parallelepiped
+11  px -5.0
+12  px 5.0
+13  px 0.0
+21  py -5.0
+22  py 5.0
+23  py 0.0
+31  pz -2.0
+32  pz 2.0
+c Fuel cube universe
+101 px -0.5
+102 px  0.5
+201 py -0.5
+202 py  0.5
+301 331 pz -0.4
+302 332 pz  0.4
+
+c Materials
+m0 nlib=70c
+m11 92235.70c 1.0
+m12 92235.70c 1.0
+m13 92235.70c 1.0
+m14 92235.70c 1.0
+m99 1001.70c 0.67 8016.70c 0.33
+c Transformations
+tr1 1 1 0
+tr2 1 2 0
+tr331 0.0 0.0 -0.1
+tr332 0.0 0.0  0.1
+tr700 1 3 0
+tr750 1 4 0
+tr990 1 5 0
+tr995 -3.5 -3.5 0.0
+tr996  3.5 -3.5 0.0
+tr997  3.5  3.5 0.0
+tr999 -3.5  3.5 0.0
+c Others
+kcode 1000 1.0 10 100
+ksrc -3.5 -3.5 0.0
+"""
+
 xsdir = """
 atomic weight ratios
    0001  1.000000   0001  1.000000
    1000  0.99931697 1001   0.99916733   1002   1.99679968   1003   2.99013997
                     1004   3.99320563   1005   4.99205575   1006   5.99301364
                     1007   6.99216250
+   3000  6.88131188 3003   3.00473919   3004   3.99259010   3005   4.96947769
+                    3006   5.96345000   3007   6.95573370   3008   7.95357035
+                    3009   8.94924505   3010   9.94927166   3011   10.94892619
+                    3012   11.95023224
    8000  15.8618629 8012   11.93102358  8013   12.91292282  8014   13.88825568
                     8015   14.87418208  8016   15.85751063  8017   16.85310100
                     8018   17.84453957  8019   18.84033026  8020   19.83223212
@@ -380,16 +470,21 @@ directory
 8016.70c 15.857510 8016.70c   0 1 1 16  0 0 2.5301e-08
 8016.71c 15.857510 8016.71c   0 1 1 16  0 0 2.5301e-08
 8016.72c 15.857510 8016.72c   0 1 1 16  0 0 2.5301e-08
+3006.70c 5.963400 3006.70c   0 1 1 18  0 0 2.5301E-08
+3006.71c 5.963400 3006.71c   0 1 1 18  0 0 2.5301E-08
+3006.72c 5.963400 3006.72c   0 1 1 18  0 0 2.5301E-08
 1001.70c 0.999167 1001.70c   0 1 1 16  0 0 2.5301e-08
 1001.71c 0.999167 1001.71c   0 1 1 16  0 0 2.5301e-08
 1001.72c 0.999167 1001.72c   0 1 1 16  0 0 2.5301e-08
+1004.80c 0.999167 1004.80c   0 1 1 16  0 0 2.5301E-08
+lwtr.10t 0.999167 lwtr.10t   0 1 1 16  0 0 2.5301E-08
 """
 
-# One xs file for each of 92238, 92235, 54135, 53135, 8016, 1001 at
+# One xs file for each of 92238, 92235, 54135, 53135, 8016, 1001, 3006 at
 # 70c, 71c, and 72c; the printing code will replace the .70c with
 # the values needed when we get there
 xs_file_names = ["92238.{}", "92235.{}", "54135.{}", "53135.{}",
-                 "8016.{}", "1001.{}"]
+                 "8016.{}", "1001.{}", "3006.{}"]
 xs_file_ext = ["70c", "71c", "72c"]
 xs_files = [
 """ 92238.{}  236.005800 2.53010e-08 2020-05-24
@@ -515,4 +610,22 @@ ACE file created by simple_ace.pl                                     2020-05-24
                   10                  10                 100                 100
                    0                   0                   1                   2
                1e-11                 100                   0                   0
+""",
+"""  3006.{}  5.96345000 2.53010e-08 2025-03-30
+ACE file custom-made by vmascolino to test Li-6                       2025-03-30
+      0   0.000000      0   0.000000      0   0.000000      0   0.000000
+      0   0.000000      0   0.000000      0   0.000000      0   0.000000
+      0   0.000000      0   0.000000      0   0.000000      0   0.000000
+      0   0.000000      0   0.000000      0   0.000000      0   0.000000
+       16     3006        2        1        0        0        0        0
+        0        3        6        0        0        0        0        0
+        1        0       11       12       13       14       15        0
+       12        0        0        0        0        0        0        0
+        0        0        0        0        0       18        0        0
+        0        0        0        0        0        0        0        0
+               1e-11                 100                  42                  42
+                  42                  42                   0                   0
+                   0                   0                 105                   0
+                   0                   1                   1                   2
+                  42                  42
 """]
diff --git a/tests/analytic/test_cram_solver.py b/tests/analytic/test_cram_solver.py
index e3d86ae..8c639fc 100644
--- a/tests/analytic/test_cram_solver.py
+++ b/tests/analytic/test_cram_solver.py
@@ -36,14 +36,18 @@ def test_single_decay():
         num_procs = 1
         # Initialize our depletion solver
         test_d = CRAMDepletion(exec_cmd, num_threads, num_procs, 1, cram_order)
+        test_d.compute_decay(lib)
 
         # Build the starting material
+        adder.isotope.ISO_REGISTRY.clear()
         mat = adder.Material("test", 1, 1.,
                              [("Xe135", "70c", True)], [1.], True,
                              "70c", 3, [], adder.constants.IN_CORE,
                              check=False)
         mat.is_default_depletion_library = True
         mat.flux = 1.E13 * np.ones(3)
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
         # Set our decay times; will look at t = [0, 1, 2, 3, 4, 5] days
         delta_ts = np.ones(6)
 
@@ -57,9 +61,9 @@ def test_single_decay():
             mat.apply_new_composition(new_isos, new_fracs, new_density)
             np.testing.assert_allclose(mat.atom_fractions,
                                        ref_soln[:, i] / np.sum(ref_soln[:, i]),
-                                       rtol=3E-14)
+                                       rtol=1E-12)
             np.testing.assert_allclose(mat.number_densities, ref_soln[:, i],
-                                       rtol=5.E-14)
+                                       rtol=1E-12)
 
     deplete_substeps(1, 16, depllib, ref_soln)
     deplete_substeps(1, 48, depllib, ref_soln)
@@ -126,15 +130,19 @@ def test_branch_decay():
         num_procs = 1
         # Initialize our depletion solver
         test_d = CRAMDepletion(exec_cmd, num_threads, num_procs, 1, cram_order)
+        test_d.compute_decay(lib)
 
         # Build the starting material, density chosen to start with
         # a number density of 1
+        adder.isotope.ISO_REGISTRY.clear()
         mat = adder.Material("test", 1, 1.,
                              [("Xe135_m1", "70c", True)], [1.], True,
                              "70c", 3, [], adder.constants.IN_CORE,
                              check=False)
         mat.is_default_depletion_library = True
         mat.flux = 1.E13 * np.ones(3)
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
         # Set our decay times; will look at t = [0, 1, 2, 3, 4, 5] days
         delta_ts = np.ones(6)
 
@@ -152,7 +160,7 @@ def test_branch_decay():
                                num_substeps)
             mat.apply_new_composition(new_isos, new_fracs, new_density)
             np.testing.assert_allclose(mat.number_densities, ref_val[:, i],
-                                       rtol=5E-14)
+                                       rtol=1E-12)
 
     deplete_substeps(1, 16, depllib, ref_val)
     deplete_substeps(1, 48, depllib, ref_val)
@@ -187,8 +195,10 @@ def test_fission_yield_decay():
         num_procs = 1
         # Initialize our depletion solver
         test_d = CRAMDepletion(exec_cmd, num_threads, num_procs, 1, cram_order)
+        test_d.compute_decay(lib)
 
         # Build the starting material
+        adder.isotope.ISO_REGISTRY.clear()
         mat = adder.Material("test", 1, 1.,
                              [("Xe135", "70c", True), ("U235", "70c", True)],
                              [0.5, 0.5], True,
@@ -196,6 +206,8 @@ def test_fission_yield_decay():
                              check=False)
         mat.is_default_depletion_library = True
         mat.flux = np.array([1.E19])
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
         # Set our decay times; will look at t = [0, 1, 2, 3, 4, 5] days
         delta_ts = np.ones(6)
 
@@ -208,7 +220,7 @@ def test_fission_yield_decay():
                                num_substeps)
             mat.apply_new_composition(new_isos, new_fracs, new_density)
             np.testing.assert_allclose(mat.number_densities, ref_vals[:, i],
-                                       rtol=3e-14)
+                                       rtol=1E-12)
 
     deplete_substeps(1, 16, depllib, ref_vals)
     deplete_substeps(1, 48, depllib, ref_vals)
@@ -221,7 +233,7 @@ def test_fission_yield_xs():
     # consisting of U235 and Xe135
     depllib = adder.DepletionLibrary("test", np.array([0., 0.01, 1., 20.]))
 
-    u235xs = adder.ReactionData("b", 3)
+    u235xs = adder.ReactionData()
     u235xs.add_type("fission", "b", 0.1 * np.ones(3))
     u235nfy = adder.YieldData()
     u235nfy.add_isotope("Xe135", 2.)
@@ -244,8 +256,10 @@ def test_fission_yield_xs():
         num_procs = 1
         # Initialize our depletion solver
         test_d = CRAMDepletion(exec_cmd, num_threads, num_procs, 1, cram_order)
+        test_d.compute_decay(lib)
 
         # Build the starting material
+        adder.isotope.ISO_REGISTRY.clear()
         mat = adder.Material("test", 1, 1.,
                              [("Xe135", "70c", True), ("U235", "70c", True)],
                              [0.5, 0.5], True,
@@ -253,6 +267,8 @@ def test_fission_yield_xs():
                              check=False)
         mat.is_default_depletion_library = True
         mat.flux = np.array([1.83423, 6.54654, 5.69335]) * 1.E19
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
         # Set our decay times; will look at t = [0, 1, 2, 3, 4, 5] days
         delta_ts = np.ones(6)
 
@@ -265,7 +281,7 @@ def test_fission_yield_xs():
                                num_substeps)
             mat.apply_new_composition(new_isos, new_fracs, new_density)
             np.testing.assert_allclose(mat.number_densities, ref_vals[:, i],
-                                       rtol=3e-14)
+                                       rtol=1E-12)
 
     deplete_substeps(1, 16, depllib, ref_vals)
     deplete_substeps(1, 48, depllib, ref_vals)
@@ -283,7 +299,7 @@ def test_multi_fission_yield():
                              .8, .9])
     yields = np.array(yields)
     for i in range(len(fissile)):
-        xs = adder.ReactionData("b", 3)
+        xs = adder.ReactionData()
         xs.add_type("fission", "cm2", xss[i] * np.ones(3))
         nfy = adder.YieldData()
         nfy.add_isotope("Xe135", yields[i])
@@ -320,15 +336,18 @@ def test_multi_fission_yield():
         num_procs = 1
         # Initialize our depletion solver
         test_d = CRAMDepletion(exec_cmd, num_threads, num_procs, 1, cram_order)
+        test_d.compute_decay(lib)
 
         # Build the starting material, density chosen to start with
         # a number density of 1
-
+        adder.isotope.ISO_REGISTRY.clear()
         mat = adder.Material("test", 1, 1., isos, np.ones(len(isos)),
                              True, "70c", 3, [], adder.constants.IN_CORE,
                              check=False)
         mat.is_default_depletion_library = True
         mat.flux = np.array([1.83423, 6.54654, 5.69335]) * 1.E18
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
         # Set our decay times; will look at t = [0, 1, 2, 3, 4, 5] days
         delta_ts = np.ones(6)
 
@@ -341,7 +360,7 @@ def test_multi_fission_yield():
                                num_substeps)
             mat.apply_new_composition(new_isos, new_fracs, new_density)
             np.testing.assert_allclose(mat.number_densities, ref_soln[i, :],
-                                       rtol=3.9E-14)
+                                       rtol=1E-12)
 
     deplete_substeps(1, 16, depllib, isos, ref_soln)
     deplete_substeps(1, 48, depllib, isos, ref_soln)
@@ -357,7 +376,7 @@ def test_burn_actinide():
     yields = [[0.5, 0.5], [0.5, 0.5], [1.]]
     types = ["(n,gamma)", "(n,2n)", "(n,3n)"]
     xss = 0.1 * np.ones(3)
-    xs = adder.ReactionData("b", 3)
+    xs = adder.ReactionData()
     stable_decay = adder.DecayData(None, "s", 0.)
     for i in range(len(targets)):
         if len(targets[i]) > 1:
@@ -397,6 +416,7 @@ def test_burn_actinide():
         num_procs = 1
         # Initialize our depletion solver
         test_d = CRAMDepletion(exec_cmd, num_threads, num_procs, 1, cram_order)
+        test_d.compute_decay(lib)
 
         # Build the starting material, density chosen to start with
         # a number density of 1
@@ -410,11 +430,14 @@ def test_burn_actinide():
             else:
                 num_frac.append(0.)
         isos = [(iso, "70c", True) for iso in isos]
+        adder.isotope.ISO_REGISTRY.clear()
         mat = adder.Material("test", 1, 1., isos, num_frac, True,
                              "70c", 3, [], adder.constants.IN_CORE,
                              check=False)
         mat.is_default_depletion_library = True
         mat.flux = np.array([0.2, 0.3, 0.5]) * 1.407416667E+19
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
 
         # Set our decay times; will look at t = [0, 1, 2, 3, 4, 5] days
         delta_ts = np.ones(6)
@@ -428,7 +451,7 @@ def test_burn_actinide():
                                num_substeps)
             mat.apply_new_composition(new_isos, new_fracs, new_density)
             np.testing.assert_allclose(mat.number_densities, ref_soln[idx, :],
-                                       rtol=3E-14)
+                                       rtol=1E-12)
 
     deplete_substeps(1, 16, depllib, targets, ref_soln)
     deplete_substeps(4, 16, depllib, targets, ref_soln)
@@ -445,7 +468,7 @@ def test_burn_notactinide():
     targets = [["Xe136"], ["Xe134"], ["Te132"], ["I135"]]
     types = ["(n,gamma)", "(n,2n)", "(n,a)", "(n,p)"]
     xss = 0.1 * np.ones(3)
-    xs = adder.ReactionData("b", 3)
+    xs = adder.ReactionData()
     stable_decay = adder.DecayData(None, "s", 0.)
     for i in range(len(targets)):
         xs.add_type(types[i], "b", xss, targets=targets[i])
@@ -484,6 +507,7 @@ def test_burn_notactinide():
         num_procs = 1
         # Initialize our depletion solver
         test_d = CRAMDepletion(exec_cmd, num_threads, num_procs, 1, cram_order)
+        test_d.compute_decay(lib)
 
         # Build the starting material, density chosen to start with
         # a number density of 1
@@ -497,11 +521,14 @@ def test_burn_notactinide():
             else:
                 num_frac.append(0.)
         isos = [(iso, "70c", True) for iso in isos]
+        adder.isotope.ISO_REGISTRY.clear()
         mat = adder.Material("test", 1, 1., isos, num_frac, True,
                              "70c", 3, [], adder.constants.IN_CORE,
                              check=False)
         mat.is_default_depletion_library = True
         mat.flux = np.array([0.2, 0.3, 0.5]) * 1.407416667E+19
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
 
         # Set our decay times; will look at t = [0, 1, 2, 3, 4, 5] days
         delta_ts = np.ones(6)
@@ -515,7 +542,7 @@ def test_burn_notactinide():
                                num_substeps)
             mat.apply_new_composition(new_isos, new_fracs, new_density)
             np.testing.assert_allclose(mat.number_densities, ref_soln[idx, :],
-                                       rtol=2.1e-14)
+                                       rtol=1E-12)
 
     deplete_substeps(1, 16, depllib, targets, ref_soln)
     deplete_substeps(4, 16, depllib, targets, ref_soln)
@@ -530,7 +557,7 @@ def test_burn():
     targets = ["Pu239", "Np238", "U235", "Pu237", "Np237", "Np236"]
     types = ["(n,gamma)", "(n,p)", "(n,a)", "(n,2n)", "(n,d)", "(n,t)"]
     xss = 0.1 * np.ones(3)
-    xs = adder.ReactionData("b", 3)
+    xs = adder.ReactionData()
     for i in range(len(targets)):
         xs.add_type(types[i], "b", xss, targets=targets[i])
         target_dk = adder.DecayData(None, "s", 0.)
@@ -575,6 +602,7 @@ def test_burn():
         num_procs = 200
         # Initialize our depletion solver
         test_d = CRAMDepletion(exec_cmd, num_threads, num_procs, 1, cram_order)
+        test_d.compute_decay(lib)
 
         # Build the starting material, density chosen to start with
         # a number density of 1
@@ -586,11 +614,14 @@ def test_burn():
             else:
                 num_frac.append(0.)
         isos = [(iso, "70c", True) for iso in isos]
+        adder.isotope.ISO_REGISTRY.clear()
         mat = adder.Material("test", 1, 1., isos, num_frac, True,
                              "70c", 3, [], adder.constants.IN_CORE,
                              check=False)
         mat.is_default_depletion_library = True
         mat.flux = np.array([0.2, 0.3, 0.5]) * 1.407416667E+19
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
 
         # Set our decay times; will look at t = [0, 1, 2, 3, 4, 5] days
         delta_ts = np.ones(6)
@@ -604,7 +635,7 @@ def test_burn():
                                num_substeps)
             mat.apply_new_composition(new_isos, new_fracs, new_density)
             np.testing.assert_allclose(mat.number_densities, ref_soln[idx, :],
-                                       rtol=4E-14)
+                                       rtol=1E-12)
 
     # Deplete with 1 substep, and with 4 substeps
     deplete_substeps(1, 16, depllib, targets, ref_soln)
@@ -623,7 +654,7 @@ def test_simple_burn_and_decay():
     targets = [["Xe136"], ["Xe134"], ["Te132"], ["I135"]]
     types = ["(n,gamma)", "(n,2n)", "(n,a)", "(n,p)"]
     xss = 0.1 * np.ones(3)
-    xs = adder.ReactionData("b", 3)
+    xs = adder.ReactionData()
     stable_decay = adder.DecayData(None, "s", 0.)
     for i in range(len(targets)):
         xs.add_type(types[i], "b", xss, targets=targets[i])
@@ -667,6 +698,7 @@ def test_simple_burn_and_decay():
         num_procs = 1
         # Initialize our depletion solver
         test_d = CRAMDepletion(exec_cmd, num_threads, num_procs, 1, cram_order)
+        test_d.compute_decay(lib)
 
         # Build the starting material, density chosen to start with
         # a number density of 1
@@ -680,11 +712,14 @@ def test_simple_burn_and_decay():
             else:
                 num_frac.append(0.)
         isos = [(iso, "70c", True) for iso in isos]
+        adder.isotope.ISO_REGISTRY.clear()
         mat = adder.Material("test", 1, 1., isos, num_frac, True,
                              "70c", 3, [], adder.constants.IN_CORE,
                              check=False)
         mat.is_default_depletion_library = True
         mat.flux = np.array([0.2, 0.3, 0.5]) * 1.407416667E+19
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
 
         # Set our decay times; will look at t = [0, 1, 2, 3, 4, 5] days
         delta_ts = np.ones(6)
@@ -698,7 +733,7 @@ def test_simple_burn_and_decay():
                                num_substeps)
             mat.apply_new_composition(new_isos, new_fracs, new_density)
             np.testing.assert_allclose(mat.number_densities, ref_soln[idx, :],
-                                       rtol=2e-13)
+                                       rtol=1E-12)
 
     deplete_substeps(1, 16, depllib, targets, ref_soln)
     deplete_substeps(1, 48, depllib, targets, ref_soln)
diff --git a/tests/analytic/test_msr_rxn_rate_avg_solver.py b/tests/analytic/test_msr_rxn_rate_avg_solver.py
index 8fb09fa..51408c6 100644
--- a/tests/analytic/test_msr_rxn_rate_avg_solver.py
+++ b/tests/analytic/test_msr_rxn_rate_avg_solver.py
@@ -64,12 +64,15 @@ def test_simple_feed_addition():
         # Build the starting material
         num_frac = [0.5, 0.5, 0.]
         initial_isos = [(iso, "70c", True) for iso in isos]
+        adder.isotope.ISO_REGISTRY.clear()
         mat = MockMaterial("test", 1, 1., initial_isos, num_frac, True,
                            "70c", 3, [], adder.constants.IN_CORE,
                            check=False)
         mat.is_default_depletion_library = True
         mat.flux = np.array([0.2, 0.3, 0.5]) * 1.407416667E+19
         mat.volume = 1.
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
 
         # Now initialize the msr data
         test_d.set_msr_params("histogram", solve_method, [sys_data], [mat],
@@ -174,12 +177,15 @@ def test_simple_feed_addition_w_tank():
         # Build the starting material
         num_frac = [0.5, 0.5, 0.]
         initial_isos = [(iso, "70c", True) for iso in isos]
+        adder.isotope.ISO_REGISTRY.clear()
         mat = MockMaterial("test", 1, 1., initial_isos, num_frac, True,
                            "70c", 3, [], adder.constants.IN_CORE,
                            check=False)
         mat.is_default_depletion_library = True
         mat.flux = np.array([0.2, 0.3, 0.5]) * 1.407416667E+19
         mat.volume = 1.
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
 
         # Now initialize the msr data
         test_d.set_msr_params("histogram", solve_method, [sys_data], [mat],
@@ -272,7 +278,7 @@ def test_stationary():
                   np.log(2) / (3.E-7), np.log(2) / (6.E-7),
                   np.log(2) / (9.E-6), None]
     xss = 0.1 * np.ones(3)
-    xs = adder.ReactionData("b", 3)
+    xs = adder.ReactionData()
     for i in range(len(targets)):
         xs.add_type(types[i], "b", xss, targets=targets[i])
         target_dk = adder.DecayData(half_lives[i], "s", 0.)
@@ -317,11 +323,14 @@ def test_stationary():
             else:
                 num_frac.append(0.)
         isos = [(iso, "70c", True) for iso in isos]
+        adder.isotope.ISO_REGISTRY.clear()
         mat = MockMaterial("test", 1, 1., isos, num_frac, True,
                            "70c", 3, [], adder.constants.IN_CORE, check=False)
         mat.is_default_depletion_library = True
         mat.flux = np.array([0.2, 0.3, 0.5]) * 1.407416667E+19
         mat.volume = 1.
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
 
         test_d.set_msr_params("histogram", solve_method, [sys_data], [mat],
             depl_libs)
@@ -391,8 +400,7 @@ def test_flowing():
     # The base depletion library
     depllib = adder.DepletionLibrary("base", np.array([0., 0.01, 1., 20.]))
     xss = [0.1, 0.2, 0.3]
-    xs = adder.ReactionData("b", 3)
-    xs.add_type
+    xs = adder.ReactionData()
     xs.add_type("(n,gamma)", "b", xss, targets="Pu239")
     am239_dk = adder.DecayData(360. * 12., "s", 0.)  # 1.2 hr half life
     am239_dk.add_type("ec/beta+", 1., ["Pu239"])
@@ -434,6 +442,7 @@ def test_flowing():
         # Build the starting material, even mix of Pu238 and Am239
         isos = [("Pu238", "70c", True), ("Am239", "70c", True)]
         num_frac = [0.5, 0.5]
+        adder.isotope.ISO_REGISTRY.clear()
         mat1 = MockMaterial("test_1", 1, 1., isos, num_frac, True,
                             "70c", 3, [], adder.constants.IN_CORE, check=False)
         mat1.is_default_depletion_library = True
@@ -445,9 +454,9 @@ def test_flowing():
                             "70c", 3, [], adder.constants.IN_CORE, check=False)
         mat2_lib = depl_libs[0].clone(new_name="mat2")
         n_xs = mat2_lib.isotopes["Pu238"].neutron_xs
-        _, t, y, q = n_xs._products["(n,gamma)"]
+        _, ty, q = n_xs.get_product_data_by_type("(n,gamma)")
         xs_2 = np.array([0.2, 0.2, 0.1])
-        n_xs._products["(n,gamma)"] = (xs_2, t, y, q)
+        n_xs.update_type("(n,gamma)", xs_2, ty, q)
         mat2.is_default_depletion_library = False
         mat2.depl_lib_name = mat2_lib.name
         mat2.flux = np.ones(3) * 1.E19
@@ -456,6 +465,8 @@ def test_flowing():
 
         test_d.set_msr_params("histogram", solve_method, [sys_data],
                               [mat1, mat2], depl_libs)
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(depl_libs,
+                                                               [mat1, mat2])
 
         # Set up our solution space
         i238 = 0
@@ -516,8 +527,7 @@ def test_multipath():
     # The base depletion library
     depllib = adder.DepletionLibrary("base", np.array([0., 0.01, 1., 20.]))
     xss = [0.1, 0.2, 0.3]
-    xs = adder.ReactionData("b", 3)
-    xs.add_type
+    xs = adder.ReactionData()
     xs.add_type("(n,gamma)", "b", xss, targets="Pu239")
     am239_dk = adder.DecayData(360. * 12., "s", 0.)  # 1.2 hr half life
     am239_dk.add_type("ec/beta+", 1., ["Pu239"])
@@ -566,6 +576,7 @@ def test_multipath():
         # Build the starting material, even mix of Pu238 and Am239
         isos = [("Pu238", "70c", True), ("Am239", "70c", True)]
         num_frac = [0.5, 0.5]
+        adder.isotope.ISO_REGISTRY.clear()
         mat1 = MockMaterial("test_1", 1, 1., isos, num_frac, True,
                             "70c", 3, [], adder.constants.IN_CORE, check=False)
         mat1.is_default_depletion_library = True
@@ -577,14 +588,17 @@ def test_multipath():
                             "70c", 3, [], adder.constants.IN_CORE, check=False)
         mat2_lib = base_lib.clone(new_name="mat2")
         n_xs = mat2_lib.isotopes["Pu238"].neutron_xs
-        _, t, y, q = n_xs._products["(n,gamma)"]
+        _, ty, q = n_xs.get_product_data_by_type("(n,gamma)")
         xs_2 = np.array([0.2, 0.2, 0.1])
-        n_xs._products["(n,gamma)"] = (xs_2, t, y, q)
+        n_xs.update_type("(n,gamma)", xs_2, ty, q)
+
         mat2.is_default_depletion_library = False
         mat2.flux = np.ones(3) * 1.E19
         mat2.depl_lib_name = mat2_lib.name
         mat2.volume = 1.
         depl_libs[mat2_lib.name] = mat2_lib
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(depl_libs,
+                                                               [mat1, mat2])
 
         test_d.set_msr_params("histogram", solve_method, [sys_data],
                               [mat1, mat2], depl_libs)
diff --git a/tests/analytic/test_msr_solver.py b/tests/analytic/test_msr_solver.py
index b7caa0d..547232a 100644
--- a/tests/analytic/test_msr_solver.py
+++ b/tests/analytic/test_msr_solver.py
@@ -46,11 +46,14 @@ def test_simple_feed_addition():
         # Build the starting material
         num_frac = [0.5, 0.5, 0.]
         initial_isos = [(iso, "70c", True) for iso in isos]
+        adder.isotope.ISO_REGISTRY.clear()
         mat = MockMaterial("test", 1, 1., initial_isos, num_frac, True, "70c",
                            3, [], adder.constants.IN_CORE, check=False)
         mat.is_default_depletion_library = True
         mat.flux = np.array([0.2, 0.3, 0.5]) * 1.407416667E+19
         mat.volume = 1.
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
 
         # Init our MSR information so that half the time is spent
         # in core (one hour in-core, one hour ex-core)
@@ -181,11 +184,14 @@ def test_simple_feed_addition_w_tank():
         # Build the starting material
         num_frac = [0.5, 0.5, 0.]
         initial_isos = [(iso, "70c", True) for iso in isos]
+        adder.isotope.ISO_REGISTRY.clear()
         mat = MockMaterial("test", 1, 1., initial_isos, num_frac, True,
                            "70c", 3, [], adder.constants.IN_CORE, check=False)
         mat.is_default_depletion_library = True
         mat.flux = np.array([0.2, 0.3, 0.5]) * 1.407416667E+19
         mat.volume = 1.
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
 
         # Now initialize the msr data
         test_d.set_msr_params("histogram", solve_method, [sys_data], [mat],
@@ -280,7 +286,7 @@ def test_stationary():
                   np.log(2) / (3.E-7), np.log(2) / (6.E-7),
                   np.log(2) / (9.E-6), None]
     xss = 0.1 * np.ones(3)
-    xs = adder.ReactionData("b", 3)
+    xs = adder.ReactionData()
     for i in range(len(targets)):
         xs.add_type(types[i], "b", xss, targets=targets[i])
         target_dk = adder.DecayData(half_lives[i], "s", 0.)
@@ -325,11 +331,14 @@ def test_stationary():
             else:
                 num_frac.append(0.)
         isos = [(iso, "70c", True) for iso in isos]
+        adder.isotope.ISO_REGISTRY.clear()
         mat = MockMaterial("test", 1, 1., isos, num_frac, True,
                            "70c", 3, [], adder.constants.IN_CORE, check=False)
         mat.is_default_depletion_library = True
         mat.flux = np.array([0.2, 0.3, 0.5]) * 1.407416667E+19
         mat.volume = 1.
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
 
         test_d.set_msr_params("histogram", solve_method, [sys_data], [mat],
             depl_libs)
@@ -411,7 +420,7 @@ def test_flowing():
                   np.log(2) / (3.E-7), np.log(2) / (6.E-7),
                   np.log(2) / (9.E-6), None]
     xss = 0.1 * np.ones(3)
-    xs = adder.ReactionData("b", 3)
+    xs = adder.ReactionData()
     for i in range(len(targets)):
         xs.add_type(types[i], "b", xss, targets=targets[i])
         target_dk = adder.DecayData(half_lives[i], "s", 0.)
@@ -463,11 +472,14 @@ def test_flowing():
             else:
                 num_frac.append(0.)
         isos = [(iso, "70c", True) for iso in isos]
+        adder.isotope.ISO_REGISTRY.clear()
         mat = MockMaterial("test", 1, 1., isos, num_frac, True,
                            "70c", 3, [], adder.constants.IN_CORE, check=False)
         mat.is_default_depletion_library = True
         mat.flux = np.array([0.2, 0.3, 0.5]) * 1.407416667E+19
         mat.volume = 1.
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
 
         test_d.set_msr_params("histogram", solve_method, [sys_data], [mat],
             depl_libs)
@@ -563,7 +575,7 @@ def test_flowing_with_feed():
                   np.log(2) / (3.E-7), np.log(2) / (6.E-7),
                   np.log(2) / (9.E-6), None]
     xss = 0.1 * np.ones(3)
-    xs = adder.ReactionData("b", 3)
+    xs = adder.ReactionData()
     for i in range(len(targets)):
         xs.add_type(types[i], "b", xss, targets=targets[i])
         target_dk = adder.DecayData(half_lives[i], "s", 0.)
@@ -623,11 +635,14 @@ def test_flowing_with_feed():
             else:
                 num_frac.append(0.)
         isos = [(iso, "70c", True) for iso in isos]
+        adder.isotope.ISO_REGISTRY.clear()
         mat = MockMaterial("test", 1, 1., isos, num_frac, True,
                            "70c", 3, [], adder.constants.IN_CORE, check=False)
         mat.is_default_depletion_library = True
         mat.flux = np.array([0.2, 0.3, 0.5]) * 1.407416667E+19
         mat.volume = 1.
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
 
         # Initialize with this feed; we expect a ValueError exception
         # because of the presence of Pu
@@ -772,7 +787,7 @@ def test_fully_cp():
                   np.log(2) / (3.E-7), np.log(2) / (6.E-7),
                   np.log(2) / (9.E-6), None]
     xss = 0.1 * np.ones(3)
-    xs = adder.ReactionData("b", 3)
+    xs = adder.ReactionData()
     for i in range(len(targets)):
         xs.add_type(types[i], "b", xss, targets=targets[i])
         target_dk = adder.DecayData(half_lives[i], "s", 0.)
@@ -825,11 +840,14 @@ def test_fully_cp():
             else:
                 num_frac.append(0.)
         isos = [(iso, "70c", True) for iso in isos]
+        adder.isotope.ISO_REGISTRY.clear()
         mat = MockMaterial("test", 1, 1., isos, num_frac, True,
                            "70c", 3, [], adder.constants.IN_CORE, check=False)
         mat.is_default_depletion_library = True
         mat.flux = np.array([0.2, 0.3, 0.5]) * 1.407416667E+19
         mat.volume = 1.
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
 
         # Init our MSR information
         test_d.set_msr_params("histogram", solve_method, [sys_data], [mat],
@@ -938,7 +956,7 @@ def test_mix_no_delay():
                   np.log(2) / (3.E-7), np.log(2) / (6.E-7),
                   np.log(2) / (9.E-6), None]
     xss = 0.1 * np.ones(3)
-    xs = adder.ReactionData("b", 3)
+    xs = adder.ReactionData()
     for i in range(len(targets)):
         xs.add_type(types[i], "b", xss, targets=targets[i])
         target_dk = adder.DecayData(half_lives[i], "s", 0.)
@@ -996,11 +1014,14 @@ def test_mix_no_delay():
             else:
                 num_frac.append(0.)
         isos = [(iso, "70c", True) for iso in isos]
+        adder.isotope.ISO_REGISTRY.clear()
         mat = MockMaterial("test", 1, 1., isos, num_frac, True,
                            "70c", 3, [], adder.constants.IN_CORE, check=False)
         mat.is_default_depletion_library = True
         mat.flux = np.array([0.2, 0.3, 0.5]) * 1.407416667E+19
         mat.volume = 1.
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
 
         # Init our MSR information
         test_d.set_msr_params("histogram", solve_method, [sys_data], [mat],
@@ -1119,7 +1140,7 @@ def test_mix_delay():
                   np.log(2) / (3.E-7), np.log(2) / (6.E-7),
                   np.log(2) / (9.E-6), None]
     xss = 0.1 * np.ones(3)
-    xs = adder.ReactionData("b", 3)
+    xs = adder.ReactionData()
     for i in range(len(targets)):
         xs.add_type(types[i], "b", xss, targets=targets[i])
         target_dk = adder.DecayData(half_lives[i], "s", 0.)
@@ -1177,11 +1198,14 @@ def test_mix_delay():
             else:
                 num_frac.append(0.)
         isos = [(iso, "70c", True) for iso in isos]
+        adder.isotope.ISO_REGISTRY.clear()
         mat = MockMaterial("test", 1, 1., isos, num_frac, True,
                            "70c", 3, [], adder.constants.IN_CORE, check=False)
         mat.is_default_depletion_library = True
         mat.flux = np.array([0.2, 0.3, 0.5]) * 1.407416667E+19
         mat.volume = 1.
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
 
         # Init our MSR information
         test_d.set_msr_params("histogram", solve_method, [sys_data], [mat],
@@ -1311,7 +1335,7 @@ def test_mix_delay_with_feed():
                   np.log(2) / (3.E-7), np.log(2) / (6.E-7),
                   np.log(2) / (9.E-6), None]
     xss = 0.1 * np.ones(3)
-    xs = adder.ReactionData("b", 3)
+    xs = adder.ReactionData()
     for i in range(len(targets)):
         xs.add_type(types[i], "b", xss, targets=targets[i])
         target_dk = adder.DecayData(half_lives[i], "s", 0.)
@@ -1374,11 +1398,14 @@ def test_mix_delay_with_feed():
             else:
                 num_frac.append(0.)
         isos = [(iso, "70c", True) for iso in isos]
+        adder.isotope.ISO_REGISTRY.clear()
         mat = MockMaterial("test", 1, 1., isos, num_frac, True,
                            "70c", 3, [], adder.constants.IN_CORE, check=False)
         mat.is_default_depletion_library = True
         mat.flux = np.array([0.2, 0.3, 0.5]) * 1.407416667E+19
         mat.volume = 1.
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
 
         # Init our MSR information
         test_d.set_msr_params("histogram", solve_method, [sys_data], [mat],
diff --git a/tests/analytic/test_origen_solver.py b/tests/analytic/test_origen_solver.py
index d5ea2e7..8950f08 100644
--- a/tests/analytic/test_origen_solver.py
+++ b/tests/analytic/test_origen_solver.py
@@ -34,18 +34,22 @@ def test_single_decay():
     def deplete_substeps(num_substeps, lib):
         num_threads = 1
         num_procs = 1
-        chunksize = 1
+        chunksize = 0
         # Initialize our depletion solver
         test_d = Origen22Depletion(EXEC_CMD, num_threads, num_procs, chunksize)
         test_d.isotope_types = Origen22Depletion.assign_isotope_types(lib)
+        test_d.compute_decay(lib)
 
         # Build the starting material
+        adder.isotope.ISO_REGISTRY.clear()
         mat = adder.Material("test", 1, 1.,
                              [("Xe135", "70c", True)], [1.], True,
                              "70c", 3, [], adder.constants.IN_CORE,
                              check=False)
         mat.is_default_depletion_library = True
         mat.flux = 1.E13 * np.ones(3)
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
         # Set our decay times; will look at t = [0, 1, 2, 3, 4, 5] days
         delta_ts = np.ones(6)
 
@@ -128,15 +132,19 @@ def test_branch_decay():
         # Initialize our depletion solver
         test_d = Origen22Depletion(EXEC_CMD, num_threads, num_procs, chunksize)
         test_d.isotope_types = Origen22Depletion.assign_isotope_types(lib)
+        test_d.compute_decay(lib)
 
         # Build the starting material, density chosen to start with
         # a number density of 1
+        adder.isotope.ISO_REGISTRY.clear()
         mat = adder.Material("test", 1, 1.,
                              [("Xe135_m1", "70c", True)], [1.], True,
                              "70c", 3, [], adder.constants.IN_CORE,
                              check=False)
         mat.is_default_depletion_library = True
         mat.flux = 1.E13 * np.ones(3)
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
         # Set our decay times; will look at t = [0, 1, 2, 3, 4, 5] days
         delta_ts = np.ones(6)
 
@@ -200,8 +208,10 @@ def test_fission_yield_decay():
         test_d.isotope_types = {"actinide": set(["U235", "S250"]),
                                 "fp": set(["Xe135"]),
                                 "activation": set()}
+        test_d.compute_decay(lib)
 
         # Build the starting material
+        adder.isotope.ISO_REGISTRY.clear()
         mat = adder.Material("test", 1, 1.,
                              [("Xe135", "70c", True), ("U235", "70c", True)],
                              [0.5, 0.5], True,
@@ -209,6 +219,8 @@ def test_fission_yield_decay():
                              check=False)
         mat.is_default_depletion_library = True
         mat.flux = np.array([1.E19])
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
         # Set our decay times; will look at t = [0, 1, 2, 3, 4, 5] days
         delta_ts = np.ones(6)
 
@@ -238,7 +250,7 @@ def test_fission_yield_xs():
     # consisting of U235 and Xe135
     depllib = adder.DepletionLibrary("test", np.array([0., 0.01, 1., 20.]))
 
-    u235xs = adder.ReactionData("b", 3)
+    u235xs = adder.ReactionData()
     u235xs.add_type("fission", "b", 0.1 * np.ones(3))
     u235nfy = adder.YieldData()
     u235nfy.add_isotope("Xe135", 2.)
@@ -262,8 +274,10 @@ def test_fission_yield_xs():
         # Initialize our depletion solver
         test_d = Origen22Depletion(EXEC_CMD, num_threads, num_procs, chunksize)
         test_d.isotope_types = Origen22Depletion.assign_isotope_types(lib)
+        test_d.compute_decay(lib)
 
         # Build the starting material
+        adder.isotope.ISO_REGISTRY.clear()
         mat = adder.Material("test", 1, 1.,
                              [("Xe135", "70c", True), ("U235", "70c", True)],
                              [0.5, 0.5], True,
@@ -271,6 +285,8 @@ def test_fission_yield_xs():
                              check=False)
         mat.is_default_depletion_library = True
         mat.flux = np.array([1.83423, 6.54654, 5.69335]) * 1.E19
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
         # Set our decay times; will look at t = [0, 1, 2, 3, 4, 5] days
         delta_ts = np.ones(6)
 
@@ -300,7 +316,7 @@ def test_multi_fission_yield():
                              .8, .9])
     yields = np.array(yields)
     for i in range(len(fissile)):
-        xs = adder.ReactionData("b", 3)
+        xs = adder.ReactionData()
         xs.add_type("fission", "cm2", xss[i] * np.ones(3))
         nfy = adder.YieldData()
         nfy.add_isotope("Xe135", yields[i])
@@ -338,15 +354,18 @@ def test_multi_fission_yield():
         # Initialize our depletion solver
         test_d = Origen22Depletion(EXEC_CMD, num_threads, num_procs, chunksize)
         test_d.isotope_types = Origen22Depletion.assign_isotope_types(lib)
+        test_d.compute_decay(lib)
 
         # Build the starting material, density chosen to start with
         # a number density of 1
-
+        adder.isotope.ISO_REGISTRY.clear()
         mat = adder.Material("test", 1, 1., isos, np.ones(len(isos)),
                              True, "70c", 3, [], adder.constants.IN_CORE,
                              check=False)
         mat.is_default_depletion_library = True
         mat.flux = np.array([1.83423, 6.54654, 5.69335]) * 1.E18
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
         # Set our decay times; will look at t = [0, 1, 2, 3, 4, 5] days
         delta_ts = np.ones(6)
 
@@ -374,7 +393,7 @@ def test_burn_actinide():
     yields = [[0.5, 0.5], [0.5, 0.5], [1.]]
     types = ["(n,gamma)", "(n,2n)", "(n,3n)"]
     xss = 0.1 * np.ones(3)
-    xs = adder.ReactionData("b", 3)
+    xs = adder.ReactionData()
     stable_decay = adder.DecayData(None, "s", 0.)
     for i in range(len(targets)):
         if len(targets[i]) > 1:
@@ -414,6 +433,7 @@ def test_burn_actinide():
         # Initialize our depletion solver
         test_d = Origen22Depletion(EXEC_CMD, num_threads, num_procs, 1)
         test_d.isotope_types = Origen22Depletion.assign_isotope_types(lib)
+        test_d.compute_decay(lib)
 
         # Build the starting material, density chosen to start with
         # a number density of 1
@@ -427,12 +447,14 @@ def test_burn_actinide():
             else:
                 num_frac.append(0.)
         isos = [(iso, "70c", True) for iso in isos]
+        adder.isotope.ISO_REGISTRY.clear()
         mat = adder.Material("test", 1, 1., isos, num_frac, True,
                              "70c", 3, [], adder.constants.IN_CORE,
                              check=False)
         mat.is_default_depletion_library = True
         mat.flux = np.array([0.2, 0.3, 0.5]) * 1.407416667E+19
-
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
         # Set our decay times; will look at t = [0, 1, 2, 3, 4, 5] days
         delta_ts = np.ones(6)
 
@@ -461,7 +483,7 @@ def test_burn_notactinide():
     targets = [["Xe136"], ["Xe134"], ["Te132"], ["I135"]]
     types = ["(n,gamma)", "(n,2n)", "(n,a)", "(n,p)"]
     xss = 0.1 * np.ones(3)
-    xs = adder.ReactionData("b", 3)
+    xs = adder.ReactionData()
     stable_decay = adder.DecayData(None, "s", 0.)
     for i in range(len(targets)):
         xs.add_type(types[i], "b", xss, targets=targets[i])
@@ -500,6 +522,7 @@ def test_burn_notactinide():
         # Initialize our depletion solver
         test_d = Origen22Depletion(EXEC_CMD, num_threads, num_procs, 1)
         test_d.isotope_types = Origen22Depletion.assign_isotope_types(lib)
+        test_d.compute_decay(lib)
 
         # Build the starting material, density chosen to start with
         # a number density of 1
@@ -513,12 +536,14 @@ def test_burn_notactinide():
             else:
                 num_frac.append(0.)
         isos = [(iso, "70c", True) for iso in isos]
+        adder.isotope.ISO_REGISTRY.clear()
         mat = adder.Material("test", 1, 1., isos, num_frac, True,
                              "70c", 3, [], adder.constants.IN_CORE,
                              check=False)
         mat.is_default_depletion_library = True
         mat.flux = np.array([0.2, 0.3, 0.5]) * 1.407416667E+19
-
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
         # Set our decay times; will look at t = [0, 1, 2, 3, 4, 5] days
         delta_ts = np.ones(6)
 
@@ -546,7 +571,7 @@ def test_simple_burn_and_decay():
     targets = [["Xe136"], ["Xe134"], ["Te132"], ["I135"]]
     types = ["(n,gamma)", "(n,2n)", "(n,a)", "(n,p)"]
     xss = 0.1 * np.ones(3)
-    xs = adder.ReactionData("b", 3)
+    xs = adder.ReactionData()
     stable_decay = adder.DecayData(None, "s", 0.)
     for i in range(len(targets)):
         xs.add_type(types[i], "b", xss, targets=targets[i])
@@ -590,6 +615,7 @@ def test_simple_burn_and_decay():
         # Initialize our depletion solver
         test_d = Origen22Depletion(EXEC_CMD, num_threads, num_procs, 1)
         test_d.isotope_types = Origen22Depletion.assign_isotope_types(lib)
+        test_d.compute_decay(lib)
 
         # Build the starting material, density chosen to start with
         # a number density of 1
@@ -603,12 +629,14 @@ def test_simple_burn_and_decay():
             else:
                 num_frac.append(0.)
         isos = [(iso, "70c", True) for iso in isos]
+        adder.isotope.ISO_REGISTRY.clear()
         mat = adder.Material("test", 1, 1., isos, num_frac, True,
                              "70c", 3, [], adder.constants.IN_CORE,
                              check=False)
         mat.is_default_depletion_library = True
         mat.flux = np.array([0.2, 0.3, 0.5]) * 1.407416667E+19
-
+        adder.isotope.ISO_REGISTRY.register_depletion_lib_isos(
+            {adder.constants.BASE_LIB: depllib}, [mat])
         # Set our decay times; will look at t = [0, 1, 2, 3, 4, 5] days
         delta_ts = np.ones(6)
 
diff --git a/tests/integration/deplete_cram16/results_true.dat b/tests/integration/deplete_cram16/results_true.dat
index a4ca39a..e4906ad 100644
--- a/tests/integration/deplete_cram16/results_true.dat
+++ b/tests/integration/deplete_cram16/results_true.dat
@@ -8,6 +8,9 @@ powers, 0.000000E+00, 0.000000E+00, 0.000000E+00,
 keffs, 2.000000E+00, 2.000000E+00, 2.000000E+00, 
 keffs_stddev, 1.000000E-02, 1.000000E-02, 1.000000E-02, 
 fluxes_1grp, 1.500000E+15, 1.500000E+15, 1.500000E+15, 
+power_densities, 4.847413E+04, 4.258194E+04, 4.258194E+04, 
+burnups, 1.938965E+01, 3.642243E+01, 3.642243E+01, 
+fission_densities, 1.296000E+23, 2.434467E+23, 2.434467E+23, 
 Q_recs, 2.017011E+02, 2.017011E+02, 2.017011E+02, 
 I134, 0.000000E+00, 1.458639E+23, 2.739976E+23, 
 I135, 0.000000E+00, 9.724261E+22, 1.826651E+23, 
@@ -23,6 +26,9 @@ powers, 0.000000E+00, 0.000000E+00, 0.000000E+00,
 keffs, 2.000000E+00, 2.000000E+00, 2.000000E+00, 
 keffs_stddev, 1.000000E-02, 1.000000E-02, 1.000000E-02, 
 fluxes_1grp, 6.666667E+14, 6.666667E+14, 6.666667E+14, 
+power_densities, 2.154406E+04, 2.033818E+04, 2.033818E+04, 
+burnups, 1.292643E+01, 2.512934E+01, 2.512934E+01, 
+fission_densities, 5.760000E+22, 1.119760E+23, 1.119760E+23, 
 Q_recs, 2.017011E+02, 2.017011E+02, 2.017011E+02, 
 I134, 0.000000E+00, 6.716702E+22, 1.305745E+23, 
 I135, 0.000000E+00, 4.477801E+22, 8.704969E+22, 
diff --git a/tests/integration/deplete_cram16/test_deplete_cram16.py b/tests/integration/deplete_cram16/test_deplete_cram16.py
index 0a3d9d7..6c8ab35 100644
--- a/tests/integration/deplete_cram16/test_deplete_cram16.py
+++ b/tests/integration/deplete_cram16/test_deplete_cram16.py
@@ -45,4 +45,5 @@ def test_cram16_deplete():
     # flux.
     test = DepleteHarness([""], "test.h5", "test16.add")
     test._build_inputs()
+    test._create_test_lib()
     test.main()
diff --git a/tests/integration/deplete_cram48/results_true.dat b/tests/integration/deplete_cram48/results_true.dat
index a4ca39a..e4906ad 100644
--- a/tests/integration/deplete_cram48/results_true.dat
+++ b/tests/integration/deplete_cram48/results_true.dat
@@ -8,6 +8,9 @@ powers, 0.000000E+00, 0.000000E+00, 0.000000E+00,
 keffs, 2.000000E+00, 2.000000E+00, 2.000000E+00, 
 keffs_stddev, 1.000000E-02, 1.000000E-02, 1.000000E-02, 
 fluxes_1grp, 1.500000E+15, 1.500000E+15, 1.500000E+15, 
+power_densities, 4.847413E+04, 4.258194E+04, 4.258194E+04, 
+burnups, 1.938965E+01, 3.642243E+01, 3.642243E+01, 
+fission_densities, 1.296000E+23, 2.434467E+23, 2.434467E+23, 
 Q_recs, 2.017011E+02, 2.017011E+02, 2.017011E+02, 
 I134, 0.000000E+00, 1.458639E+23, 2.739976E+23, 
 I135, 0.000000E+00, 9.724261E+22, 1.826651E+23, 
@@ -23,6 +26,9 @@ powers, 0.000000E+00, 0.000000E+00, 0.000000E+00,
 keffs, 2.000000E+00, 2.000000E+00, 2.000000E+00, 
 keffs_stddev, 1.000000E-02, 1.000000E-02, 1.000000E-02, 
 fluxes_1grp, 6.666667E+14, 6.666667E+14, 6.666667E+14, 
+power_densities, 2.154406E+04, 2.033818E+04, 2.033818E+04, 
+burnups, 1.292643E+01, 2.512934E+01, 2.512934E+01, 
+fission_densities, 5.760000E+22, 1.119760E+23, 1.119760E+23, 
 Q_recs, 2.017011E+02, 2.017011E+02, 2.017011E+02, 
 I134, 0.000000E+00, 6.716702E+22, 1.305745E+23, 
 I135, 0.000000E+00, 4.477801E+22, 8.704969E+22, 
diff --git a/tests/integration/deplete_msr/results_true.dat b/tests/integration/deplete_msr/results_true.dat
index 2da0924..802e3cc 100644
--- a/tests/integration/deplete_msr/results_true.dat
+++ b/tests/integration/deplete_msr/results_true.dat
@@ -8,6 +8,9 @@ powers, 1.000000E+01, 1.000000E+01,
 keffs, 2.000000E+00, 2.000000E+00, 
 keffs_stddev, 1.000000E-02, 1.000000E-02, 
 fluxes_1grp, 5.569982E+17, 5.569982E+17, 
+power_densities, 1.500000E+07, 1.500000E+07, 
+burnups, 4.166666E-02, 4.166666E-02, 
+fission_densities, 3.341989E+20, 3.341989E+20, 
 Q_recs, 2.017011E+02, 2.017011E+02, 
 I134, 0.000000E+00, 2.005026E+20, 
 I135, 0.000000E+00, 1.336684E+20, 
@@ -23,6 +26,9 @@ powers, 1.000000E+01, 1.000000E+01,
 keffs, 2.000000E+00, 2.000000E+00, 
 keffs_stddev, 1.000000E-02, 1.000000E-02, 
 fluxes_1grp, 2.475547E+17, 2.475547E+17, 
+power_densities, 6.666667E+06, 6.666667E+06, 
+burnups, 2.777778E-02, 2.777778E-02, 
+fission_densities, 1.485328E+20, 1.485328E+20, 
 Q_recs, 2.017011E+02, 2.017011E+02, 
 I134, 0.000000E+00, 1.782262E+20, 
 I135, 0.000000E+00, 1.188174E+20, 
diff --git a/tests/integration/deplete_nondepl_iso/results_true_cram16.dat b/tests/integration/deplete_nondepl_iso/results_true_cram16.dat
index 0fe8aac..c27234a 100644
--- a/tests/integration/deplete_nondepl_iso/results_true_cram16.dat
+++ b/tests/integration/deplete_nondepl_iso/results_true_cram16.dat
@@ -8,6 +8,9 @@ powers, 0.000000E+00, 0.000000E+00, 0.000000E+00,
 keffs, 2.000000E+00, 2.000000E+00, 2.000000E+00, 
 keffs_stddev, 1.000000E-02, 1.000000E-02, 1.000000E-02, 
 fluxes_1grp, 1.500000E+15, 1.500000E+15, 1.500000E+15, 
+power_densities, 4.847413E+04, 4.258194E+04, 4.258194E+04, 
+burnups, 1.938965E+01, 3.642243E+01, 3.642243E+01, 
+fission_densities, 1.296000E+23, 2.434467E+23, 2.434467E+23, 
 Q_recs, 2.017011E+02, 2.017011E+02, 2.017011E+02, 
 I134, 0.000000E+00, 1.458639E+23, 2.739976E+23, 
 I135, 0.000000E+00, 9.724261E+22, 1.826651E+23, 
@@ -23,5 +26,8 @@ powers, 0.000000E+00, 0.000000E+00, 0.000000E+00,
 keffs, 2.000000E+00, 2.000000E+00, 2.000000E+00, 
 keffs_stddev, 1.000000E-02, 1.000000E-02, 1.000000E-02, 
 fluxes_1grp, 6.666667E+14, 6.666667E+14, 6.666667E+14, 
+power_densities, 2.154406E+04, 2.154406E+04, 2.154406E+04, 
+burnups, 1.292643E+01, 2.585287E+01, 2.585287E+01, 
+fission_densities, 5.760000E+22, 1.152000E+23, 1.152000E+23, 
 Q_recs, 2.017011E+02, 2.017011E+02, 2.017011E+02, 
 U235, 1.000000E+24, 1.000000E+24, 1.000000E+24, 
diff --git a/tests/integration/deplete_nondepl_iso/results_true_cram48.dat b/tests/integration/deplete_nondepl_iso/results_true_cram48.dat
index 0fe8aac..c27234a 100644
--- a/tests/integration/deplete_nondepl_iso/results_true_cram48.dat
+++ b/tests/integration/deplete_nondepl_iso/results_true_cram48.dat
@@ -8,6 +8,9 @@ powers, 0.000000E+00, 0.000000E+00, 0.000000E+00,
 keffs, 2.000000E+00, 2.000000E+00, 2.000000E+00, 
 keffs_stddev, 1.000000E-02, 1.000000E-02, 1.000000E-02, 
 fluxes_1grp, 1.500000E+15, 1.500000E+15, 1.500000E+15, 
+power_densities, 4.847413E+04, 4.258194E+04, 4.258194E+04, 
+burnups, 1.938965E+01, 3.642243E+01, 3.642243E+01, 
+fission_densities, 1.296000E+23, 2.434467E+23, 2.434467E+23, 
 Q_recs, 2.017011E+02, 2.017011E+02, 2.017011E+02, 
 I134, 0.000000E+00, 1.458639E+23, 2.739976E+23, 
 I135, 0.000000E+00, 9.724261E+22, 1.826651E+23, 
@@ -23,5 +26,8 @@ powers, 0.000000E+00, 0.000000E+00, 0.000000E+00,
 keffs, 2.000000E+00, 2.000000E+00, 2.000000E+00, 
 keffs_stddev, 1.000000E-02, 1.000000E-02, 1.000000E-02, 
 fluxes_1grp, 6.666667E+14, 6.666667E+14, 6.666667E+14, 
+power_densities, 2.154406E+04, 2.154406E+04, 2.154406E+04, 
+burnups, 1.292643E+01, 2.585287E+01, 2.585287E+01, 
+fission_densities, 5.760000E+22, 1.152000E+23, 1.152000E+23, 
 Q_recs, 2.017011E+02, 2.017011E+02, 2.017011E+02, 
 U235, 1.000000E+24, 1.000000E+24, 1.000000E+24, 
diff --git a/tests/integration/deplete_nondepl_iso/results_true_origen22.dat b/tests/integration/deplete_nondepl_iso/results_true_origen22.dat
index 774f3d6..e4e2299 100644
--- a/tests/integration/deplete_nondepl_iso/results_true_origen22.dat
+++ b/tests/integration/deplete_nondepl_iso/results_true_origen22.dat
@@ -8,6 +8,9 @@ powers, 0.000000E+00, 0.000000E+00, 0.000000E+00,
 keffs, 2.000000E+00, 2.000000E+00, 2.000000E+00, 
 keffs_stddev, 1.000000E-02, 1.000000E-02, 1.000000E-02, 
 fluxes_1grp, 1.500000E+15, 1.500000E+15, 1.500000E+15, 
+power_densities, 4.847413E+04, 4.258208E+04, 4.258208E+04, 
+burnups, 1.938965E+01, 3.642248E+01, 3.642248E+01, 
+fission_densities, 1.296000E+23, 2.434471E+23, 2.434471E+23, 
 Q_recs, 2.017011E+02, 2.017011E+02, 2.017011E+02, 
 I134, 0.000000E+00, 1.458623E+23, 2.739954E+23, 
 I135, 0.000000E+00, 9.724553E+22, 1.826696E+23, 
@@ -23,5 +26,8 @@ powers, 0.000000E+00, 0.000000E+00, 0.000000E+00,
 keffs, 2.000000E+00, 2.000000E+00, 2.000000E+00, 
 keffs_stddev, 1.000000E-02, 1.000000E-02, 1.000000E-02, 
 fluxes_1grp, 6.666667E+14, 6.666667E+14, 6.666667E+14, 
+power_densities, 2.154406E+04, 2.154406E+04, 2.154406E+04, 
+burnups, 1.292643E+01, 2.585287E+01, 2.585287E+01, 
+fission_densities, 5.760000E+22, 1.152000E+23, 1.152000E+23, 
 Q_recs, 2.017011E+02, 2.017011E+02, 2.017011E+02, 
 U235, 1.000000E+24, 1.000000E+24, 1.000000E+24, 
diff --git a/tests/integration/deplete_origen/results_true.dat b/tests/integration/deplete_origen/results_true.dat
index 1b99562..b4d86b6 100644
--- a/tests/integration/deplete_origen/results_true.dat
+++ b/tests/integration/deplete_origen/results_true.dat
@@ -8,6 +8,9 @@ powers, 0.000000E+00, 0.000000E+00, 0.000000E+00,
 keffs, 2.000000E+00, 2.000000E+00, 2.000000E+00, 
 keffs_stddev, 1.000000E-02, 1.000000E-02, 1.000000E-02, 
 fluxes_1grp, 1.500000E+15, 1.500000E+15, 1.500000E+15, 
+power_densities, 4.847413E+04, 4.258208E+04, 4.258208E+04, 
+burnups, 1.938965E+01, 3.642248E+01, 3.642248E+01, 
+fission_densities, 1.296000E+23, 2.434471E+23, 2.434471E+23, 
 Q_recs, 2.017011E+02, 2.017011E+02, 2.017011E+02, 
 I134, 0.000000E+00, 1.458623E+23, 2.739954E+23, 
 I135, 0.000000E+00, 9.724553E+22, 1.826696E+23, 
@@ -23,6 +26,9 @@ powers, 0.000000E+00, 0.000000E+00, 0.000000E+00,
 keffs, 2.000000E+00, 2.000000E+00, 2.000000E+00, 
 keffs_stddev, 1.000000E-02, 1.000000E-02, 1.000000E-02, 
 fluxes_1grp, 6.666667E+14, 6.666667E+14, 6.666667E+14, 
+power_densities, 2.154406E+04, 2.033825E+04, 2.033825E+04, 
+burnups, 1.292643E+01, 2.512939E+01, 2.512939E+01, 
+fission_densities, 5.760000E+22, 1.119762E+23, 1.119762E+23, 
 Q_recs, 2.017011E+02, 2.017011E+02, 2.017011E+02, 
 I134, 0.000000E+00, 6.716494E+22, 1.305721E+23, 
 I135, 0.000000E+00, 4.477823E+22, 8.705005E+22, 
diff --git a/tests/integration/excore_decay/results_true.dat b/tests/integration/excore_decay/results_true.dat
index e3d510d..032ed80 100644
--- a/tests/integration/excore_decay/results_true.dat
+++ b/tests/integration/excore_decay/results_true.dat
@@ -8,6 +8,9 @@ powers, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.
 keffs, 1.919670E+00, 1.918190E+00, 1.919700E+00, 1.918310E+00, 1.919670E+00, 1.918190E+00, 
 keffs_stddev, 9.487000E-04, 1.005650E-03, 9.618660E-04, 1.087400E-03, 9.487000E-04, 1.005650E-03, 
 fluxes_1grp, 1.000000E+15, 1.000000E+15, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
+power_densities, 3.231609E+04, 3.231609E+04, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
+burnups, 3.231609E+01, 3.231609E+01, 3.231609E+01, 3.231609E+01, 3.231609E+01, 3.231609E+01, 
+fission_densities, 8.640000E+19, 8.640000E+19, 8.640000E+19, 8.640000E+19, 8.640000E+19, 8.640000E+19, 
 Q_recs, 2.017011E+02, 2.017011E+02, 2.017011E+02, 2.017011E+02, 2.017011E+02, 2.017011E+02, 
 He4, 0.000000E+00, 4.999809E+23, 4.999809E+23, 7.499593E+23, 7.499593E+23, 8.749485E+23, 
 I134, 0.000000E+00, 7.478645E+19, 7.478645E+19, 7.478645E+19, 7.478645E+19, 7.478645E+19, 
@@ -25,6 +28,9 @@ powers, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.
 keffs, 1.919670E+00, 1.918190E+00, 1.919700E+00, 1.918310E+00, 1.919670E+00, 1.918190E+00, 
 keffs_stddev, 9.487000E-04, 1.005650E-03, 9.618660E-04, 1.087400E-03, 9.487000E-04, 1.005650E-03, 
 fluxes_1grp, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
+power_densities, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
+burnups, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
+fission_densities, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
 Q_recs, 2.017011E+02, 2.017011E+02, 2.017011E+02, 2.017011E+02, 2.017011E+02, 2.017011E+02, 
 U235, 1.000000E+24, 1.000000E+24, 1.000000E+24, 1.000000E+24, 1.000000E+24, 1.000000E+24, 
 
@@ -38,6 +44,9 @@ powers, 0.000000E+00, 0.000000E+00,
 keffs, 1.919670E+00, 1.918190E+00, 
 keffs_stddev, 9.487000E-04, 1.005650E-03, 
 fluxes_1grp, 1.000000E+15, 1.000000E+15, 
+power_densities, 3.231609E+04, 3.231609E+04, 
+burnups, 3.231609E+01, 3.231609E+01, 
+fission_densities, 8.640000E+19, 8.640000E+19, 
 Q_recs, 2.017011E+02, 2.017011E+02, 
 He4, 0.000000E+00, 4.999809E+23, 
 I134, 0.000000E+00, 7.478645E+19, 
@@ -55,6 +64,9 @@ powers, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.
 keffs, 1.919670E+00, 1.918190E+00, 1.919700E+00, 1.918310E+00, 1.919670E+00, 1.918190E+00, 
 keffs_stddev, 9.487000E-04, 1.005650E-03, 9.618660E-04, 1.087400E-03, 9.487000E-04, 1.005650E-03, 
 fluxes_1grp, 0.000000E+00, 0.000000E+00, 1.000000E+15, 1.000000E+15, 0.000000E+00, 0.000000E+00, 
+power_densities, 0.000000E+00, 0.000000E+00, 1.615804E+04, 1.615804E+04, 0.000000E+00, 0.000000E+00, 
+burnups, 0.000000E+00, 0.000000E+00, 1.615804E+01, 1.615804E+01, 1.615804E+01, 1.615804E+01, 
+fission_densities, 0.000000E+00, 0.000000E+00, 4.320000E+19, 4.320000E+19, 4.320000E+19, 4.320000E+19, 
 Q_recs, 2.017011E+02, 2.017011E+02, 2.017011E+02, 2.017011E+02, 2.017011E+02, 2.017011E+02, 
 He4, 0.000000E+00, 5.000000E+23, 5.000000E+23, 7.499904E+23, 7.499904E+23, 8.749796E+23, 
 I134, 0.000000E+00, 0.000000E+00, 0.000000E+00, 3.739323E+19, 3.739323E+19, 3.739323E+19, 
diff --git a/tests/integration/excore_decay/test.add b/tests/integration/excore_decay/test.add
index 6b51758..7cffa2b 100644
--- a/tests/integration/excore_decay/test.add
+++ b/tests/integration/excore_decay/test.add
@@ -18,6 +18,9 @@ depletion_method = predictor
             neutronics_id_end = 2
             depleting = True
             use_default_depletion_library = True
+        [[[item]]]
+            neutronics_id = 2
+            density = 1.0
 
     [[storage]]
         [[[copy]]]
diff --git a/tests/integration/excore_decay/test_excore_decay.py b/tests/integration/excore_decay/test_excore_decay.py
index 5dbffd6..333458a 100644
--- a/tests/integration/excore_decay/test_excore_decay.py
+++ b/tests/integration/excore_decay/test_excore_decay.py
@@ -75,7 +75,7 @@ class ExCoreHarness(TestHarness):
         depllib.add_isotope("He4", decay=he4dk)
 
         # U235
-        u235xs = ReactionData("b", 1)
+        u235xs = ReactionData()
         u235xs.add_type("fission", "b", [1.0])
         u235dk = DecayData(1.0, "d", 5.)
         u235dk.add_type("alpha", 1., ["Th231"])
diff --git a/tests/integration/mcnp_complex_geometry/test_mcnp_complex_geometry.py b/tests/integration/mcnp_complex_geometry/test_mcnp_complex_geometry.py
index 367e74f..17acecb 100644
--- a/tests/integration/mcnp_complex_geometry/test_mcnp_complex_geometry.py
+++ b/tests/integration/mcnp_complex_geometry/test_mcnp_complex_geometry.py
@@ -28,8 +28,8 @@ class ComplexGeometryHarness(TestHarness):
 
         warning_3 = "There are more cells in universe 1016 than the universe " \
                     "it was cloned from due to a lattice structure being " \
-                    "split up. The volumes for cells in universe 1016 should " \
-                    "be checked."
+                    "split up. The volumes for cells in universe 1016 " \
+                    "and any user tallies should be checked."
 
         self.log_messages = [('warning', warning_1, 1),
                              ('warning', warning_2, 1),
diff --git a/tests/integration/mcnp_surf_search/test.add b/tests/integration/mcnp_surf_search/test.add
index 801f23c..e6b4e48 100644
--- a/tests/integration/mcnp_surf_search/test.add
+++ b/tests/integration/mcnp_surf_search/test.add
@@ -27,7 +27,8 @@ use_depletion_library_xs = False
             k_target = 1.0
             target_interval = 0.001
             bracket_interval = 0., 20.
-            uncertainty_factor = 0.5
+            uncertainty_fraction = 0.5
+            reference_position = "initial"
     [[state 2]]
         label = second_search
         [[[geometry_search_1]]]
@@ -36,3 +37,46 @@ use_depletion_library_xs = False
             target_interval = 0.001
             bracket_interval = 0., 20.
             min_active_batches = 10
+            initial_guess = last
+    [[state 3]]
+        label = third_search
+        [[[geometry_search_1]]]
+            group_name = bank_1
+            k_target = 0.95
+            target_interval = 0.001
+            bracket_interval = -2.5, 2.5
+            min_active_batches = 10
+            initial_guess = 2.0
+            reference_position = "last"
+    [[state 4]]
+        label = fourth_search
+        [[[transform_1]]]
+            group_name = bank_1
+            value = 5.13
+            reset = True
+        [[[geometry_search_1]]]
+            group_name = bank_1
+            k_target = 0.925
+            target_interval = 0.001
+            bracket_interval = -4.13, 13.87
+            min_active_batches = 10
+            reference_position = last
+            initial_guess = last
+    [[state 5]]
+         label = fifth_search
+         [[[geometry_search_1]]]
+            group_name = bank_1
+            k_target = 0.822
+            target_interval = 0.005
+            bracket_interval = 0., 20.
+            uncertainty_fraction = 1
+            reference_position = "initial"
+    [[state 6]]
+         label = sixth_search
+         [[[geometry_search_1]]]
+            group_name = bank_1
+            k_target = 0.822
+            target_interval = 0.015
+            bracket_interval = 0., 20.
+            uncertainty_fraction = 1
+            reference_position = "initial"
diff --git a/tests/integration/mcnp_surf_search/test_mcnp_surf_search.py b/tests/integration/mcnp_surf_search/test_mcnp_surf_search.py
index a6392fd..68dab33 100644
--- a/tests/integration/mcnp_surf_search/test_mcnp_surf_search.py
+++ b/tests/integration/mcnp_surf_search/test_mcnp_surf_search.py
@@ -4,6 +4,7 @@ import os
 import numpy as np
 import h5py
 from tests.testing_harness import TestHarness
+from adder.mcnp.constants import CI_95
 
 inp_file = """Cylinder rod test case
 1 1 4e-3 -1  10 -11 imp:n=1    $ homogenized fuel
@@ -22,7 +23,18 @@ ksrc 0. 0. 1. 1. 1. 1. 1. -1. 1. -1. 1. 1. -1. -1. 1.
 
 
 class GeomSweepHarness(TestHarness):
-    REF_RANGES = [(8.58, 8.84), (2.14, 2.22)]
+    REF_RANGES = [(8.58, 8.84), (2.14, 2.22), (2.03, 2.35), (-2.12, -1.80), (0, 1), (0, 1)]
+
+    k_targets = [1.0, 0.9, 0.95, 0.925, 0.822, 0.822]
+    target_intervals = [0.001, 0.001, 0.001, 0.001, 0.005, 0.015]
+    REF_TARGET_RANGES = []
+
+    for target, interval in zip(k_targets, target_intervals):
+        REF_TARGET_RANGES.append([target - interval, target + interval])
+
+    @property
+    def REF_INITIALS(self):
+        return [self.displacements[0], 2.0, 0.0]
 
     def _build_inputs(self):
         with open("test.inp", mode="w") as mcnp_input_file:
@@ -33,8 +45,11 @@ class GeomSweepHarness(TestHarness):
 
     def _get_results(self):
         """Digest info in the output and return as array of the 2 positions."""
-        output = self._get_outputs()
+        output, initial_positions, keffs, keff_stddevs = self._get_outputs()
         self.displacements = output
+        self.initial_positions = initial_positions
+        self.keffs = keffs
+        self.keff_stddevs = keff_stddevs
 
     def _write_results(self, results_string):
         pass
@@ -48,19 +63,48 @@ class GeomSweepHarness(TestHarness):
         assert len(self.REF_RANGES) == len(self.displacements)
         for i in range(len(self.REF_RANGES)):
             assert self.REF_RANGES[i][0] <= self.displacements[i] <= self.REF_RANGES[i][1]
+        assert np.array_equal(np.round(np.array(self.REF_INITIALS), 3), 
+                              np.round(np.array(self.initial_positions), 3))
+
+        for i in range(len(self.REF_TARGET_RANGES)):
+
+            keff = self.keffs[i]
+            keff_std = self.keff_stddevs[i]
+            keff_95lo = keff - (CI_95 * keff_std)
+            keff_95hi = keff + (CI_95 * keff_std)
+
+            assert keff_95lo >= self.REF_TARGET_RANGES[i][0]
+            assert keff_95hi <= self.REF_TARGET_RANGES[i][1]
 
     def _get_outputs(self):
         # Get the HDF5 file and obtain the control group displacement in time
-        h5_group_names = ["case_1/operation_1/step_1/control_groups/bank_1/",
-                          "case_2/operation_1/step_1/control_groups/bank_1/"]
-
-        displacements = []
+        h5_group_names = ["case_1/operation_1/step_1/",
+                          "case_2/operation_1/step_1/",
+                          "case_3/operation_1/step_1/",
+                          "case_4/operation_2/step_1/",
+                          "case_5/operation_1/step_1/",
+                          "case_6/operation_1/step_1/"]
+
+        displacements, keffs, keff_stddevs = [], [], []
         with h5py.File("results.h5", "r") as h5:
             for group_name in h5_group_names:
-                grp = h5[group_name]
+                grp = h5[group_name + "control_groups/bank_1/"]
                 displacements.append(float(grp.attrs["displacement"]))
 
-        return displacements
+                keffs.append(h5[group_name].attrs["keff"])
+                keff_stddevs.append(h5[group_name].attrs["keff_stddev"])
+
+        initial_positions = []
+        with open("adder.log", "r") as log:
+            found = False
+            for line in log:
+                if ' as initial guess' in line:
+                    found = True
+                elif found and ('Iteration 1' in line):
+                    initial_positions.append(float(line.split('Position')[-1]))
+                    found = False
+
+        return displacements, initial_positions, keffs, keff_stddevs
 
 
 def test_mcnp_surf_search():
diff --git a/tests/integration/msr_constant_feed/results_true.dat b/tests/integration/msr_constant_feed/results_true.dat
index dcd8d12..7991011 100644
--- a/tests/integration/msr_constant_feed/results_true.dat
+++ b/tests/integration/msr_constant_feed/results_true.dat
@@ -8,6 +8,9 @@ powers, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00,
 keffs, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
 keffs_stddev, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
 fluxes_1grp, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
+power_densities, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
+burnups, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
+fission_densities, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
 Q_recs, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
 I135, 0.000000E+00, 9.416144E+20, 1.828761E+21, 2.664589E+21, 
 U235, 1.000000E+24, 9.430961E+23, 8.894838E+23, 8.389727E+23, 
diff --git a/tests/integration/msr_constant_feed/test.add b/tests/integration/msr_constant_feed/test.add
index c38406f..421c3ab 100644
--- a/tests/integration/msr_constant_feed/test.add
+++ b/tests/integration/msr_constant_feed/test.add
@@ -17,6 +17,7 @@ output_hdf5 = results.h5
       [[[item_2]]]
         neutronics_id = 2
         volume = 1.
+        depleting = False
 
 [msr]
     solve_method = tmatrix
@@ -27,12 +28,12 @@ output_hdf5 = results.h5
         flowrate = 10.
         [[[feed]]]
             feed_rate = 1e22
-            feed_material = f1
+            feed_material = material_f1
             feed_mixture = 1
 	        feed_rate_units = atoms/sec
             density = 10.
             vector_units = ao
-            [[[[material_f1]]]]
+            [[[[material_material_f1]]]]
                 names = U235, I135
                 vector = 0.5, 0.5
         [[[component_1]]]
diff --git a/tests/integration/msr_constant_feed_variable_input/results_true.dat b/tests/integration/msr_constant_feed_variable_input/results_true.dat
index dcd8d12..7991011 100644
--- a/tests/integration/msr_constant_feed_variable_input/results_true.dat
+++ b/tests/integration/msr_constant_feed_variable_input/results_true.dat
@@ -8,6 +8,9 @@ powers, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00,
 keffs, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
 keffs_stddev, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
 fluxes_1grp, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
+power_densities, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
+burnups, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
+fission_densities, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
 Q_recs, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
 I135, 0.000000E+00, 9.416144E+20, 1.828761E+21, 2.664589E+21, 
 U235, 1.000000E+24, 9.430961E+23, 8.894838E+23, 8.389727E+23, 
diff --git a/tests/integration/msr_variable_feed_multi_block/results_true.dat b/tests/integration/msr_variable_feed_multi_block/results_true.dat
index 9683b01..09183b6 100644
--- a/tests/integration/msr_variable_feed_multi_block/results_true.dat
+++ b/tests/integration/msr_variable_feed_multi_block/results_true.dat
@@ -8,6 +8,9 @@ powers, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00,
 keffs, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
 keffs_stddev, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
 fluxes_1grp, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
+power_densities, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
+burnups, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
+fission_densities, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
 Q_recs, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
 I135, 0.000000E+00, 9.416144E+20, 2.802842E+21, 4.081166E+21, 
 U235, 1.000000E+24, 9.430961E+23, 9.029255E+23, 8.580205E+23, 
diff --git a/tests/integration/msr_variable_feed_single_block/results_true.dat b/tests/integration/msr_variable_feed_single_block/results_true.dat
index 732fa18..25c556a 100644
--- a/tests/integration/msr_variable_feed_single_block/results_true.dat
+++ b/tests/integration/msr_variable_feed_single_block/results_true.dat
@@ -8,6 +8,9 @@ powers, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00,
 keffs, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
 keffs_stddev, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
 fluxes_1grp, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
+power_densities, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
+burnups, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
+fission_densities, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
 Q_recs, 0.000000E+00, 0.000000E+00, 0.000000E+00, 0.000000E+00, 
 I135, 0.000000E+00, 9.416144E+20, 2.802842E+21, 4.081166E+21, 
 U235, 1.000000E+24, 9.430961E+23, 9.029255E+23, 8.580205E+23, 
diff --git a/tests/integration/neutronics_mcnp/results_true.dat b/tests/integration/neutronics_mcnp/results_true.dat
index b79664f..d431aeb 100644
--- a/tests/integration/neutronics_mcnp/results_true.dat
+++ b/tests/integration/neutronics_mcnp/results_true.dat
@@ -54,6 +54,7 @@ m43 92235.70c 1.
 F99999984:N 11 12
 E99999984 2.00000000E+01
 FM99999984:N (1. 43 -6)
+c User tallies
 FMESH4:n ORIGIN=0,0,0 IMESH=10,20 JMESH=10,20 KMESH=10,20
 
 message: xsdir=./xsdir
@@ -116,6 +117,7 @@ sp3 0 1
 F99999994:N 11 12 21 22 31 32 41 42
 E99999994 20.0
 FC99999994 Flux tally for depletion
+c User tallies
 FMESH4:n ORIGIN=0,0,0 IMESH=10,20 JMESH=10,20 KMESH=10,20
 
 message: xsdir=./xsdir
@@ -178,6 +180,7 @@ sp3 0 1
 F99999994:N 11 12 21 22 31 32 41 42
 E99999994 20.0
 FC99999994 Flux tally for depletion
+c User tallies
 FMESH4:n ORIGIN=0,0,0 IMESH=10,20 JMESH=10,20 KMESH=10,20
 
 message: xsdir=./xsdir
diff --git a/tests/integration/neutronics_mcnp/test.add b/tests/integration/neutronics_mcnp/test.add
index 9603bd3..1665127 100644
--- a/tests/integration/neutronics_mcnp/test.add
+++ b/tests/integration/neutronics_mcnp/test.add
@@ -3,7 +3,6 @@ neutronics_solver = "MCNP"
 neutronics_exec = mcnp.EXE
 num_neutronics_threads = 2
 num_depletion_threads = 4
-depletion_chunksize = 100
 neutronics_input_file = test.inp
 neutronics_library_file = ./xsdir
 depletion_solver = ORIGEN2.2
@@ -48,6 +47,11 @@ use_depletion_library_xs = False
                 neutronics_id_end = 63
                 exclude_neutronics_ids = 63
 
+[tallies]
+    [[item]]
+        tally_id = 4
+        type=universe
+
 [operations]
     [[state 0]]
         label = "Cycle 0"
@@ -82,4 +86,4 @@ use_depletion_library_xs = False
             mode = "w"
         [[[write_depletion_lib_all]]]
             filename = "output_all_modified.h5"
-            materials = all_modified
\ No newline at end of file
+            materials = all_modified
diff --git a/tests/integration/neutronics_mcnp/test_neutronics_mcnp.py b/tests/integration/neutronics_mcnp/test_neutronics_mcnp.py
index dad2a8b..cb45a91 100644
--- a/tests/integration/neutronics_mcnp/test_neutronics_mcnp.py
+++ b/tests/integration/neutronics_mcnp/test_neutronics_mcnp.py
@@ -1,6 +1,8 @@
 import pytest
 import os
+import h5py
 import numpy as np
+import scipy.sparse as sp
 from tests import mcnp_2x2x2
 from tests import default_config as config
 from tests.testing_harness import TestHarness
@@ -16,7 +18,7 @@ class MCNPHarness(TestHarness):
             self._create_test_lib()
             # Run 1
             self._run_adder()
-            results, exec_skip_lines_1 = self._get_results()
+            results, exec_skip_lines_1 = self._get_outputs()
             self._write_results(results)
             self._compare_results()
 
@@ -28,10 +30,13 @@ class MCNPHarness(TestHarness):
 
             # Now we know that we got the same results, lets just verify that
             # the first pass actually executed mcnp while the second skipped it
+            assert len(exec_skip_lines_1) == 8
             for line in exec_skip_lines_1:
                 assert "Executing MCNP" in line
+            assert len(exec_skip_lines_2) == 8
             for line in exec_skip_lines_2:
                 assert "Skipping MCNP" in line
+
         finally:
             self._cleanup()
 
@@ -54,9 +59,9 @@ class MCNPHarness(TestHarness):
         # Now get from the log whether or not we skipped MCNP
         exec_skip_lines = []
         with open("adder.log", "r") as fin:
-            for line in fin.readline():
+            for line in fin:
                 if "Executing MCNP" in line or "Skipping MCNP" in line:
-                    exec_skip_lines.append(line[30:].ltrim())
+                    exec_skip_lines.append(line[30:].lstrip())
         return outstr, exec_skip_lines
 
     def _run_adder_ff(self):
@@ -91,7 +96,8 @@ class MCNPHarness(TestHarness):
 
             # Now make sure we have the correct data; most direct and
             # concise way is to just compare the depletion matrices
-            test_A = test_lib.build_depletion_matrix(flux).todense()
+            dk_matrix = sp.csr_matrix(test_lib.build_decay_matrix())
+            test_A = test_lib.build_depletion_matrix(flux, dk_matrix).todense()
             np.testing.assert_allclose(ref_A, test_A, rtol=1.e-15)
 
         for name in unmatching:
@@ -100,7 +106,8 @@ class MCNPHarness(TestHarness):
 
             # Now make sure we have the correct data; most direct and
             # concise way is to just compare the depletion matrices
-            test_A = test_lib.build_depletion_matrix(flux).todense()
+            dk_matrix = sp.csr_matrix(test_lib.build_decay_matrix())
+            test_A = test_lib.build_depletion_matrix(flux, dk_matrix).todense()
             # This material doesn't have H1 so the lib doesnt have it
             # either
             assert list(test_lib.isotopes.keys()) == \
diff --git a/tests/integration/shuffle_bymat/results_true.dat b/tests/integration/shuffle_bymat/results_true.dat
index f527ab1..6e2def4 100644
--- a/tests/integration/shuffle_bymat/results_true.dat
+++ b/tests/integration/shuffle_bymat/results_true.dat
@@ -61,11 +61,40 @@ sp3 0 1
 F99999994:N 11 12 21 22 31 32 41 42
 E99999994 20.0
 FC99999994 Flux tally for depletion
+c User tallies
+f6:n,p 42
+e6:n 1E-5 1E-3
+tm6 1 2
+c6 -.866 -.5 0 .5 .866 1
+t6 2 4
+df6 IC 40 IU 1 LIN FAC 123.4
+f34:n 11 12
+e34 1. 20
+tm34 1 2
+c34 -.866 -.5 0 .5 .866 1
+t34 2 4
+df34 IC 40 IU 1 LIN FAC 123.4
+fc54 testing
+f54:n 41
+fm54 (1. 11 (-1 103))
+e54:n 1E-5 1E-3
+tm54 1 2
+c54 -.866 -.5 0 .5 .866 1
+t54 2 4
+df54 IC 40 IU 1 LIN FAC 123.4
+fc64 flux in mat cell replaced by supply
+f64:n 42
+tm64 4 6
+e64:n 1E-5 1E-3
+c64 -.866 -.5 0 .5 .866 1
+t64 2 4
+df64 IC 40 IU 1 LIN FAC 123.4
 FMESH4:n ORIGIN=0,0,0 IMESH=10,20 JMESH=10,20 KMESH=10,20 TYPE=FLUX
+df4 IC 40 IU 1 LIN FAC 123.4
 
 message: xsdir=./xsdir
 
-Simple 2x2x2 Grid, but the title is artificially long to[...] case_2_op_4_step_1
+Simple 2x2x2 Grid, but the title is artificially long to[...] case_2_op_3_step_1
 11 21 1.5420618013560E-02 10 -11 21 -22 30 -31 vol=1000.0 u=0 imp:n=1 trcl=1
 12 22 1.2712753933619E-02 10 -11 21 -22 31 -32 vol=1000.0 u=0 imp:n=1 trcl=2
 21 11 1.1021230352758E-02 11 -12 21 -22 30 -31 vol=1000.0 u=0 imp:n=1 trcl=6
@@ -127,11 +156,46 @@ sp3 0 1
 F99999994:N 11 12 21 22 31 32 41 42
 E99999994 20.0
 FC99999994 Flux tally for depletion
+c User tallies
+f6:n,p 42
+e6:n 1E-5 1E-3
+tm6 1 2
+c6 -.866 -.5 0 .5 .866 1
+t6 2 4
+df6 IC 40 IU 1 LIN FAC 123.4
+f74:n 11 12
+e74 1. 20
+tm74 1 2
+c74 -.866 -.5 0 .5 .866 1
+t74 2 4
+df74 IC 40 IU 1 LIN FAC 123.4
+fc84 flux in mat cell replaced by supply
+f84:n 42
+tm84 4 6
+e84:n 1E-5 1E-3
+c84 -.866 -.5 0 .5 .866 1
+t84 2 4
+df84 IC 40 IU 1 LIN FAC 123.4
 FMESH4:n ORIGIN=0,0,0 IMESH=10,20 JMESH=10,20 KMESH=10,20 TYPE=FLUX
+df4 IC 40 IU 1 LIN FAC 123.4
+f34:n 21 22
+e34 1. 20
+tm34 1 2
+c34 -.866 -.5 0 .5 .866 1
+t34 2 4
+df34 IC 40 IU 1 LIN FAC 123.4
+fc54 testing
+f54:n 41
+fm54 (1. 11 (-1 103))
+e54:n 1E-5 1E-3
+tm54 1 2
+c54 -.866 -.5 0 .5 .866 1
+t54 2 4
+df54 IC 40 IU 1 LIN FAC 123.4
 
 message: xsdir=./xsdir
 
-Simple 2x2x2 Grid, but the title is artificially long to[...] case_4_op_2_step_1
+Simple 2x2x2 Grid, but the title is artificially long to[...] case_3_op_2_step_1
 11 61 6.1000000000000E+00 10 -11 21 -22 30 -31 vol=1000.0 u=0 imp:n=1 trcl=1
 12 62 6.2000000000000E+00 10 -11 21 -22 31 -32 vol=1000.0 u=0 imp:n=1 trcl=2
 21 11 1.1021230352758E-02 11 -12 21 -22 30 -31 vol=1000.0 u=0 imp:n=1 trcl=6
@@ -193,11 +257,46 @@ sp3 0 1
 F99999994:N 11 12 21 22 31 32 41 42
 E99999994 20.0
 FC99999994 Flux tally for depletion
+c User tallies
+f6:n,p 42
+e6:n 1E-5 1E-3
+tm6 1 2
+c6 -.866 -.5 0 .5 .866 1
+t6 2 4
+df6 IC 40 IU 1 LIN FAC 123.4
+f94:n 11 12
+e94 1. 20
+tm94 1 2
+c94 -.866 -.5 0 .5 .866 1
+t94 2 4
+df94 IC 40 IU 1 LIN FAC 123.4
 FMESH4:n ORIGIN=0,0,0 IMESH=10,20 JMESH=10,20 KMESH=10,20 TYPE=FLUX
+df4 IC 40 IU 1 LIN FAC 123.4
+f34:n 21 22
+e34 1. 20
+tm34 1 2
+c34 -.866 -.5 0 .5 .866 1
+t34 2 4
+df34 IC 40 IU 1 LIN FAC 123.4
+fc54 testing
+f54:n 41
+fm54 (1. 11 (-1 103))
+e54:n 1E-5 1E-3
+tm54 1 2
+c54 -.866 -.5 0 .5 .866 1
+t54 2 4
+df54 IC 40 IU 1 LIN FAC 123.4
+fc84 flux in mat cell replaced by supply
+f84:n 42
+tm84 4 6
+e84:n 1E-5 1E-3
+c84 -.866 -.5 0 .5 .866 1
+t84 2 4
+df84 IC 40 IU 1 LIN FAC 123.4
 
 message: xsdir=./xsdir
 
-Simple 2x2x2 Grid, but the title is artificially long to[...] case_5_op_2_step_1
+Simple 2x2x2 Grid, but the title is artificially long to[...] case_4_op_2_step_1
 11 61 6.1000000000000E+00 10 -11 21 -22 30 -31 vol=1000.0 u=0 imp:n=1 trcl=1
 12 62 6.2000000000000E+00 10 -11 21 -22 31 -32 vol=1000.0 u=0 imp:n=1 trcl=2
 21 11 1.1021230352758E-02 11 -12 21 -22 30 -31 vol=1000.0 u=0 imp:n=1 trcl=6
@@ -260,11 +359,45 @@ sp3 0 1
 F99999994:N 11 12 21 22 31 32 41 42
 E99999994 20.0
 FC99999994 Flux tally for depletion
+c User tallies
+f6:n,p 42
+e6:n 1E-5 1E-3
+tm6 1 2
+c6 -.866 -.5 0 .5 .866 1
+t6 2 4
+df6 IC 40 IU 1 LIN FAC 123.4
+fc104 flux in mat cell replaced by supply
+f104:n 42
+tm104 4 6
+e104:n 1E-5 1E-3
+c104 -.866 -.5 0 .5 .866 1
+t104 2 4
+df104 IC 40 IU 1 LIN FAC 123.4
 FMESH4:n ORIGIN=0,0,0 IMESH=10,20 JMESH=10,20 KMESH=10,20 TYPE=FLUX
+df4 IC 40 IU 1 LIN FAC 123.4
+f34:n 21 22
+e34 1. 20
+tm34 1 2
+c34 -.866 -.5 0 .5 .866 1
+t34 2 4
+df34 IC 40 IU 1 LIN FAC 123.4
+fc84 flux in mat cell replaced by supply
+f84:n 41
+tm84 4 6
+e84:n 1E-5 1E-3
+c84 -.866 -.5 0 .5 .866 1
+t84 2 4
+df84 IC 40 IU 1 LIN FAC 123.4
+f94:n 11 12
+e94 1. 20
+tm94 1 2
+c94 -.866 -.5 0 .5 .866 1
+t94 2 4
+df94 IC 40 IU 1 LIN FAC 123.4
 
 message: xsdir=./xsdir
 
-Simple 2x2x2 Grid, but the title is artificially long to[...] case_7_op_2_step_1
+Simple 2x2x2 Grid, but the title is artificially long to[...] case_5_op_2_step_1
 11 12 8.7795921826831E-03 10 -11 21 -22 30 -31 vol=1000.0 u=0 imp:n=1 trcl=1
 12 11 1.1021230352758E-02 10 -11 21 -22 31 -32 vol=1000.0 u=0 imp:n=1 trcl=2
 21 64 5.1000000000000E+00 11 -12 21 -22 30 -31 vol=1000.0 u=0 imp:n=1 trcl=6
@@ -327,11 +460,10 @@ sp3 0 1
 F99999994:N 11 12 21 22 31 32 41 42
 E99999994 20.0
 FC99999994 Flux tally for depletion
-FMESH4:n ORIGIN=0,0,0 IMESH=10,20 JMESH=10,20 KMESH=10,20 TYPE=FLUX
 
 message: xsdir=./xsdir
 
-Simple 2x2x2 Grid, but the title is artificially long to[...] case_7_op_4_step_1
+Simple 2x2x2 Grid, but the title is artificially long to[...] case_5_op_4_step_1
 11 62 6.2000000000000E+00 10 -11 21 -22 30 -31 vol=1000.0 u=0 imp:n=1 trcl=1
 12 11 1.1021230352758E-02 10 -11 21 -22 31 -32 vol=1000.0 u=0 imp:n=1 trcl=2
 21 64 5.1000000000000E+00 11 -12 21 -22 30 -31 vol=1000.0 u=0 imp:n=1 trcl=6
@@ -394,11 +526,10 @@ sp3 0 1
 F99999994:N 11 12 21 22 31 32 41 42
 E99999994 20.0
 FC99999994 Flux tally for depletion
-FMESH4:n ORIGIN=0,0,0 IMESH=10,20 JMESH=10,20 KMESH=10,20 TYPE=FLUX
 
 message: xsdir=./xsdir
 
-Simple 2x2x2 Grid, but the title is artificially long to[...] case_8_op_2_step_1
+Simple 2x2x2 Grid, but the title is artificially long to[...] case_6_op_2_step_1
 11 62 6.2000000000000E+00 10 -11 21 -22 30 -31 vol=1000.0 u=0 imp:n=1 trcl=9
 12 11 1.1021230352758E-02 10 -11 21 -22 31 -32 vol=1000.0 u=0 imp:n=1 trcl=10
 21 64 5.1000000000000E+00 11 -12 21 -22 30 -31 vol=1000.0 u=0 imp:n=1 trcl=10
@@ -439,13 +570,13 @@ m64 92235.70c 5.000000E-01 92238.70c 1.000000E-01 8016.70c 3.000000E-01 1001.70c
      1.000000E-01
 tr4 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.8660254037844387 0.5000000000000001 0.0
      -0.4999999999999998 0.8660254037844387 1
-tr8 0.0 0.0 0.0 0.0 -1.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1
-tr9 0.0 0.0 0.0 0.0 0.0 -1.0 1.0 0.0 0.0 0.0 -1.0 0.0 1
-tr10 0.0 0.0 0.0 0.0 -1.0 0.0 0.0 0.0 -1.0 1.0 0.0 0.0 1
-tr12 0.0 0.0 0.0 0.7071067811865475 -0.7071067811865476 0.0 0.7071067811865476
-     0.7071067811865476 0.0 0.0 0.0 1.0 1
-tr14 0.0 0.0 0.0 0.0 -0.8660254037844387 -0.5000000000000001 1.0 0.0 0.0 0.0
-     -0.5000000000000001 0.8660254037844387 1
+tr8 0.0 0.0 0.0 0.0 1.0 0.0 -1.0 0.0 0.0 0.0 0.0 1.0 1
+tr9 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 1
+tr10 0.0 0.0 0.0 0.0 0.0 -1.0 -1.0 0.0 0.0 0.0 1.0 0.0 1
+tr12 0.0 0.0 0.0 -0.7071067811865476 0.7071067811865476 0.0 -0.7071067811865476
+     -0.7071067811865475 0.0 0.0 0.0 1.0 1
+tr14 0.0 0.0 0.0 0.0 1.0 0.0 -0.8660254037844387 0.0 0.5000000000000001
+     0.5000000000000001 0.0 0.8660254037844387 1
 PRINT 60 128 130
 PRDMP 0 0 1
 kcode 100 1.00000 10 100 4500 0 6500 1
@@ -459,11 +590,10 @@ sp3 0 1
 F99999994:N 11 12 21 22 31 32 41 42
 E99999994 20.0
 FC99999994 Flux tally for depletion
-FMESH4:n ORIGIN=0,0,0 IMESH=10,20 JMESH=10,20 KMESH=10,20 TYPE=FLUX
 
 message: xsdir=./xsdir
 
-Simple 2x2x2 Grid, but the title is artificially long to[...] case_8_op_4_step_1
+Simple 2x2x2 Grid, but the title is artificially long to[...] case_6_op_4_step_1
 11 62 6.2000000000000E+00 10 -11 21 -22 30 -31 vol=1000.0 u=0 imp:n=1 trcl=16
 12 11 1.1021230352758E-02 10 -11 21 -22 31 -32 vol=1000.0 u=0 imp:n=1 trcl=10
 21 64 5.1000000000000E+00 11 -12 21 -22 30 -31 vol=1000.0 u=0 imp:n=1 trcl=10
@@ -504,13 +634,13 @@ m64 92235.70c 5.000000E-01 92238.70c 1.000000E-01 8016.70c 3.000000E-01 1001.70c
      1.000000E-01
 tr4 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.8660254037844387 0.5000000000000001 0.0
      -0.4999999999999998 0.8660254037844387 1
-tr8 0.0 0.0 0.0 0.0 -1.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1
-tr10 0.0 0.0 0.0 0.0 -1.0 0.0 0.0 0.0 -1.0 1.0 0.0 0.0 1
-tr12 0.0 0.0 0.0 0.7071067811865475 -0.7071067811865476 0.0 0.7071067811865476
-     0.7071067811865476 0.0 0.0 0.0 1.0 1
-tr14 0.0 0.0 0.0 0.0 -0.8660254037844387 -0.5000000000000001 1.0 0.0 0.0 0.0
-     -0.5000000000000001 0.8660254037844387 1
-tr16 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 -1.0 0.0 1
+tr8 0.0 0.0 0.0 0.0 1.0 0.0 -1.0 0.0 0.0 0.0 0.0 1.0 1
+tr10 0.0 0.0 0.0 0.0 0.0 -1.0 -1.0 0.0 0.0 0.0 1.0 0.0 1
+tr12 0.0 0.0 0.0 -0.7071067811865476 0.7071067811865476 0.0 -0.7071067811865476
+     -0.7071067811865475 0.0 0.0 0.0 1.0 1
+tr14 0.0 0.0 0.0 0.0 1.0 0.0 -0.8660254037844387 0.0 0.5000000000000001
+     0.5000000000000001 0.0 0.8660254037844387 1
+tr16 0.0 0.0 0.0 -1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1
 PRINT 60 128 130
 PRDMP 0 0 1
 kcode 100 1.00000 10 100 4500 0 6500 1
@@ -524,5 +654,4 @@ sp3 0 1
 F99999994:N 11 12 21 22 31 32 41 42
 E99999994 20.0
 FC99999994 Flux tally for depletion
-FMESH4:n ORIGIN=0,0,0 IMESH=10,20 JMESH=10,20 KMESH=10,20 TYPE=FLUX
 
diff --git a/tests/integration/shuffle_bymat/test.add b/tests/integration/shuffle_bymat/test.add
index b0b278d..721a7ef 100644
--- a/tests/integration/shuffle_bymat/test.add
+++ b/tests/integration/shuffle_bymat/test.add
@@ -58,6 +58,14 @@ output_hdf5 = results.h5
         name = "fresh_tall"
         set = 61, 62
 
+[tallies]
+    [[list_mat]]
+        tally_ids = 14, 24, 34, 44
+        type = material
+    [[item_detect]]
+        tally_id = 4
+        type = material
+
 [operations]
     [[state 1]]
         label = "Cycle 1"
@@ -93,6 +101,7 @@ output_hdf5 = results.h5
            z_flip = True
         [[[write_input_1]]]
             filename = "state5.inp"
+            include_user_tallies = False
         [[[revolve_2]]]
            set = 62, 12
            shape = 1, 1, 2
@@ -100,6 +109,7 @@ output_hdf5 = results.h5
            z_flip = False
         [[[write_input_2]]]
             filename = "state6.inp"
+            include_user_tallies = False
     [[Cycle 6]]
         [[[transform]]]
            set = 11, 12, 21, 22, 31, 32, 42
@@ -108,10 +118,13 @@ output_hdf5 = results.h5
            angle_units = degrees
         [[[write_input]]]
             filename = "state7.inp"
+            include_user_tallies = False
         [[[transform_2]]]
            set = 11
            type = cell
            matrix = 0.,  1.,  0., -1.,  0.,  0., 0.,  0.,  1.
            angle_units = degrees
         [[[write_input_2]]]
-            filename = "state8.inp"
+           filename = "state8.inp"
+           include_user_tallies = False
+
diff --git a/tests/integration/shuffle_bymat/test_shuffle_bymat.py b/tests/integration/shuffle_bymat/test_shuffle_bymat.py
index ecd1c9e..65e60b8 100644
--- a/tests/integration/shuffle_bymat/test_shuffle_bymat.py
+++ b/tests/integration/shuffle_bymat/test_shuffle_bymat.py
@@ -1,10 +1,26 @@
 import pytest
 import re
+import h5py
+import numpy as np
+from adder.constants import IN_CORE, STORAGE, SUPPLY
 from tests import mcnp_2x2x2_trcl
 from tests.testing_harness import TestHarness
 
 
 class ShuffleHarness(TestHarness):
+
+    def execute_test(self):
+        """Run ADDER with the appropriate arguments and check the outputs."""
+        try:
+            self._create_test_lib()
+            self._run_adder()
+            results = self._get_results()
+            self._write_results(results)
+            self._compare_mcnp_files()
+            _check_materials_status("results.h5")
+        finally:
+            self._cleanup()
+
     def _build_inputs(self):
         with open("test.inp", mode="w") as mcnp_input_file:
             mcnp_input_file.write(mcnp_2x2x2_trcl)
@@ -20,7 +36,9 @@ def test_mcnp_shuffle_bymat():
     # This tests MCNPs ability to shuffle fuel. The second test is the same as
     # the first, but the volumes are removed from the materials in the MCNP
     # input to check if ADDER raises a warning during the shuffling of materials
-    # with no volumes.
+    # with no volumes. Additional tests are added to check the rotation via the
+    # the transform subsection using the yaw, pitch, roll and matrix attributes
+    # w/ the mcnp (default) and common notation. 
 
     output_text_files = ["state{}.inp".format(i + 1) for i in range(8)]
     test = ShuffleHarness(output_text_files, "test.h5")
@@ -39,3 +57,107 @@ def test_mcnp_shuffle_bymat():
     test._run_adder()
     test._check_log_messages()
     test._cleanup()
+
+
+def _check_materials_status(h5_filename):
+    """
+    This function checks the status of selected materials from the HDF5 file
+    against reference values provided via the _base_materials (initial) 
+    dictionary and _update_materials_status function. 
+    """
+    with h5py.File(h5_filename, "r") as h5:
+        i_step = 0
+        i_checks = 0
+        i_tot_references = 0
+        reference = {}
+        case_ids = np.sort([int(x.split('_')[-1]) for x in h5.keys()])
+        for case_name in [f'case_{x}' for x in case_ids]:
+            case = h5[case_name]
+            op_ids = np.sort([int(x.split('_')[-1]) for x in case.keys()])
+            for operation_name in [f'operation_{x}' for x in op_ids]:
+                operation = case[operation_name]
+                step_ids = np.sort([int(x.split('_')[-1]) 
+                                    for x in operation.keys()])
+                for step_name in [f'step_{x}' for x in step_ids]:
+                    step = operation[step_name]
+                    materials = step['materials']
+                    i_step += 1
+                    reference = _update_materials_status(reference, i_step)
+                    i_tot_references += len(reference)
+                    if reference:
+                        for material_name in materials:
+                            data = materials[material_name]
+                            material = data[()]
+                            status = material['status']
+                            material_id = material['id'][0]
+                            try:
+                                ref_status = reference[str(material_id)]
+                            except KeyError as e:
+                                # This material is not one of our checks
+                                continue
+
+                            # Check status
+                            i_checks += 1
+                            assert int(status) == int(ref_status)
+
+                    # Check that all the available references were checked
+                    assert i_checks == i_tot_references
+
+
+_base_materials = {
+    '11': IN_CORE,
+    '12': IN_CORE,
+    '21': IN_CORE,
+    '22': IN_CORE,
+    '31': IN_CORE,
+    '32': IN_CORE,
+    '41': IN_CORE,
+    '42': IN_CORE,
+    '51': SUPPLY,
+    '61': STORAGE,
+    '62': STORAGE,  
+}
+
+def _update_materials_status(previous, write_id):
+    """ 
+    This function reflects 1-to-1 the shuffle and revolve operations in 
+    the test.add file 
+    """
+    materials = previous.copy()
+    if write_id == 1:
+        materials = _base_materials.copy()
+    elif write_id == 2:
+        materials['63'] = IN_CORE           #fresh[1]
+        materials['42'] = STORAGE
+        materials['11'] = previous['21']
+        materials['21'] = previous['11']
+        materials['12'] = previous['22']
+        materials['22'] = previous['12']
+    elif write_id == 3:
+        materials['61'] = previous['21']
+        materials['21'] = previous['61']
+        materials['62'] = previous['22']
+        materials['22'] = previous['62']
+    elif write_id == 4:
+        materials['64'] = IN_CORE           #fresh[2]
+        materials['63'] = previous['41'] 
+        materials['41'] = STORAGE
+    elif write_id == 5:
+        # Revolve top
+        materials['62'] = previous['31']
+        materials['31'] = previous['64']
+        materials['64'] = previous['11']
+        materials['11'] = previous['62']
+        # Revolve bottom
+        materials['12'] = previous['61']
+        materials['61'] = previous['32']
+        materials['32'] = previous['63']
+        materials['63'] = previous['12']
+    elif write_id == 6:
+        materials['62'] = previous['12']
+        materials['12'] = previous['62']
+    else:
+        pass
+
+    return materials
+
diff --git a/tests/integration/shuffle_byuniv/results_true.dat b/tests/integration/shuffle_byuniv/results_true.dat
index 9b08ecb..dce6174 100644
--- a/tests/integration/shuffle_byuniv/results_true.dat
+++ b/tests/integration/shuffle_byuniv/results_true.dat
@@ -8,9 +8,9 @@ c      1      | 1
 c      2      | 2            
 c      3      | 3            
 c      5      | 5            
-c      6      | 6            
+c      6      | uni_6        
 c      7      | 7            
-c      8      | 8            
+c      8      | uni_8        
 c      9      | 9            
 c     10      | 10           
 1 0 -1 u=0 imp:n=1 fill=10 (3)
@@ -90,11 +90,30 @@ mode n
 F99999994:N 11 21 31 51 61 71 81 91
 E99999994 20.0
 FC99999994 Flux tally for depletion
-f4:n 11 21 31 41 51 61 71 81 91
-e4 1. 20.
+c User tallies
 fc4 testing
+f4:n 11 21 31 51 61 71 81 91
+e4 1. 20.
+tm4 1 2
+c4 -.866 -.5 0 .5 .866 1
+t4 2 4
+f6:n,p 91
+e6 1E-5 1E-3
+tm6 1 2
+c6 -.866 -.5 0 .5 .866 1
+t6 2 4
 f14:n 11
 fm14 (1. 15 (-1 103))
+e14 1E-5 1E-3
+tm14 1 2
+c14 -.866 -.5 0 .5 .866 1
+t14 2 4
+fc34 flux in supply element
+f34:n 91
+tm34 4 6
+e34 1E-5 1E-3
+c34 -.866 -.5 0 .5 .866 1
+t34 2 4
 
 message: xsdir=./xsdir
 
@@ -102,15 +121,15 @@ simple lattice case_2_op_2_step_1
 c ADDER UNIVERSE IDENTIFICATION TABLE
 c Universe ID | Universe Name
 c --------------------------
-c      1      | 1            
-c      2      | 2            
-c      3      | 3            
-c      5      | 5            
-c      6      | 6            
-c      7      | 7            
-c      8      | 8            
-c      9      | 9            
-c     10      | 10           
+c      1      | 1
+c      2      | 2
+c      3      | 3
+c      5      | 5
+c      6      | uni_6
+c      7      | 7
+c      8      | uni_8
+c      9      | 9
+c     10      | 10
 1 0 -1 u=0 imp:n=1 fill=10 (3)
 2 10 1.0000000000000E+00 -301 302 -303 304 u=10 lat=1 imp:n=1 fill=-2:2 -2:2 0:0
      10 10 10 10 10 10 9 2(1) 3 10 10 2(2) 5 6 10 10 7 8 1 10 10 10 10 10 10
@@ -188,11 +207,30 @@ mode n
 F99999994:N 11 21 31 51 61 71 81 91
 E99999994 20.0
 FC99999994 Flux tally for depletion
-f4:n 11 21 31 41 51 61 71 81 91
-e4 1. 20.
+c User tallies
 fc4 testing
+f4:n 11 21 31 51 61 71 81 91
+e4 1. 20.
+tm4 1 2
+c4 -.866 -.5 0 .5 .866 1
+t4 2 4
+f6:n,p 91
+e6 1E-5 1E-3
+tm6 1 2
+c6 -.866 -.5 0 .5 .866 1
+t6 2 4
 f14:n 11
 fm14 (1. 15 (-1 103))
+e14 1E-5 1E-3
+tm14 1 2
+c14 -.866 -.5 0 .5 .866 1
+t14 2 4
+fc34 flux in supply element
+f34:n 91
+tm34 4 6
+e34 1E-5 1E-3
+c34 -.866 -.5 0 .5 .866 1
+t34 2 4
 
 message: xsdir=./xsdir
 
@@ -200,15 +238,15 @@ simple lattice case_3_op_2_step_1
 c ADDER UNIVERSE IDENTIFICATION TABLE
 c Universe ID | Universe Name
 c --------------------------
-c      1      | 1            
-c      2      | 2            
-c      3      | 3            
-c      5      | 5            
-c      6      | 6            
-c      7      | 7            
-c      8      | 8            
-c      9      | 9            
-c     10      | 10           
+c      1      | 1
+c      2      | 2
+c      3      | 3
+c      5      | 5
+c      6      | uni_6
+c      7      | 7
+c      8      | uni_8
+c      9      | 9
+c     10      | 10
 1 0 -1 u=0 imp:n=1 fill=10 (3)
 2 10 1.0000000000000E+00 -301 302 -303 304 u=10 lat=1 imp:n=1 fill=-2:2 -2:2 0:0
      10 10 10 10 10 10 9 2(1) 7 10 10 2(2) 5 6 10 10 3 8 1 10 10 10 10 10 10
@@ -286,11 +324,30 @@ mode n
 F99999994:N 11 21 31 51 61 71 81 91
 E99999994 20.0
 FC99999994 Flux tally for depletion
-f4:n 11 21 31 41 51 61 71 81 91
-e4 1. 20.
+c User tallies
 fc4 testing
+f4:n 11 21 31 51 61 71 81 91
+e4 1. 20.
+tm4 1 2
+c4 -.866 -.5 0 .5 .866 1
+t4 2 4
+f6:n,p 91
+e6 1E-5 1E-3
+tm6 1 2
+c6 -.866 -.5 0 .5 .866 1
+t6 2 4
 f14:n 11
 fm14 (1. 15 (-1 103))
+e14 1E-5 1E-3
+tm14 1 2
+c14 -.866 -.5 0 .5 .866 1
+t14 2 4
+fc34 flux in supply element
+f34:n 91
+tm34 4 6
+e34 1E-5 1E-3
+c34 -.866 -.5 0 .5 .866 1
+t34 2 4
 
 message: xsdir=./xsdir
 
@@ -298,15 +355,15 @@ simple lattice case_4_op_2_step_1
 c ADDER UNIVERSE IDENTIFICATION TABLE
 c Universe ID | Universe Name
 c --------------------------
-c      1      | 1            
-c      2      | 2            
-c      3      | 3            
-c      6      | 6            
-c      7      | 7            
-c      8      | 8            
-c      9      | 9            
-c     10      | 10           
-c     11      | storage_uni  
+c      1      | 1
+c      2      | 2
+c      3      | 3
+c      6      | uni_6
+c      7      | 7
+c      8      | uni_8
+c      9      | 9
+c     10      | 10
+c     11      | storage_uni
 1 0 -1 u=0 imp:n=1 fill=10 (3)
 2 10 1.0000000000000E+00 -301 302 -303 304 u=10 lat=1 imp:n=1 fill=-2:2 -2:2 0:0
      10 10 10 10 10 10 9 2(1) 7 10 10 2(2) 11 6 10 10 3 8 1 10 10 10 10 10 10
@@ -385,11 +442,36 @@ mode n
 F99999994:N 11 21 31 61 71 81 91 95 96
 E99999994 20.0
 FC99999994 Flux tally for depletion
-f4:n 11 21 31 41 51 61 71 81 91
-e4 1. 20.
+c User tallies
 fc4 testing
+f4:n 11 21 31 51 61 71 81 91
+e4 1. 20.
+tm4 1 2
+c4 -.866 -.5 0 .5 .866 1
+t4 2 4
+f6:n,p 91
+e6 1E-5 1E-3
+tm6 1 2
+c6 -.866 -.5 0 .5 .866 1
+t6 2 4
 f14:n 11
 fm14 (1. 15 (-1 103))
+e14 1E-5 1E-3
+tm14 1 2
+c14 -.866 -.5 0 .5 .866 1
+t14 2 4
+fc24 flux in storage element
+f24:n 95
+e24 1E-5 1E-3
+tm24 1 2
+c24 -.866 -.5 0 .5 .866 1
+t24 2 4
+fc34 flux in supply element
+f34:n 91
+tm34 4 6
+e34 1E-5 1E-3
+c34 -.866 -.5 0 .5 .866 1
+t34 2 4
 
 message: xsdir=./xsdir
 
@@ -397,15 +479,15 @@ simple lattice case_5_op_2_step_1
 c ADDER UNIVERSE IDENTIFICATION TABLE
 c Universe ID | Universe Name
 c --------------------------
-c      1      | 1            
-c      2      | 2            
-c      3      | 3            
-c      5      | 5            
-c      6      | 6            
-c      7      | 7            
-c      9      | 9            
-c     10      | 10           
-c     11      | storage_uni  
+c      1      | 1
+c      2      | 2
+c      3      | 3
+c      5      | 5
+c      6      | uni_6
+c      7      | 7
+c      9      | 9
+c     10      | 10
+c     11      | storage_uni
 1 0 -1 u=0 imp:n=1 fill=10 (3)
 2 10 1.0000000000000E+00 -301 302 -303 304 u=10 lat=1 imp:n=1 fill=-2:2 -2:2 0:0
      10 10 10 10 10 10 9 2(1) 7 10 10 2(2) 11 6 10 10 3 5 1 10 10 10 10 10 10
@@ -484,11 +566,36 @@ mode n
 F99999994:N 11 21 31 51 61 71 91 95 96
 E99999994 20.0
 FC99999994 Flux tally for depletion
-f4:n 11 21 31 41 51 61 71 81 91
-e4 1. 20.
+c User tallies
 fc4 testing
+f4:n 11 21 31 51 61 71 81 91
+e4 1. 20.
+tm4 1 2
+c4 -.866 -.5 0 .5 .866 1
+t4 2 4
+f6:n,p 91
+e6 1E-5 1E-3
+tm6 1 2
+c6 -.866 -.5 0 .5 .866 1
+t6 2 4
 f14:n 11
 fm14 (1. 15 (-1 103))
+e14 1E-5 1E-3
+tm14 1 2
+c14 -.866 -.5 0 .5 .866 1
+t14 2 4
+fc24 flux in storage element
+f24:n 95
+e24 1E-5 1E-3
+tm24 1 2
+c24 -.866 -.5 0 .5 .866 1
+t24 2 4
+fc34 flux in supply element
+f34:n 91
+tm34 4 6
+e34 1E-5 1E-3
+c34 -.866 -.5 0 .5 .866 1
+t34 2 4
 
 message: xsdir=./xsdir
 
@@ -496,15 +603,15 @@ simple lattice case_6_op_2_step_1
 c ADDER UNIVERSE IDENTIFICATION TABLE
 c Universe ID | Universe Name
 c --------------------------
-c      1      | 1            
-c      2      | 2            
-c      3      | 3            
-c      5      | 5            
-c      6      | 6            
-c      7      | 7            
-c      9      | 9            
-c     10      | 10           
-c     11      | storage_uni  
+c      1      | 1
+c      2      | 2
+c      3      | 3
+c      5      | 5
+c      6      | uni_6
+c      7      | 7
+c      9      | 9
+c     10      | 10
+c     11      | storage_uni
 1 0 -1 u=0 imp:n=1 fill=10 (3)
 2 10 1.0000000000000E+00 -301 302 -303 304 u=10 lat=1 imp:n=1 fill=-2:2 -2:2 0:0
      10 10 10 10 10 10 9 2(1) 7 10 10 2(2) 6 1 10 10 3 11 5 10 10 10 10 10 10
@@ -583,11 +690,36 @@ mode n
 F99999994:N 11 21 31 51 61 71 91 95 96
 E99999994 20.0
 FC99999994 Flux tally for depletion
-f4:n 11 21 31 41 51 61 71 81 91
-e4 1. 20.
+c User tallies
 fc4 testing
+f4:n 11 21 31 51 61 71 81 91
+e4 1. 20.
+tm4 1 2
+c4 -.866 -.5 0 .5 .866 1
+t4 2 4
+f6:n,p 91
+e6 1E-5 1E-3
+tm6 1 2
+c6 -.866 -.5 0 .5 .866 1
+t6 2 4
 f14:n 11
 fm14 (1. 15 (-1 103))
+e14 1E-5 1E-3
+tm14 1 2
+c14 -.866 -.5 0 .5 .866 1
+t14 2 4
+fc24 flux in storage element
+f24:n 95
+e24 1E-5 1E-3
+tm24 1 2
+c24 -.866 -.5 0 .5 .866 1
+t24 2 4
+fc34 flux in supply element
+f34:n 91
+tm34 4 6
+e34 1E-5 1E-3
+c34 -.866 -.5 0 .5 .866 1
+t34 2 4
 
 message: xsdir=./xsdir
 
@@ -595,15 +727,15 @@ simple lattice case_7_op_2_step_1
 c ADDER UNIVERSE IDENTIFICATION TABLE
 c Universe ID | Universe Name
 c --------------------------
-c      2      | 2            
-c      3      | 3            
-c      5      | 5            
-c      6      | 6            
-c      7      | 7            
-c      9      | 9            
-c     10      | 10           
-c     11      | storage_uni  
-c     12      | 12           
+c      2      | 2
+c      3      | 3
+c      5      | 5
+c      6      | uni_6
+c      7      | 7
+c      9      | 9
+c     10      | 10
+c     11      | storage_uni
+c     12      | 12
 1 0 -1 u=0 imp:n=1 fill=10 (3)
 2 10 1.0000000000000E+00 -301 302 -303 304 u=10 lat=1 imp:n=1 fill=-2:2 -2:2 0:0
      10 10 10 10 10 10 9 2(1) 7 10 10 2(2) 6 12 10 10 3 11 5 10 10 10 10 10 10
@@ -683,11 +815,30 @@ mode n
 F99999994:N 21 31 51 61 71 91 95 96 97 98
 E99999994 20.0
 FC99999994 Flux tally for depletion
-f4:n 11 21 31 41 51 61 71 81 91
-e4 1. 20.
+c User tallies
 fc4 testing
-f14:n 11
-fm14 (1. 15 (-1 103))
+f4:n 11 21 31 51 61 71 81 91
+e4 1. 20.
+tm4 1 2
+c4 -.866 -.5 0 .5 .866 1
+t4 2 4
+f6:n,p 91
+e6 1E-5 1E-3
+tm6 1 2
+c6 -.866 -.5 0 .5 .866 1
+t6 2 4
+fc24 flux in storage element
+f24:n 95
+e24 1E-5 1E-3
+tm24 1 2
+c24 -.866 -.5 0 .5 .866 1
+t24 2 4
+fc34 flux in supply element
+f34:n 91
+tm34 4 6
+e34 1E-5 1E-3
+c34 -.866 -.5 0 .5 .866 1
+t34 2 4
 
 message: xsdir=./xsdir
 
@@ -695,15 +846,15 @@ simple lattice case_8_op_2_step_1
 c ADDER UNIVERSE IDENTIFICATION TABLE
 c Universe ID | Universe Name
 c --------------------------
-c      2      | 2            
-c      3      | 3            
-c      5      | 5            
-c      6      | 6            
-c      7      | 7            
-c      9      | 9            
-c     10      | 10           
-c     11      | storage_uni  
-c     14      | new_9[1]     
+c      2      | 2
+c      3      | 3
+c      5      | 5
+c      6      | uni_6
+c      7      | 7
+c      9      | 9
+c     10      | 10
+c     11      | storage_uni
+c     14      | new_9[1]
 1 0 -1 u=0 imp:n=1 fill=10 (3)
 2 10 1.0000000000000E+00 -301 302 -303 304 u=10 lat=1 imp:n=1 fill=-2:2 -2:2 0:0
      10 10 10 10 10 10 9 2(1) 7 10 10 2(2) 6 14 10 10 3 11 5 10 10 10 10 10 10
@@ -782,11 +933,41 @@ mode n
 F99999994:N 21 31 51 61 71 91 95 96 101
 E99999994 20.0
 FC99999994 Flux tally for depletion
-f4:n 11 21 31 41 51 61 71 81 91
-e4 1. 20.
+c User tallies
 fc4 testing
-f14:n 11
-fm14 (1. 15 (-1 103))
+f4:n 11 21 31 51 61 71 81 91
+e4 1. 20.
+tm4 1 2
+c4 -.866 -.5 0 .5 .866 1
+t4 2 4
+f16:n,p 101
+e16 1E-5 1E-3
+tm16 1 2
+c16 -.866 -.5 0 .5 .866 1
+t16 2 4
+f6:n,p 91
+e6 1E-5 1E-3
+tm6 1 2
+c6 -.866 -.5 0 .5 .866 1
+t6 2 4
+fc24 flux in storage element
+f24:n 95
+e24 1E-5 1E-3
+tm24 1 2
+c24 -.866 -.5 0 .5 .866 1
+t24 2 4
+fc44 flux in supply element
+f44:n 101
+tm44 4 6
+e44 1E-5 1E-3
+c44 -.866 -.5 0 .5 .866 1
+t44 2 4
+fc34 flux in supply element
+f34:n 91
+tm34 4 6
+e34 1E-5 1E-3
+c34 -.866 -.5 0 .5 .866 1
+t34 2 4
 
 message: xsdir=./xsdir
 
@@ -794,15 +975,15 @@ simple lattice case_9_op_2_step_1
 c ADDER UNIVERSE IDENTIFICATION TABLE
 c Universe ID | Universe Name
 c --------------------------
-c      2      | 2            
-c      3      | 3            
-c      5      | 5            
-c      6      | 6            
-c      7      | 7            
-c      9      | 9            
-c     10      | 10           
-c     11      | storage_uni  
-c     14      | new_9[1]     
+c      2      | 2
+c      3      | 3
+c      5      | 5
+c      6      | uni_6
+c      7      | 7
+c      9      | 9
+c     10      | 10
+c     11      | storage_uni
+c     14      | new_9[1]
 1 0 -1 u=0 imp:n=1 fill=10 (3)
 2 10 1.0000000000000E+00 -301 302 -303 304 u=10 lat=1 imp:n=1 fill=-2:2 -2:2 0:0
      10 10 10 10 10 10 9 2(1) 7 10 10 2(2) 6 3 10 10 14 11 5 10 10 10 10 10 10
@@ -880,11 +1061,41 @@ mode n
 F99999994:N 21 31 51 61 71 91 95 96 101
 E99999994 20.0
 FC99999994 Flux tally for depletion
-f4:n 11 21 31 41 51 61 71 81 91
-e4 1. 20.
+c User tallies
 fc4 testing
-f14:n 11
-fm14 (1. 15 (-1 103))
+f4:n 11 21 31 51 61 71 81 91
+e4 1. 20.
+tm4 1 2
+c4 -.866 -.5 0 .5 .866 1
+t4 2 4
+f6:n,p 91
+e6 1E-5 1E-3
+tm6 1 2
+c6 -.866 -.5 0 .5 .866 1
+t6 2 4
+fc24 flux in storage element
+f24:n 95
+e24 1E-5 1E-3
+tm24 1 2
+c24 -.866 -.5 0 .5 .866 1
+t24 2 4
+fc34 flux in supply element
+f34:n 91
+tm34 4 6
+e34 1E-5 1E-3
+c34 -.866 -.5 0 .5 .866 1
+t34 2 4
+f16:n,p 101
+e16 1E-5 1E-3
+tm16 1 2
+c16 -.866 -.5 0 .5 .866 1
+t16 2 4
+fc44 flux in supply element
+f44:n 101
+tm44 4 6
+e44 1E-5 1E-3
+c44 -.866 -.5 0 .5 .866 1
+t44 2 4
 
 message: xsdir=./xsdir
 
@@ -892,15 +1103,15 @@ simple lattice case_10_op_2_step_1
 c ADDER UNIVERSE IDENTIFICATION TABLE
 c Universe ID | Universe Name
 c --------------------------
-c      2      | 2            
-c      3      | 3            
-c      5      | 5            
-c      6      | 6            
-c      7      | 7            
-c      9      | 9            
-c     10      | 10           
-c     11      | storage_uni  
-c     14      | new_9[1]     
+c      2      | 2
+c      3      | 3
+c      5      | 5
+c      6      | uni_6
+c      7      | 7
+c      9      | 9
+c     10      | 10
+c     11      | storage_uni
+c     14      | new_9[1]
 1 0 -1 u=0 imp:n=1 fill=10 (1)
 2 10 1.0000000000000E+00 -301 302 -303 304 u=10 lat=1 imp:n=1 fill=-2:2 -2:2 0:0
      10 10 10 10 10 10 9 2(5) 7(4) 10 10 2(6) 6 3 10 10 14 11 5 10 10 10 10 10
@@ -965,10 +1176,12 @@ c ADDER Material Name: 9[1][1]
 m27 92235.70c 2.500000E-02 92238.70c 4.750000E-01 8016.70c 5.000000E-01
 c ADDER Material Name: non_depleting_reg_90[1][1]
 m28 1001.70c 6.666667E-01 8016.72c 3.333333E-01
+c Multiplier Material Name: 15
+m15 92235.70c 1.000000E+00
 tr1 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 -1.0 0.0 1
-tr4 0.0 0.0 0.0 0.0 -1.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1
-tr5 0.0 0.0 0.0 0.0 0.0 -1.0 1.0 0.0 0.0 0.0 -1.0 0.0 1
-tr6 0.0 0.0 0.0 0.0 -1.0 0.0 0.0 0.0 -1.0 1.0 0.0 0.0 1
+tr4 0.0 0.0 0.0 0.0 1.0 0.0 -1.0 0.0 0.0 0.0 0.0 1.0 1
+tr5 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 1
+tr6 0.0 0.0 0.0 0.0 0.0 -1.0 -1.0 0.0 0.0 0.0 1.0 0.0 1
 PRINT 60 128 130
 PRDMP 0 0 1
 DBCN 1
@@ -986,10 +1199,138 @@ simple lattice case_10_op_3_step_1
 c ADDER UNIVERSE IDENTIFICATION TABLE
 c Universe ID | Universe Name
 c --------------------------
+c      2      | 2
+c      3      | 3
+c      5      | 5
+c      6      | uni_6
+c      7      | 7
+c      9      | 9
+c     10      | 10
+c     11      | storage_uni
+c     14      | new_9[1]
+1 0 -1 u=0 imp:n=1 fill=10 (1)
+2 10 1.0000000000000E+00 -301 302 -303 304 u=10 lat=1 imp:n=1 fill=-2:2 -2:2 0:0
+     10 10 10 10 10 10 9 2(5) 7(4) 10 10 2(6) 6 3 10 10 14 11 5 10 10 10 10 10
+     10
+5 0 1 u=0 imp:n=0
+20 17 1.0000000000000E+00 +10 vol=1.059498275 u=2 imp:n=1
+21 2 2.0000000000000E+00 -10 vol=0.528101 u=2 imp:n=1
+30 18 1.0000000000000E+00 +10 vol=1.059498275 u=3 imp:n=1
+31 3 2.0000000000000E+00 -10 vol=0.528101 u=3 imp:n=1
+50 20 1.0000000000000E+00 +10 vol=1.059498275 u=5 imp:n=1
+51 5 2.0000000000000E+00 -10 vol=0.528101 u=5 imp:n=1
+60 21 1.0000000000000E+00 +10 vol=1.059498275 u=6 imp:n=1
+61 6 2.0000000000000E+00 -10 vol=0.528101 u=6 imp:n=1
+70 22 1.0000000000000E+00 +10 vol=1.059498275 u=7 imp:n=1
+71 7 2.0000000000000E+00 -10 vol=0.528101 u=7 imp:n=1
+90 24 1.0000000000000E+00 +10 vol=1.059498275 u=9 imp:n=1
+91 9 2.0000000000000E+00 -10 vol=0.528101 u=9 imp:n=1
+95 11 2.0000000000000E+00 -10 vol=0.528101 u=11 imp:n=1
+96 12 1.0000000000000E+00 +10 vol=1.059498275 u=11 imp:n=1
+101 27 2.0000000000000E+00 -10 vol=0.528101 u=14 imp:n=1
+102 28 1.0000000000000E+00 +10 vol=1.059498275 u=14 imp:n=1
+
+1 cz 3.15
+10 cz 0.41
+301 px .63
+302 px -.63
+303 py .63
+304 py -.63
+
+c ADDER Material Name: 2
+m2 92235.70c 2.500000E-02 92238.70c 4.750000E-01 8016.70c 5.000000E-01
+c ADDER Material Name: 3
+m3 92235.70c 2.500000E-02 92238.70c 4.750000E-01 8016.70c 5.000000E-01
+c ADDER Material Name: 5
+m5 92235.70c 2.500000E-02 92238.70c 4.750000E-01 8016.70c 5.000000E-01
+c ADDER Material Name: 6
+m6 92235.70c 2.500000E-02 92238.70c 4.750000E-01 8016.70c 5.000000E-01
+c ADDER Material Name: 7
+m7 92235.70c 2.500000E-02 92238.70c 4.750000E-01 8016.70c 5.000000E-01
+c ADDER Material Name: 9
+m9 92235.70c 2.500000E-02 92238.70c 4.750000E-01 8016.70c 5.000000E-01
+c ADDER Material Name: non_depleting
+m10 1001.70c 6.666667E-01 8016.72c 3.333333E-01
+c ADDER Material Name: 11
+m11 92235.70c 2.500000E-02 92238.70c 4.750000E-01 8016.70c 5.000000E-01
+c ADDER Material Name: 12
+m12 1001.70c 6.666667E-01 8016.72c 3.333333E-01
+mt12 lwtr.10t
+c ADDER Material Name: non_depleting_reg_20
+m17 1001.70c 6.666667E-01 8016.72c 3.333333E-01
+c ADDER Material Name: non_depleting_reg_30
+m18 1001.70c 6.666667E-01 8016.72c 3.333333E-01
+c ADDER Material Name: non_depleting_reg_50
+m20 1001.70c 6.666667E-01 8016.72c 3.333333E-01
+c ADDER Material Name: non_depleting_reg_60
+m21 1001.70c 6.666667E-01 8016.72c 3.333333E-01
+c ADDER Material Name: non_depleting_reg_70
+m22 1001.70c 6.666667E-01 8016.72c 3.333333E-01
+c ADDER Material Name: non_depleting_reg_90
+m24 1001.70c 6.666667E-01 8016.72c 3.333333E-01
+c ADDER Material Name: 9[1][1]
+m27 92235.70c 2.500000E-02 92238.70c 4.750000E-01 8016.70c 5.000000E-01
+c ADDER Material Name: non_depleting_reg_90[1][1]
+m28 1001.70c 6.666667E-01 8016.72c 3.333333E-01
+c Multiplier Material Name: 15
+m15 92235.70c 1.000000E+00
+tr1 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 -1.0 0.0 1
+tr4 0.0 0.0 0.0 0.0 1.0 0.0 -1.0 0.0 0.0 0.0 0.0 1.0 1
+tr5 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 1
+tr6 0.0 0.0 0.0 0.0 0.0 -1.0 -1.0 0.0 0.0 0.0 1.0 0.0 1
+PRINT 60 128 130
+PRDMP 0 0 1
+DBCN 1
+kcode 100 1.00000 10 100 4500 0 6500 1
+ksrc -.63 -.63 0. -.63 0. 0. -.63 .63 0. 0. -.63 0. 0. 0. 0. 0. .63 0. .63 -.63
+     0. .63 0. 0. .63 .63 0.
+mode n
+c User tallies
+fc4 testing
+f4:n 11 21 31 51 61 71 81 91
+e4 1. 20.
+tm4 1 2
+c4 -.866 -.5 0 .5 .866 1
+t4 2 4
+f6:n,p 91
+e6 1E-5 1E-3
+tm6 1 2
+c6 -.866 -.5 0 .5 .866 1
+t6 2 4
+fc24 flux in storage element
+f24:n 95
+e24 1E-5 1E-3
+tm24 1 2
+c24 -.866 -.5 0 .5 .866 1
+t24 2 4
+fc34 flux in supply element
+f34:n 91
+tm34 4 6
+e34 1E-5 1E-3
+c34 -.866 -.5 0 .5 .866 1
+t34 2 4
+f16:n,p 101
+e16 1E-5 1E-3
+tm16 1 2
+c16 -.866 -.5 0 .5 .866 1
+t16 2 4
+fc44 flux in supply element
+f44:n 101
+tm44 4 6
+e44 1E-5 1E-3
+c44 -.866 -.5 0 .5 .866 1
+t44 2 4
+
+message: xsdir=./xsdir
+
+simple lattice case_10_op_5_step_1
+c ADDER UNIVERSE IDENTIFICATION TABLE
+c Universe ID | Universe Name
+c --------------------------
 c      2      | 2            
 c      3      | 3            
 c      5      | 5            
-c      6      | 6            
+c      6      | uni_6        
 c      7      | 7            
 c      9      | 9            
 c     10      | 10           
@@ -997,7 +1338,7 @@ c     11      | storage_uni
 c     14      | new_9[1]     
 1 0 -1 u=0 imp:n=1 fill=10 (1)
 2 10 1.0000000000000E+00 -301 302 -303 304 u=10 lat=1 imp:n=1 fill=-2:2 -2:2 0:0
-     10 10 10 10 10 10 9 2(5) 7(4) 10 10 2(6) 6 3 10 10 14 11 5 10 10 10 10 10
+     10 10 10 10 10 10 9 2(5) 7(8) 10 10 2(6) 6 3 10 10 14 11 5 10 10 10 10 10
      10
 5 0 1 u=0 imp:n=0
 20 17 1.0000000000000E+00 +10 vol=1.059498275 u=2 imp:n=1
@@ -1062,9 +1403,9 @@ m28 1001.70c 6.666667E-01 8016.72c 3.333333E-01
 c Multiplier Material Name: 15
 m15 92235.70c 1.000000E+00
 tr1 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 -1.0 0.0 1
-tr4 0.0 0.0 0.0 0.0 -1.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1
-tr5 0.0 0.0 0.0 0.0 0.0 -1.0 1.0 0.0 0.0 0.0 -1.0 0.0 1
-tr6 0.0 0.0 0.0 0.0 -1.0 0.0 0.0 0.0 -1.0 1.0 0.0 0.0 1
+tr5 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 1
+tr6 0.0 0.0 0.0 0.0 0.0 -1.0 -1.0 0.0 0.0 0.0 1.0 0.0 1
+tr8 0.0 0.0 0.0 -1.0 0.0 0.0 0.0 -1.0 0.0 0.0 0.0 1.0 1
 PRINT 60 128 130
 PRDMP 0 0 1
 DBCN 1
@@ -1072,22 +1413,17 @@ kcode 100 1.00000 10 100 4500 0 6500 1
 ksrc -.63 -.63 0. -.63 0. 0. -.63 .63 0. 0. -.63 0. 0. 0. 0. 0. .63 0. .63 -.63
      0. .63 0. 0. .63 .63 0.
 mode n
-f4:n 11 21 31 41 51 61 71 81 91
-e4 1. 20.
-fc4 testing
-f14:n 11
-fm14 (1. 15 (-1 103))
 
 message: xsdir=./xsdir
 
-simple lattice case_10_op_5_step_1
+simple lattice case_11_op_2_step_1
 c ADDER UNIVERSE IDENTIFICATION TABLE
 c Universe ID | Universe Name
 c --------------------------
 c      2      | 2            
 c      3      | 3            
 c      5      | 5            
-c      6      | 6            
+c      6      | uni_6        
 c      7      | 7            
 c      9      | 9            
 c     10      | 10           
@@ -1095,7 +1431,8 @@ c     11      | storage_uni
 c     14      | new_9[1]     
 1 0 -1 u=0 imp:n=1 fill=10 (1)
 2 10 1.0000000000000E+00 -301 302 -303 304 u=10 lat=1 imp:n=1 fill=-2:2 -2:2 0:0
-     10 10 10 10 10 10 9 2(5) 7 10 10 2(6) 6 3 10 10 14 11 5 10 10 10 10 10 10
+     10 10 10 10 10 10 9 2(5) 7(8) 10 10 2(6) 6 3 10 10 14 11 5 10 10 10 10 10
+     10
 5 0 1 u=0 imp:n=0
 20 17 1.0000000000000E+00 +10 vol=1.059498275 u=2 imp:n=1
 21 2 2.0000000000000E+00 -10 vol=0.528101 u=2 imp:n=1
@@ -1114,7 +1451,7 @@ c     14      | new_9[1]
 101 27 2.0000000000000E+00 -10 vol=0.528101 u=14 imp:n=1
 102 28 1.0000000000000E+00 +10 vol=1.059498275 u=14 imp:n=1
 
-1 cz 3.15
+1 9 cz 3.15
 10 cz 0.41
 301 px .63
 302 px -.63
@@ -1156,9 +1493,13 @@ c ADDER Material Name: 9[1][1]
 m27 92235.70c 2.500000E-02 92238.70c 4.750000E-01 8016.70c 5.000000E-01
 c ADDER Material Name: non_depleting_reg_90[1][1]
 m28 1001.70c 6.666667E-01 8016.72c 3.333333E-01
+c Multiplier Material Name: 15
+m15 92235.70c 1.000000E+00
 tr1 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 -1.0 0.0 1
-tr5 0.0 0.0 0.0 0.0 0.0 -1.0 1.0 0.0 0.0 0.0 -1.0 0.0 1
-tr6 0.0 0.0 0.0 0.0 -1.0 0.0 0.0 0.0 -1.0 1.0 0.0 0.0 1
+tr5 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 1
+tr6 0.0 0.0 0.0 0.0 0.0 -1.0 -1.0 0.0 0.0 0.0 1.0 0.0 1
+tr8 0.0 0.0 0.0 -1.0 0.0 0.0 0.0 -1.0 0.0 0.0 0.0 1.0 1
+tr9 0.0 0.0 10.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 1
 PRINT 60 128 130
 PRDMP 0 0 1
 DBCN 1
@@ -1166,17 +1507,20 @@ kcode 100 1.00000 10 100 4500 0 6500 1
 ksrc -.63 -.63 0. -.63 0. 0. -.63 .63 0. 0. -.63 0. 0. 0. 0. 0. .63 0. .63 -.63
      0. .63 0. 0. .63 .63 0.
 mode n
+F99999994:N 21 31 51 61 71 91 95 96 101
+E99999994 20.0
+FC99999994 Flux tally for depletion
 
 message: xsdir=./xsdir
 
-simple lattice case_11_op_2_step_1
+simple lattice case_12_op_4_step_1
 c ADDER UNIVERSE IDENTIFICATION TABLE
 c Universe ID | Universe Name
 c --------------------------
 c      2      | 2            
 c      3      | 3            
 c      5      | 5            
-c      6      | 6            
+c      6      | uni_6        
 c      7      | 7            
 c      9      | 9            
 c     10      | 10           
@@ -1184,7 +1528,8 @@ c     11      | storage_uni
 c     14      | new_9[1]     
 1 0 -1 u=0 imp:n=1 fill=10 (1)
 2 10 1.0000000000000E+00 -301 302 -303 304 u=10 lat=1 imp:n=1 fill=-2:2 -2:2 0:0
-     10 10 10 10 10 10 9 2(5) 7 10 10 2(6) 6 3 10 10 14 11 5 10 10 10 10 10 10
+     10 10 10 10 10 10 9 2(5) 7(14) 10 10 2(6) 6(10) 3 10 10 14 11 5 10 10 10 10
+     10 10
 5 0 1 u=0 imp:n=0
 20 17 1.0000000000000E+00 +10 vol=1.059498275 u=2 imp:n=1
 21 2 2.0000000000000E+00 -10 vol=0.528101 u=2 imp:n=1
@@ -1203,7 +1548,7 @@ c     14      | new_9[1]
 101 27 2.0000000000000E+00 -10 vol=0.528101 u=14 imp:n=1
 102 28 1.0000000000000E+00 +10 vol=1.059498275 u=14 imp:n=1
 
-1 7 cz 3.15
+1 9 cz 3.15
 10 cz 0.41
 301 px .63
 302 px -.63
@@ -1245,10 +1590,18 @@ c ADDER Material Name: 9[1][1]
 m27 92235.70c 2.500000E-02 92238.70c 4.750000E-01 8016.70c 5.000000E-01
 c ADDER Material Name: non_depleting_reg_90[1][1]
 m28 1001.70c 6.666667E-01 8016.72c 3.333333E-01
+c Multiplier Material Name: 15
+m15 92235.70c 1.000000E+00
 tr1 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 -1.0 0.0 1
-tr5 0.0 0.0 0.0 0.0 0.0 -1.0 1.0 0.0 0.0 0.0 -1.0 0.0 1
-tr6 0.0 0.0 0.0 0.0 -1.0 0.0 0.0 0.0 -1.0 1.0 0.0 0.0 1
-tr7 0.0 0.0 10.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 1
+tr5 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 1
+tr6 0.0 0.0 0.0 0.0 0.0 -1.0 -1.0 0.0 0.0 0.0 1.0 0.0 1
+tr9 0.0 0.0 10.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 1
+tr10 0.0 0.0 0.0 0.12493411877638022 0.09414461119996485 -0.9876883405951378
+     -0.6018150231520483 0.7986355100472928 0.0 0.7888029816589621
+     0.594405681562271 0.15643446504023092 1
+tr14 0.0 0.0 0.0 -0.981627183447664 -0.17001205975432954 0.08662547116579845 0.0
+     -0.4539904997395468 -0.8910065241883678 0.1908089953765448
+     -0.8746362247725203 0.44564941557132876 1
 PRINT 60 128 130
 PRDMP 0 0 1
 DBCN 1
@@ -1260,3 +1613,105 @@ F99999994:N 21 31 51 61 71 91 95 96 101
 E99999994 20.0
 FC99999994 Flux tally for depletion
 
+message: xsdir=./xsdir
+
+simple lattice case_12_op_6_step_1
+c ADDER UNIVERSE IDENTIFICATION TABLE
+c Universe ID | Universe Name
+c --------------------------
+c      2      | 2            
+c      5      | 5            
+c      6      | uni_6        
+c      7      | 7            
+c      9      | 9            
+c     10      | 10           
+c     11      | storage_uni  
+c     14      | new_9[1]     
+c     15      | new_9[2]     
+1 0 -1 u=0 imp:n=1 fill=10 (1)
+2 10 1.0000000000000E+00 -301 302 -303 304 u=10 lat=1 imp:n=1 fill=-2:2 -2:2 0:0
+     10 10 10 10 10 10 9 2(5) 15 10 10 2(6) 7(15) 6(16) 10 10 14 11 5 10 10 10
+     10 10 10
+5 0 1 u=0 imp:n=0
+20 17 1.0000000000000E+00 +10 vol=1.059498275 u=2 imp:n=1
+21 2 2.0000000000000E+00 -10 vol=0.528101 u=2 imp:n=1
+50 20 1.0000000000000E+00 +10 vol=1.059498275 u=5 imp:n=1
+51 5 2.0000000000000E+00 -10 vol=0.528101 u=5 imp:n=1
+60 21 1.0000000000000E+00 +10 vol=1.059498275 u=6 imp:n=1
+61 6 2.0000000000000E+00 -10 vol=0.528101 u=6 imp:n=1
+70 22 1.0000000000000E+00 +10 vol=1.059498275 u=7 imp:n=1
+71 7 2.0000000000000E+00 -10 vol=0.528101 u=7 imp:n=1
+90 24 1.0000000000000E+00 +10 vol=1.059498275 u=9 imp:n=1
+91 9 2.0000000000000E+00 -10 vol=0.528101 u=9 imp:n=1
+95 11 2.0000000000000E+00 -10 vol=0.528101 u=11 imp:n=1
+96 12 1.0000000000000E+00 +10 vol=1.059498275 u=11 imp:n=1
+101 27 2.0000000000000E+00 -10 vol=0.528101 u=14 imp:n=1
+102 28 1.0000000000000E+00 +10 vol=1.059498275 u=14 imp:n=1
+103 29 2.0000000000000E+00 -10 vol=0.528101 u=15 imp:n=1
+104 30 1.0000000000000E+00 +10 vol=1.059498275 u=15 imp:n=1
+
+1 9 cz 3.15
+10 cz 0.41
+301 px .63
+302 px -.63
+303 py .63
+304 py -.63
+
+c ADDER Material Name: 2
+m2 92235.70c 2.500000E-02 92238.70c 4.750000E-01 8016.70c 5.000000E-01
+c ADDER Material Name: 5
+m5 92235.70c 2.500000E-02 92238.70c 4.750000E-01 8016.70c 5.000000E-01
+c ADDER Material Name: 6
+m6 92235.70c 2.500000E-02 92238.70c 4.750000E-01 8016.70c 5.000000E-01
+c ADDER Material Name: 7
+m7 92235.70c 2.500000E-02 92238.70c 4.750000E-01 8016.70c 5.000000E-01
+c ADDER Material Name: 9
+m9 92235.70c 2.500000E-02 92238.70c 4.750000E-01 8016.70c 5.000000E-01
+c ADDER Material Name: non_depleting
+m10 1001.70c 6.666667E-01 8016.72c 3.333333E-01
+c ADDER Material Name: 11
+m11 92235.70c 2.500000E-02 92238.70c 4.750000E-01 8016.70c 5.000000E-01
+c ADDER Material Name: 12
+m12 1001.70c 6.666667E-01 8016.72c 3.333333E-01
+mt12 lwtr.10t
+c ADDER Material Name: non_depleting_reg_20
+m17 1001.70c 6.666667E-01 8016.72c 3.333333E-01
+c ADDER Material Name: non_depleting_reg_50
+m20 1001.70c 6.666667E-01 8016.72c 3.333333E-01
+c ADDER Material Name: non_depleting_reg_60
+m21 1001.70c 6.666667E-01 8016.72c 3.333333E-01
+c ADDER Material Name: non_depleting_reg_70
+m22 1001.70c 6.666667E-01 8016.72c 3.333333E-01
+c ADDER Material Name: non_depleting_reg_90
+m24 1001.70c 6.666667E-01 8016.72c 3.333333E-01
+c ADDER Material Name: 9[1][1]
+m27 92235.70c 2.500000E-02 92238.70c 4.750000E-01 8016.70c 5.000000E-01
+c ADDER Material Name: non_depleting_reg_90[1][1]
+m28 1001.70c 6.666667E-01 8016.72c 3.333333E-01
+c ADDER Material Name: 9[1][2]
+m29 92235.70c 2.500000E-02 92238.70c 4.750000E-01 8016.70c 5.000000E-01
+c ADDER Material Name: non_depleting_reg_90[1][2]
+m30 1001.70c 6.666667E-01 8016.72c 3.333333E-01
+c Multiplier Material Name: 15
+m15 92235.70c 1.000000E+00
+tr1 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 -1.0 0.0 1
+tr5 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 1
+tr6 0.0 0.0 0.0 0.0 0.0 -1.0 -1.0 0.0 0.0 0.0 1.0 0.0 1
+tr9 0.0 0.0 10.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 1
+tr15 0.0 0.0 0.0 -0.981627183447664 -0.17001205975432954 0.08662547116579845 0.0
+     -0.4539904997395468 -0.8910065241883678 0.1908089953765448
+     -0.8746362247725203 0.44564941557132876 1
+tr16 0.0 0.0 0.0 0.12493411877638022 0.09414461119996485 -0.9876883405951378
+     -0.6018150231520483 0.7986355100472928 0.0 0.7888029816589621
+     0.594405681562271 0.15643446504023092 1
+PRINT 60 128 130
+PRDMP 0 0 1
+DBCN 1
+kcode 100 1.00000 10 100 4500 0 6500 1
+ksrc -.63 -.63 0. -.63 0. 0. -.63 .63 0. 0. -.63 0. 0. 0. 0. 0. .63 0. .63 -.63
+     0. .63 0. 0. .63 .63 0.
+mode n
+F99999994:N 21 51 61 71 91 95 96 101 103
+E99999994 20.0
+FC99999994 Flux tally for depletion
+
diff --git a/tests/integration/shuffle_byuniv/test.add b/tests/integration/shuffle_byuniv/test.add
index 87a61f8..9ccf7b5 100644
--- a/tests/integration/shuffle_byuniv/test.add
+++ b/tests/integration/shuffle_byuniv/test.add
@@ -37,12 +37,18 @@ output_hdf5 = results.h5
         [[[item]]]
             neutronics_id = 11
             name = storage_uni
+        [[[list]]]
+            neutronics_ids = 6, 8
+            names = uni
 
     [[aliases]]
         # Showcase universe aliases by setting u1 as an alias for universe 1
         [[[alias 1]]]
             name = u1
             set = 1
+        [[[alias 2]]]
+            name = many_universes
+            set = uni_8, uni_6
 
     [[storage]]
         # Set universe 12 as storage
@@ -59,6 +65,15 @@ output_hdf5 = results.h5
                 # It will have the name new_9
                 name = new_9
 
+[tallies]
+    [[range]]
+        tally_id_start = 1
+        tally_id_end = 100
+        type = universe
+    [[item]]
+        tally_id = 4
+        type = unprocessed
+
 [operations]
     [[state 1]]
         label = "Cycle 1"
@@ -91,14 +106,14 @@ output_hdf5 = results.h5
         label = "Cycle 5"
         [[[shuffle_2]]]
             type = "universe"
-            moves = 5, 8
+            moves = 5, uni_8
         [[[write_input]]]
             filename = "state5.inp"
     [[state 6]]
         label = "Cycle 6"
         [[[revolve_1]]]
             type = "universe"
-            set = storage_uni, 6, 5, 1
+            set = storage_uni, uni_6, 5, 1
             shape = 1, 2, 2
             xy_degrees = 90
             z_flip = False
@@ -156,3 +171,30 @@ output_hdf5 = results.h5
         [[[write_input]]]
             filename = "state13.inp"
             include_user_tallies = False
+    [[state 12]]
+        label = "Cycle 12"
+        [[[transform_1]]]
+            set = uni_6
+            type = universe
+            pitch = 81
+            yaw = 37
+            angle_units = degrees
+        [[[transform_2]]]
+            set = 7
+            type = universe
+            pitch = 11
+            angle_units = degrees
+        [[[transform_3]]]
+            set = 7
+            type = universe
+            roll = 63
+            angle_units = degrees
+        [[[write_input]]]
+            filename = "state14.inp"
+            include_user_tallies = False
+        [[[shuffle_1]]]
+            type = "universe"
+            moves = new_9, 7, uni_6, 3 
+        [[[write_input_2]]]
+            filename = "state15.inp"
+            include_user_tallies = False
diff --git a/tests/integration/shuffle_byuniv/test_shuffle_byuniv.py b/tests/integration/shuffle_byuniv/test_shuffle_byuniv.py
index 7d70ae0..d50c098 100644
--- a/tests/integration/shuffle_byuniv/test_shuffle_byuniv.py
+++ b/tests/integration/shuffle_byuniv/test_shuffle_byuniv.py
@@ -1,18 +1,165 @@
 import pytest
+import h5py
+import numpy as np
+from adder.constants import IN_CORE, STORAGE, SUPPLY
 from tests import mcnp_lattice
 from tests.testing_harness import TestHarness
 
 
 class ShuffleHarness(TestHarness):
+
+    def execute_test(self):
+        """Run ADDER with the appropriate arguments and check the outputs."""
+        try:
+            self._create_test_lib()
+            self._run_adder()
+            results = self._get_results()
+            self._write_results(results)
+            self._compare_mcnp_files()
+            _check_universes_status("results.h5")
+        finally:
+            self._cleanup()
+
     def _build_inputs(self):
         with open("test.inp", mode="w") as mcnp_input_file:
             mcnp_input_file.write(mcnp_lattice)
 
 
 def test_mcnp_shuffle_byuniv():
-    # This tests MCNPs ability to shuffle fuel using universes
+    # This tests MCNPs ability to shuffle fuel using universes.
+    # Additional tests are added to check the rotation via the
+    # the transform subsection using the yaw, pitch, roll and 
+    # matrix attributes w/ the mcnp (default) and common notation.	
 
-    output_text_files = ["state{}.inp".format(i + 1) for i in range(13)]
+    output_text_files = ["state{}.inp".format(i + 1) for i in range(15)]
     test = ShuffleHarness(output_text_files, "test.h5")
     test._build_inputs()
     test.main()
+
+
+def _check_universes_status(h5_filename):
+    """
+    This function checks the status of selected materials from the HDF5 file
+    against reference values provided via the _base_materials (initial) 
+    dictionary and _update_materials_status function. Note that materials are
+    checked instead of universes as universes information is not retained in 
+    the HDF5 file. All the operations in this integration test however 
+    (tests/integration/shuffle_byuniv) are performed by universes, so this 
+    tests that shuffled universes have their status set correctly, which should
+    be reflected in their materials.
+    """
+    with h5py.File(h5_filename, "r") as h5:
+        i_step = 0
+        i_checks = 0
+        i_tot_references = 0
+        reference = {}
+        case_ids = np.sort([int(x.split('_')[-1]) for x in h5.keys()])
+        for case_name in [f'case_{x}' for x in case_ids]:
+            case = h5[case_name]
+            op_ids = np.sort([int(x.split('_')[-1]) for x in case.keys()])
+            for operation_name in [f'operation_{x}' for x in op_ids]:
+                operation = case[operation_name]
+                step_ids = np.sort([int(x.split('_')[-1]) 
+                                    for x in operation.keys()])
+                for step_name in [f'step_{x}' for x in step_ids]:
+                    step = operation[step_name]
+                    materials = step['materials']
+                    i_step += 1
+                    reference = _update_materials_status(reference, i_step)
+                    i_tot_references += len(reference)
+                    if reference:
+                        for material_name in materials:
+                            data = materials[material_name]
+                            material = data[()]
+                            status = material['status']
+                            material_id = material['id'][0]
+                            try:
+                                ref_status = reference[str(material_id)]
+                            except KeyError as e:
+                                # This material is not one of our checks
+                                continue
+
+                            # Check status
+                            i_checks += 1
+                            assert int(status) == int(ref_status)
+
+                    # Check that all the available references were checked
+                    assert i_checks == i_tot_references
+
+
+_base_materials = {
+    # Fuel materials
+    '1': IN_CORE,
+    '2': IN_CORE,
+    '3': IN_CORE,
+    '4': SUPPLY,
+    '5': IN_CORE,
+    '6': IN_CORE,
+    '7': IN_CORE,
+    '8': IN_CORE,
+    '9': IN_CORE,
+    '11': STORAGE,
+    '12': STORAGE,  # 11 and 12 are part of the same material u=11
+    '13': STORAGE,  
+    '14': STORAGE,  # 13 and 14 are part of the same material u=12
+    # Non-depleting materials, copied from 10.
+    # Only the base material (m10) and the copy for universe 1 are tested here
+    # Copies for supply universes are also tested when relevant (see below)
+    '10': IN_CORE,  # First instance 
+    '16': IN_CORE,  # Copied for universe 1
+}
+
+def _update_materials_status(previous, write_id):
+    """ 
+    This function reflects 1-to-1 the shuffle and revolve operations in 
+    the test.add file 
+    """
+    materials = previous.copy()
+    if write_id == 1:
+        materials = _base_materials.copy()
+    elif write_id == 2:
+        materials['1'] = previous['9']
+        materials['16'] = previous['9']
+        materials['9'] = previous['1']
+    elif write_id == 3:
+        materials['3'] = previous['7']
+        materials['7'] = previous['3']
+    elif write_id == 4:
+        materials['11'] = previous['5']
+        materials['12'] = previous['5']
+        materials['5']  = previous['11']
+    elif write_id == 5:
+        materials['5'] = previous['8']
+        materials['8'] = previous['5']
+    elif write_id == 6:
+        materials['11'] = previous['5']
+        materials['12'] = previous['5']
+        materials['5']  = previous['1']
+        materials['1']  = previous['6']
+        materials['16'] = previous['6']
+        materials['6']  = previous['11']
+    elif write_id == 7:
+        materials['13'] = previous['1']
+        materials['14'] = previous['1']
+        materials['1']  = previous['13']
+        materials['16'] = previous['13']
+    elif write_id == 8:
+        materials['27'] = IN_CORE
+        materials['28'] = IN_CORE   # Non-depleting material, copy of m10
+        materials['13'] = STORAGE
+        materials['14'] = STORAGE
+    elif write_id == 9:
+        materials['27'] = previous['3']
+        materials['28'] = previous['3']
+        materials['3']  = previous['27']
+    elif write_id == 15:
+        materials['29'] = IN_CORE 
+        materials['30'] = IN_CORE   # Non-depleting material, copy of m10 
+        materials['7']  = previous['6']
+        materials['6']  = previous['3']
+        materials['3']  = STORAGE
+    else:
+        pass
+
+    return materials
+
diff --git a/tests/testing_harness.py b/tests/testing_harness.py
index 07378f0..1fe4d24 100644
--- a/tests/testing_harness.py
+++ b/tests/testing_harness.py
@@ -82,12 +82,15 @@ class TestHarness(object):
 
         log_warnings = []
         log_errors = []
+        log_infos = []
         with open("adder.log", "r") as fin:
             for line in fin.readlines():
                 if "- WARNING -" in line:
                     log_warnings.append(line)
                 elif "- ERROR -" in line:
                     log_errors.append(line)
+                elif "- INFO -" in line:
+                    log_infos.append(line)
 
         # For each message a list is created that contains all the errors or
         # warnings from the ADDER log that contain the message. It is then
@@ -100,6 +103,9 @@ class TestHarness(object):
             elif message[0] == 'error':
                 assert len([s for s in log_errors if message[1] in s]) == \
                        message[2]
+            elif message[0] == 'info':
+                assert len([s for s in log_infos if message[1] in s]) == \
+                       message[2]
 
     def _get_results(self):
         """Digest info in the output and return as a string."""
@@ -129,6 +135,49 @@ class TestHarness(object):
             os.rename('results_test.dat', self.results_error_fname)
         assert compare, 'Results do not agree.'
 
+    @staticmethod
+    def _is_float(word):
+        """Checks if a word can be converted to a float."""
+        try:
+            float(word)
+            return True
+        except ValueError:
+            return False
+
+    def _compare_mcnp_files(self, tol=5e-16):
+
+        """This function compares MCNP files with an allowed tolerance for
+        numbers containing decimal places."""
+
+        with open('results_test.dat', "r") as results_test:
+            results_test_lines = results_test.readlines()
+
+        with open(self.results_true_fname) as results_true:
+            results_true_lines = results_true.readlines()
+
+        test_words, true_words = [], []
+
+        for test_line, true_line in zip(results_test_lines, results_true_lines):
+            test_words.extend(test_line.split())
+            true_words.extend(true_line.split())
+
+        # Ensure files have the same number of words
+        assert len(results_test_lines) == len(results_true_lines)
+
+        for i, test_word in enumerate(test_words):
+            true_word = true_words[i]
+
+            if ('.' in test_word and '.' in true_word and
+                    self._is_float(test_word) and self._is_float(true_word)):
+
+                # Ensure any numbers with a decimal place match within tolerance
+                assert (abs(float(test_word) - float(true_word)) < tol)
+
+            else:
+
+                # Ensure any other words match exactly
+                assert test_word == true_word
+
     def _cleanup(self):
         """Delete statepoints, tally, and test files."""
         output = glob.glob('*.h5')
@@ -151,7 +200,7 @@ class TestHarness(object):
         depllib.add_isotope("He4", decay=he4dk)
 
         # U235
-        u235xs = ReactionData("b", 1)
+        u235xs = ReactionData()
         u235xs.add_type("fission", "b", [1.0])
         u235dk = DecayData(None, "s", 200.)
         u235yd = YieldData()
@@ -454,14 +503,14 @@ class CouplingHarness(TestHarness):
 
     def _create_test_lib(self):
         depllib = DepletionLibrary(self.lib_name, np.array([0., 100.]))
-        u235xs = ReactionData("cm2", 1)
+        u235xs = ReactionData()
         u235xs.add_type("fission", "cm2", np.array([self.sig_f]))
         u235nfy = YieldData()
         u235nfy.add_isotope("I134", 1.)
         depllib.add_isotope("U235", xs=u235xs, nfy=u235nfy)
 
         stable = DecayData(None, "s", 0.)
-        I134xs = ReactionData("cm2", 1)
+        I134xs = ReactionData()
         I134xs.add_type("(n,gamma)", "cm2", np.array([self.sig_c]), "I135")
         depllib.add_isotope("I134", xs=I134xs, decay=stable)
         depllib.add_isotope("I135", decay=stable)
diff --git a/tests/unit/conftest.py b/tests/unit/conftest.py
index aad453f..e741472 100755
--- a/tests/unit/conftest.py
+++ b/tests/unit/conftest.py
@@ -14,7 +14,7 @@ def depletion_lib():
     depllib.add_isotope("He4", decay=he4dk)
 
     # U235
-    u235xs = ReactionData("b", 1)
+    u235xs = ReactionData()
     u235xs.add_type("fission", "b", [100.0])
     u235dk = DecayData(np.log(2.) / 0.5, "s", 200.)
     u235dk.add_type("alpha", 1., "Th231")
@@ -28,7 +28,7 @@ def depletion_lib():
     depllib.add_isotope("Th231", decay=th231dk)
 
     # U238
-    u238xs = ReactionData("b", 1)
+    u238xs = ReactionData()
     u238xs.add_type("fission", "b", [10.0], "fission")
     u238yd = YieldData()
     u238yd.add_isotope("H1", 1.)
@@ -63,11 +63,11 @@ def depletion_lib():
 def simple_lib():
     lib = DepletionLibrary("test", np.array([0., 20.]))
 
-    u235xs = ReactionData("b", 1)
+    u235xs = ReactionData()
     u235xs.add_type("fission", "b", np.array([10.]), yields_=[1.])
     lib.add_isotope("U235", xs=u235xs)
 
-    u238xs = ReactionData("b", 1)
+    u238xs = ReactionData()
     u238xs.add_type("fission", "b", np.array([1.]))
     lib.add_isotope("U238", xs=u238xs)
     lib.finalize_library()
@@ -95,19 +95,19 @@ def simple_lib():
 def simple_lib_h1u234():
     lib = DepletionLibrary("test", np.array([0., 20.]))
 
-    u235xs = ReactionData("b", 1)
+    u235xs = ReactionData()
     u235xs.add_type("fission", "b", np.array([10.]), yields_=[1.])
     lib.add_isotope("U235", xs=u235xs)
 
-    u238xs = ReactionData("b", 1)
+    u238xs = ReactionData()
     u238xs.add_type("fission", "b", np.array([1.]))
     lib.add_isotope("U238", xs=u238xs)
 
-    h1xs = ReactionData("b", 1)
+    h1xs = ReactionData()
     h1xs.add_type("(n,gamma)", "b", np.array([1.]), "U235")
     lib.add_isotope("H1", xs=h1xs)
 
-    u234xs = ReactionData("b", 1)
+    u234xs = ReactionData()
     u234xs.add_type("(n,gamma)", "b", np.array([1.]), "U235")
     lib.add_isotope("U234", xs=u234xs)
 
@@ -126,7 +126,7 @@ def depletion_lib_2g():
     depllib.add_isotope("He4", decay=he4dk)
 
     # U235
-    u235xs = ReactionData("b", 2)
+    u235xs = ReactionData()
     u235xs.add_type("fission", "b", [50.0, 125.0])
     u235dk = DecayData(np.log(2.) / 0.5, "s", 200.)
     u235dk.add_type("alpha", 1., "Th231")
@@ -140,7 +140,7 @@ def depletion_lib_2g():
     depllib.add_isotope("Th231", decay=th231dk)
 
     # U238
-    u238xs = ReactionData("b", 2)
+    u238xs = ReactionData()
     u238xs.add_type("fission", "b", [5.0, 12.5])
     u238yd = YieldData()
     u238yd.add_isotope("H1", 1.)
diff --git a/tests/unit/test_cramdepletion.py b/tests/unit/test_cramdepletion.py
index efe63f3..dbaa0f3 100644
--- a/tests/unit/test_cramdepletion.py
+++ b/tests/unit/test_cramdepletion.py
@@ -14,7 +14,7 @@ def test_depletion_init():
     num_threads = 20
     num_procs = 200
     order = 16
-    chunksize = 100
+    chunksize = 0
 
     # Check the type and value checks of each of the input parameters
     # Check exec_cmd
@@ -37,7 +37,7 @@ def test_depletion_init():
         test_d = CRAMDepletion(exec_cmd, num_threads,
                                num_procs, str(chunksize), order)
     with pytest.raises(ValueError):
-        test_d = CRAMDepletion(exec_cmd, num_threads, num_procs, 0, order)
+        test_d = CRAMDepletion(exec_cmd, num_threads, num_procs, -1, order)
     # Check order
     with pytest.raises(ValueError):
         test_d = CRAMDepletion(exec_cmd, num_threads, num_procs, chunksize, "16")
diff --git a/tests/unit/test_depletion_library.py b/tests/unit/test_depletion_library.py
index 2d7db5e..71aa341 100755
--- a/tests/unit/test_depletion_library.py
+++ b/tests/unit/test_depletion_library.py
@@ -1,4 +1,5 @@
 import numpy as np
+import scipy.sparse as sp
 from collections import OrderedDict
 
 from adder import DepletionLibrary
@@ -95,6 +96,8 @@ origen_lib_all_xs = \
    1                0.0       0.0       0.0       0.0       1.000E 00 1.000E 00
    1   20040  6     0.0       0.0       0.0       0.0       0.0       0.0
    1                0.0       0.0       0.0       0.0       1.000E 00 1.000E 00
+   1   30060  6     0.0       0.0       0.0       0.0       0.0       0.0
+   1                0.0       0.0       0.0       0.0       4.000E-08 2.000E-04
    1   60130  6     0.0       0.0       0.0       0.0       0.0       0.0
    1                0.0       0.0       0.0       0.0       4.000E-08 2.000E-04
    1   70160  6     0.0       0.0       0.0       0.0       0.0       0.0
@@ -117,6 +120,8 @@ origen_lib_all_xs = \
    2                0.0       0.0       0.0       0.0       4.000E-08 2.000E-04
   -1
    3    TEST DECAY LIBRARY: FP
+   3   30060  6     0.0       0.0       0.0       0.0       0.0       0.0
+   3                0.0       0.0       0.0       0.0       4.000E-08 2.000E-04
    3   80160  6     0.0       0.0       0.0       0.0       0.0       0.0
    3                0.0       0.0       0.0       0.0       4.000E-08 2.000E-04
   -1
@@ -128,6 +133,8 @@ origen_lib_all_xs = \
    5  922350 8.000E-01 1.200E 00 3.000E 00 4.000E 00 2.000E-01 8.000E-01   -1.0
   -1
    6    TEST XS AND YIELD LIBRARY: FP
+   6   30060 0.0       0.0       4.200E 01 0.0       0.0       0.0          1.0
+   6     0.0      0.0      1.00E 02 0.0      0.0      0.0      0.0      0.0
    6   80160 0.0       0.0       3.000E-01 7.000E-01 0.0       0.0          1.0
    6     0.0      0.0      1.00E 02 0.00E 01 0.0      0.0      0.0      0.0
   -1
@@ -372,6 +379,10 @@ origen_lib_all_xs_output = \
               0.00000000E+00 0.00000000E+00
    3 0.00000000E+00 0.00000000E+00 0.00000000E+00 9.99998000E+01 1.00000000E+00
      1.00000000E+00
+   3  30060 6 0.00000000E+00 0.00000000E+00 0.00000000E+00 0.00000000E+00
+              0.00000000E+00 0.00000000E+00
+   3 0.00000000E+00 0.00000000E+00 0.00000000E+00 7.58900000E+00 1.00000000E+00
+     1.00000000E+00
    3  60130 6 0.00000000E+00 0.00000000E+00 0.00000000E+00 0.00000000E+00
               0.00000000E+00 0.00000000E+00
    3 0.00000000E+00 0.00000000E+00 0.00000000E+00 1.10780000E+00 1.00000000E+00
@@ -392,6 +403,10 @@ origen_lib_all_xs_output = \
             2.00000000E-01 8.00000000E-01 -1.0
   -1
    6    TEST XS AND YIELD LIBRARY: FP
+   6  30060 0.00000000E+00 0.00000000E+00 4.20000000E+01 0.00000000E+00
+            0.00000000E+00 0.00000000E+00 1.0
+   6 0.00000000E+00 0.00000000E+00 1.00000000E+02 0.00000000E+00 0.00000000E+00
+     0.00000000E+00 0.00000000E+00 0.00000000E+00
    6  80160 0.00000000E+00 0.00000000E+00 3.00000000E-01 7.00000000E-01
             0.00000000E+00 0.00000000E+00 1.0
    6 0.00000000E+00 0.00000000E+00 1.00000000E+02 0.00000000E+00 0.00000000E+00
@@ -400,6 +415,32 @@ origen_lib_all_xs_output = \
 """
 
 
+def check_decay(this, ref_t12, ref_t12_units, refQ, ref_prod_types,
+                ref_prod_brs, ref_prod_targets, ref_prod_yields):
+    assert this.half_life == ref_t12
+    assert this.half_life_units == ref_t12_units
+    assert this.decay_energy == refQ
+    assert sorted(this._product_types) == sorted(ref_prod_types)
+    for i, type_ in enumerate(ref_prod_types):
+        br, target_yields = this.get_product_data_by_type(type_)
+        assert abs(br - ref_prod_brs[i]) < 1e-15
+        assert np.all(target_yields['targets'] == ref_prod_targets[i])
+        np.testing.assert_allclose(
+            target_yields['yields'], ref_prod_yields[i], atol=1.e-15)
+
+
+def check_xs(this, ref_groups, ref_types, ref_xss, ref_targets,
+             ref_yields, ref_q):
+    assert sorted(this._product_types) == ref_types
+    for type_ in ref_types:
+        xs, target_yields, q_val = this.get_product_data_by_type(type_)
+        assert xs.shape == (ref_groups,)
+        assert xs == ref_xss
+        assert np.all(target_yields['targets'] == ref_targets)
+        assert np.all(target_yields['yields'] == ref_yields)
+        assert q_val == ref_q
+
+
 def test_from_origen():
     # This tests the Depletion Library's ability to read from a file
 
@@ -428,18 +469,6 @@ def test_from_origen():
                 "Th232", "U233", "Pu239", "Pu241", "Cm245", "Cf252"])
 
     # Check decay
-    def check_decay(this, ref_t12, ref_t12_units, refQ, ref_prod_types,
-                    ref_prod_brs, ref_prod_targets, ref_prod_yields):
-        assert this.half_life == ref_t12
-        assert this.half_life_units == ref_t12_units
-        assert this.decay_energy == refQ
-        assert sorted(this._products.keys()) == sorted(ref_prod_types)
-        for i, type_ in enumerate(ref_prod_types):
-            br, target, yield_ = this[type_]
-            assert br == ref_prod_brs[i]
-            assert target == ref_prod_targets[i]
-            assert yield_ == ref_prod_yields[i]
-
     check_decay(lib.isotopes["H1"].decay, None, "s", 0., [], [], [], [])
     check_decay(lib.isotopes["H2"].decay, None, "s", 0., [], [], [], [])
     check_decay(lib.isotopes["Th231"].decay, None, "s", 201., [], [], [], [])
@@ -451,23 +480,12 @@ def test_from_origen():
     check_decay(lib.isotopes["U238"].decay, None, "s", 202., [], [], [], [])
 
     # Now move on to comparing the xs
-    def check_xs(this, ref_units, ref_groups, ref_types, ref_xss, ref_targets,
-                 ref_yields, ref_q):
-        assert this.xs_units == ref_units
-        assert this.num_groups == ref_groups
-        assert sorted(this.keys()) == ref_types
-        for xs, targets, yields, q_val in this.values():
-            assert xs == ref_xss
-            assert targets == ref_targets
-            assert yields == ref_yields
-            assert q_val == ref_q
-
     # Now move on to comparing the xs
     xs = lib.isotopes["U235"].neutron_xs
-    check_xs(xs, "b", 1, ["fission"], np.array([100.]), ["fission"],
+    check_xs(xs,1, ["fission"], np.array([100.]), ["fission"],
              [1.0], 0.)
     xs = lib.isotopes["U238"].neutron_xs
-    check_xs(xs, "b", 1, ["fission"], np.array([10.]), ["fission"],
+    check_xs(xs, 1, ["fission"], np.array([10.]), ["fission"],
              [1.0], 0.)
 
     # Finally compare the yields
@@ -476,18 +494,18 @@ def test_from_origen():
     nfy = lib.isotopes["U235"].neutron_fission_yield
     ref_vals = {k: 0.5 for k in ref_channels}
     for key in ref_vals.keys():
-        assert nfy._products[key] == ref_vals[key]
+        assert nfy[key] == ref_vals[key]
     nfy = lib.isotopes["U238"].neutron_fission_yield
     ref_vals["H1"] = 0.3
     ref_vals["O16"] = 0.7
     for key in ref_vals.keys():
-        assert nfy._products[key] == ref_vals[key]
+        assert nfy[key] == ref_vals[key]
     # Now check the rest
     for iso in ["Th232", "U233", "Pu239", "Pu241", "Cm245", "Cf252"]:
         nfy = lib.isotopes[iso].neutron_fission_yield
         ref_vals = {k: 0.0 for k in ref_channels}
         for key in ref_vals.keys():
-            assert nfy._products[key] == ref_vals[key]
+            assert nfy[key] == ref_vals[key]
 
 
 def test_from_origen_all_decay():
@@ -518,18 +536,6 @@ def test_from_origen_all_decay():
     assert sorted(lib.initial_isotopes) == all_isos
 
     # Check decay
-    def check_decay(this, ref_t12, ref_t12_units, refQ, ref_prod_types,
-                    ref_prod_brs, ref_prod_targets, ref_prod_yields):
-        assert this.half_life == ref_t12
-        assert this.half_life_units == ref_t12_units
-        assert this.decay_energy == refQ
-        assert sorted(this._products.keys()) == sorted(ref_prod_types)
-        for i, type_ in enumerate(ref_prod_types):
-            br, target, yield_ = this[type_]
-            assert abs(br - ref_prod_brs[i]) < 1e-15
-            assert target == ref_prod_targets[i]
-            np.testing.assert_allclose(yield_, ref_prod_yields[i], atol=1.e-15)
-
     ref_channels = sorted(["H1", "O16"])
     for iso_name in yield_isos:
         # Should be no neutron_xs, no decay, and I inputted 0 values for
@@ -541,7 +547,7 @@ def test_from_origen_all_decay():
         nfy = iso.neutron_fission_yield
         ref_vals = {k: 0.0 for k in ref_channels}
         for key in ref_vals.keys():
-            assert nfy._products[key] == ref_vals[key]
+            assert nfy[key] == ref_vals[key]
 
     for iso_name in manual_isos:
         # Should have manually set decay info, no neutron_xs, and
@@ -568,7 +574,7 @@ def test_from_origen_all_decay():
             nfy = iso.neutron_fission_yield
             ref_vals = {k: 0.5 for k in ref_channels}
             for key in ref_vals.keys():
-                assert nfy._products[key] == ref_vals[key]
+                assert nfy[key] == ref_vals[key]
 
 
 def test_from_origen_all_xs():
@@ -591,8 +597,8 @@ def test_from_origen_all_xs():
     assert np.array_equal(lib.neutron_group_structure, np.array([0., 20.]))
     # We test against this list here because from_origen adds in fissile
     # isotopes that yield data exist for.
-    manual_isos = ["H1", "He4", "C13", "N16", "O16", "U233", "U234", "U234_m1",
-                   "U235", "U236", "U236_m1"]
+    manual_isos = ["H1", "He4", "C13", "Li6", "N16", "O16", "U233", "U234", 
+                   "U234_m1", "U235", "U236", "U236_m1"]
     yield_isos = ["Th232", "U238", "Pu239", "Pu241", "Cm245", "Cf252"]
     all_isos = sorted(manual_isos + yield_isos)
     assert sorted(lib.isotopes) == all_isos
@@ -606,16 +612,17 @@ def test_from_origen_all_xs():
         assert this.decay_energy == 0.
         assert len(this._products) == 0
 
-    def check_xs(this, ref_units, ref_groups, ref_type_data):
-        assert this.xs_units == ref_units
-        assert this.num_groups == ref_groups
-        assert sorted(this.keys()) == sorted(ref_type_data.keys())
-        for key, (xs, targets, yields, q_val) in this.items():
-            ref_xs, ref_targets, ref_yields, ref_q = ref_type_data[key]
+    def check_xs(this, ref_groups, ref_type_data):
+        assert sorted(this._product_types) == sorted(ref_type_data.keys())
+        for type_ in ref_type_data.keys():
+            ref_xs, ref_targets, ref_yields, ref_q = ref_type_data[type_]
+            xs, target_yields, q_val = this.get_product_data_by_type(type_)
             ref_xs = np.array([ref_xs])
+            assert xs.shape == (ref_groups,)
             assert xs == ref_xs
-            assert targets == ref_targets
-            assert yields == ref_yields
+            assert np.all(target_yields['targets'] == ref_targets)
+            np.testing.assert_allclose(
+                target_yields['yields'], ref_yields, atol=1.e-15)
             assert q_val == ref_q
 
     ref_channels = sorted(["O16"])
@@ -629,7 +636,7 @@ def test_from_origen_all_xs():
         nfy = iso.neutron_fission_yield
         ref_vals = {k: 0.0 for k in ref_channels}
         for key in ref_vals.keys():
-            assert nfy._products[key] == ref_vals[key]
+            assert nfy[key] == ref_vals[key]
 
     for iso_name in manual_isos:
         # Should have manually set xs info, no decay, and
@@ -637,15 +644,19 @@ def test_from_origen_all_xs():
         iso = lib.isotopes[iso_name]
         check_stable_decay(iso.decay)
         if iso_name == "U235":
-            check_xs(iso.neutron_xs, "b", 1,
+            check_xs(iso.neutron_xs, 1,
                      {"(n,gamma)": (1., ["U236", "U236_m1"], [0.8, 0.2], 0.),
                       "(n,2n)": (2., ["U234", "U234_m1"], [0.6, 0.4], 0.),
                       "(n,3n)": (3., ["U233"], [1.], 0.),
                       "fission": (4., ["fission"], [1.0], 0.)})
         elif iso_name == "O16":
-            check_xs(iso.neutron_xs, "b", 1,
+            check_xs(iso.neutron_xs, 1,
                      {"(n,a)": (0.3, ["C13", "He4"], [1.0, 1.0], 0.),
                       "(n,p)": (0.7, ["N16", "H1"], [1.0, 1.0], 0.)})
+        elif iso_name == "Li6":
+            # Note that (n,a) should have been assigned to (n,t) by ADDER
+            check_xs(iso.neutron_xs, 1,
+                     {"(n,t)": (42., ["H3", "He4"], [1.0, 1.0], 0.)})
         else:
             assert iso.neutron_xs is None
 
@@ -653,11 +664,11 @@ def test_from_origen_all_xs():
         if iso_name == "U235":
             ref_vals = {k: 1. for k in ref_channels}
             for key in ref_vals.keys():
-                assert nfy._products[key] == ref_vals[key]
+                assert nfy[key] == ref_vals[key]
         elif iso_name == "U233":
             ref_vals = {k: 0.0 for k in ref_channels}
             for key in ref_vals.keys():
-                assert nfy._products[key] == ref_vals[key]
+                assert nfy[key] == ref_vals[key]
         else:
             assert nfy is None
 
@@ -777,18 +788,6 @@ def test_to_hdf5():
                 "Th232", "U233", "Pu239", "Pu241", "Cm245", "Cf252"])
 
     # Check the decay
-    def check_decay(this, ref_t12, ref_t12_units, refQ, ref_prod_types,
-                    ref_prod_brs, ref_prod_targets, ref_prod_yields):
-        assert this.half_life == ref_t12
-        assert this.half_life_units == ref_t12_units
-        assert this.decay_energy == refQ
-        assert sorted(this._products.keys()) == sorted(ref_prod_types)
-        for i, type_ in enumerate(ref_prod_types):
-            br, target, yield_ = this[type_]
-            assert br == ref_prod_brs[i]
-            assert target == ref_prod_targets[i]
-            assert yield_ == ref_prod_yields[i]
-
     check_decay(lib.isotopes["H1"].decay, None, "s", 0., [], [], [], [])
     check_decay(lib.isotopes["H2"].decay, None, "s", 0., [], [], [], [])
     check_decay(lib.isotopes["Th231"].decay, None, "s", 201., [], [], [], [])
@@ -800,22 +799,11 @@ def test_to_hdf5():
     check_decay(lib.isotopes["U238"].decay, None, "s", 202., [], [], [], [])
 
     # Now move on to comparing the xs
-    def check_xs(this, ref_units, ref_groups, ref_types, ref_xss, ref_targets,
-                 ref_yields, ref_q):
-        assert this.xs_units == ref_units
-        assert this.num_groups == ref_groups
-        assert sorted(this.keys()) == ref_types
-        for xs, targets, yields, q_val in this.values():
-            assert xs == ref_xss
-            assert targets == ref_targets
-            assert yields == ref_yields
-            assert q_val == ref_q
-
     xs = lib.isotopes["U235"].neutron_xs
-    check_xs(xs, "b", 1, ["fission"], np.array([100.]), ["fission"],
+    check_xs(xs, 1, ["fission"], np.array([100.]), ["fission"],
              [1.0], 0.)
     xs = lib.isotopes["U238"].neutron_xs
-    check_xs(xs, "b", 1, ["fission"], np.array([10.]), ["fission"],
+    check_xs(xs, 1, ["fission"], np.array([10.]), ["fission"],
              [1.0], 0.)
 
     # Finally compare the yields
@@ -824,18 +812,18 @@ def test_to_hdf5():
     nfy = lib.isotopes["U235"].neutron_fission_yield
     ref_vals = {k: 0.5 for k in ref_channels}
     for key in ref_vals.keys():
-        assert nfy._products[key] == ref_vals[key]
+        assert nfy[key] == ref_vals[key]
     nfy = lib.isotopes["U238"].neutron_fission_yield
     ref_vals["H1"] = 0.3
     ref_vals["O16"] = 0.7
     for key in ref_vals.keys():
-        assert nfy._products[key] == ref_vals[key]
+        assert nfy[key] == ref_vals[key]
     # Now check the rest
     for iso in ["Th232", "U233", "Pu239", "Pu241", "Cm245", "Cf252"]:
         nfy = lib.isotopes[iso].neutron_fission_yield
         ref_vals = {k: 0.0 for k in ref_channels}
         for key in ref_vals.keys():
-            assert nfy._products[key] == ref_vals[key]
+            assert nfy[key] == ref_vals[key]
 
 
 def test_A_matrix(depletion_lib_2g):
@@ -885,7 +873,8 @@ def test_A_matrix(depletion_lib_2g):
     # we are aware of it and it has no effect
     # we could do a try/except but to catch a warning (vice error)
     # will require extra code that doesn't seem worth it.
-    testA = depletion_lib_2g.build_depletion_matrix(flux).todense()
+    testA = depletion_lib_2g.build_depletion_matrix(
+        flux, sp.csr_matrix(test_decay_matrix)).todense()
     np.testing.assert_allclose(A, testA, rtol=1.e-14)
 
 
@@ -926,7 +915,7 @@ def test_clone(depletion_lib_2g):
         ref = depletion_lib_2g.isotopes[iso_name]
 
         # Check the shallow copies
-        attribs = ["name", "atomic_mass", "neutron_fission_yield", "decay"]
+        attribs = ["atomic_mass", "neutron_fission_yield", "decay"]
         for attrib in attribs:
             test_a = getattr(test, attrib)
             ref_a = getattr(ref, attrib)
diff --git a/tests/unit/test_material.py b/tests/unit/test_material.py
index 6c5d1d1..1038070 100755
--- a/tests/unit/test_material.py
+++ b/tests/unit/test_material.py
@@ -145,8 +145,10 @@ def test_material_init():
                               num_groups, thermal_xs_libraries, status)
     assert test_mat.name == name
     assert test_mat.id == mat_id
+    assert test_mat.parent_id == None
     assert test_mat.density == density
-    for i, test_iso in enumerate(test_mat.isotopes):
+    for i in range(test_mat.num_isotopes):
+        test_iso = test_mat.isotope_obj(i)
         assert test_iso.name == isotope_data[i][0]
         assert test_iso.xs_library == isotope_data[i][1]
     np.testing.assert_array_equal(test_mat.atom_fractions, [0.4, 0.5, 0.1])
@@ -154,7 +156,7 @@ def test_material_init():
     assert test_mat.default_xs_library == default_xs_library
     assert test_mat.num_groups == num_groups
     assert test_mat.thermal_xs_libraries == thermal_xs_libraries
-    assert test_mat.isotopes_in_neutronics == [True, True, True]
+    assert np.all(test_mat.isotopes_in_neutronics == True)
     assert test_mat.volume is None
     np.testing.assert_array_equal(test_mat.flux, np.zeros(1))
     assert test_mat.Q == 0.
@@ -254,8 +256,10 @@ def test_material_clone(simple_lib):
     # Now verify the clone
     assert test_mat.name == new_name
     assert test_mat.id == 2
+    assert test_mat.parent_id == 1
     assert test_mat.density == density
-    for i, test_iso in enumerate(test_mat.isotopes):
+    for i in range(test_mat.num_isotopes):
+        test_iso = test_mat.isotope_obj(i)
         assert test_iso.name == isotope_data[i][0]
         assert test_iso.xs_library == isotope_data[i][1]
     np.testing.assert_array_equal(test_mat.atom_fractions, [0.4, 0.5, 0.1])
@@ -263,7 +267,7 @@ def test_material_clone(simple_lib):
     assert test_mat.default_xs_library == default_xs_library
     assert test_mat.num_groups == num_groups
     assert test_mat.thermal_xs_libraries == thermal_xs_libraries
-    assert test_mat.isotopes_in_neutronics == [True, True, True]
+    assert np.all(test_mat.isotopes_in_neutronics == True)
     assert test_mat.volume is None
     np.testing.assert_array_equal(test_mat.flux, np.zeros(1))
     assert test_mat.Q == 0.
@@ -313,7 +317,8 @@ def test_material_update_isotope_is_depleting(simple_lib):
 
     # Verify by checking the isotopes' status hasn't changed from what
     # we initialized it to
-    for i, iso in enumerate(test_mat.isotopes):
+    for i in range(test_mat.num_isotopes):
+        iso = test_mat.isotope_obj(i)
         assert iso.is_depleting == isotope_data[i][-1]
 
     # Ok, now assign the depletion library to be a clone of simple_lib
@@ -327,7 +332,8 @@ def test_material_update_isotope_is_depleting(simple_lib):
     # Since simple_lib does not include H1, we should see that H1 is now
     # non-depleting
     isotope_data[0] = ("H1", "70c", False)
-    for i, iso in enumerate(test_mat.isotopes):
+    for i in range(test_mat.num_isotopes):
+        iso = test_mat.isotope_obj(i)
         assert iso.is_depleting == isotope_data[i][-1]
     # We should also see the info that H1 was changed
     assert len(test_mat.logs) == 1
@@ -336,7 +342,7 @@ def test_material_update_isotope_is_depleting(simple_lib):
     # a stable, zero xs H1
     assert "H1" in new_lib.isotopes.keys()
     iso_lib = new_lib.isotopes["H1"]
-    np.testing.assert_array_equal(iso_lib.get_total_removal_xs("b"), [0.])
+    np.testing.assert_array_equal(iso_lib.get_total_removal_xs("b"), None)
     np.testing.assert_array_equal(iso_lib.get_total_decay_const("s"), [0.])
 
 
@@ -413,7 +419,8 @@ def test_material_determine_important_isotopes(simple_lib, simple_lib_h1u234):
     # neutronics except for ones with concentrations less tan 1E-10
     # (so U238 should be considered not in neutronics)
     test_mat.determine_important_isotopes(lib)
-    assert test_mat.isotopes_in_neutronics == [True, True, False]
+    assert np.array_equal(test_mat.isotopes_in_neutronics,
+                          np.array([True, True, False], dtype=np.bool_))
 
     # Now we need to have a flux so we can step through the rest of
     # the function
@@ -423,14 +430,15 @@ def test_material_determine_important_isotopes(simple_lib, simple_lib_h1u234):
     # U235 will be because its important, and U238 is at such a low
     # concentration that it will not be. Therefore, the
     # isotopes to neglect will be the same as in the test block above
-    assert test_mat.isotopes_in_neutronics == [True, True, False]
+    assert np.array_equal(test_mat.isotopes_in_neutronics,
+                          np.array([True, True, False], dtype=np.bool_))
 
     # Finally we run the exact same case but now we tell it that U238 must be
     # kept in the model no matter what. Therefore we expect the corresponding
     # value in test_mat.isotopes_in_neutronics to be True.
     test_mat.isotopes_to_keep_in_model = {'U238'}
     test_mat.determine_important_isotopes(lib)
-    assert test_mat.isotopes_in_neutronics == [True, True, True]
+    assert np.all(test_mat.isotopes_in_neutronics == True)
 
     # Now lets repeat with a purely absorbing material
     # Create a material to test
@@ -455,11 +463,12 @@ def test_material_determine_important_isotopes(simple_lib, simple_lib_h1u234):
 
     # Before we go ahead, prove that test_mat.isotopes_in_neutronics
     # is all true
-    assert all(test_mat.isotopes_in_neutronics)
+    assert np.all(test_mat.isotopes_in_neutronics == True)
 
     # Now we expect that U234 will not be included but H1 will be. Lets check
     test_mat.determine_important_isotopes(lib)
-    assert test_mat.isotopes_in_neutronics == [True, False]
+    assert np.array_equal(test_mat.isotopes_in_neutronics,
+                          np.array([True, False], dtype=np.bool_))
 
 
 def test_material_number_density_vectors(simple_lib):
@@ -546,6 +555,10 @@ def test_material_hdf5(simple_lib):
     thermal_xs_libraries = []
     flux = np.array([10.])
     volume = 2.
+    power_density = flux.sum() * 200. * 1e18 * 1.6021766208e-19 * 1.0e6 \
+                    / volume
+    burnup = power_density * volume * 1e-6 * 3.
+    fission_density = 10 * 1e18 * 3. * 86400 / volume
     status = adder.constants.IN_CORE
 
     # initialize the material and write it to an hdf5 file
@@ -554,6 +567,9 @@ def test_material_hdf5(simple_lib):
                               num_groups, thermal_xs_libraries, status)
     init_mat.flux = flux
     init_mat.volume = volume
+    init_mat.power_density = power_density
+    init_mat.burnup = burnup
+    init_mat.fission_density = fission_density
 
     # Clone material an arbitrary number of times n_clones
     # to test the num_copies attribute
@@ -574,7 +590,8 @@ def test_material_hdf5(simple_lib):
     assert test_mat.name == name
     assert test_mat.id == mat_id
     assert test_mat.density == density
-    for i, test_iso in enumerate(test_mat.isotopes):
+    for i in range(test_mat.num_isotopes):
+        test_iso = test_mat.isotope_obj(i)
         assert test_iso.name == isotope_data[i][0]
         assert test_iso.xs_library == isotope_data[i][1]
     np.testing.assert_array_equal(test_mat.atom_fractions, [0.4, 0.5, 0.1])
@@ -582,9 +599,12 @@ def test_material_hdf5(simple_lib):
     assert test_mat.default_xs_library == default_xs_library
     assert test_mat.num_groups == num_groups
     assert test_mat.thermal_xs_libraries == thermal_xs_libraries
-    assert test_mat.isotopes_in_neutronics == [True, True, True]
+    assert np.all(test_mat.isotopes_in_neutronics == True)
     assert test_mat.volume == volume
     np.testing.assert_array_equal(test_mat.flux, flux)
+    assert test_mat.power_density == power_density
+    assert test_mat.burnup == burnup
+    assert test_mat.fission_density == fission_density
     assert test_mat.Q == 0.
     ref_N = np.array([0.4, 0.5, 0.1]) * 2. * 1.E24
     np.testing.assert_array_equal(test_mat.number_densities, ref_N)
diff --git a/tests/unit/test_mcnp_parse.py b/tests/unit/test_mcnp_parse.py
index b97bff2..e78b56e 100644
--- a/tests/unit/test_mcnp_parse.py
+++ b/tests/unit/test_mcnp_parse.py
@@ -26,6 +26,7 @@ c lower-case comment
 1 1 1.0 -2 imp:n=1 imp:p 2
 2 2 -1.0 2 -3 IMP:N=1 ImP:P=2.5
 3 0 3 imp:n,p=0 $ inline comment
+4 3 1.0 -2 imp:n,p=0
 """
 
 surf_block = """
@@ -43,6 +44,7 @@ mat_block = """
 m0 nlib=70c
 m1 92235.71c 1.0 8016 2.0
 m2 92238.72c -0.88 8016 -.12 nlib=71c
+m3 1004.80c 1.0
 """
 
 # The data block will not include specific cards to actually test handling of,
@@ -78,7 +80,7 @@ cf1 2
 cm1 1.
 sf1 1
 f4:n 1
-fm4 1
+fm4 (1)(1 1 (1 -4)(-2))((1 1 102)(1 -1 2 1)(1 -1 5 1 6 2 7 3))  
 fq4 1
 ft4 1
 fs4 1
@@ -91,17 +93,16 @@ Em4 1
 t4 1
 tf4 1
 tm4 1
-F14X:n 1
-f14y:n 1
-f14z:n 1
+F14:n 1
 kpert14 1
 ksen14 1
+fic5:n 1
+fip15:n 1
+fir25:n 1
+f35:n 1
+de35 1
+df35 1
 fmesh24:n data=1.0
-fic34:n 1
-fip34:n 1
-fir34:n 1
-de44 1
-df44 1
 c tmesh block
 tmesh
     cmesh1:n 1
@@ -156,9 +157,15 @@ def test_mcnp_readwrite(simple_lib):
     user_univ_info = {}
     shuffled_mats = set()
     shuffled_univs = set()
+    
+    # materials for multiplier card
+    mat_block_multiplier = """m5 92235.71c 1.0 8016 2.0
+    m6 92238.72c -0.88 8016 -.12 nlib=71c
+    m7 92235.71c 1.0 8016 2.0
+    """
 
     # Write the input file
-    start_inp = "".join([cell_block, surf_block, mat_block, data_block, ""])
+    start_inp = "".join([cell_block, surf_block, mat_block, mat_block_multiplier, data_block, ""])
     with open(fname, "w+") as f:
         f.write(start_inp)
     # And the xsdir file
@@ -166,29 +173,34 @@ def test_mcnp_readwrite(simple_lib):
         f.write(xsdir)
 
     # Now we can get the data
-    test_mats = test_neut.read_input(lib_file, num_neutron_groups,
+    neut_lib_isos = test_neut.parse_library(lib_file)
+    test_mats = test_neut.read_input(num_neutron_groups,
                                      user_mats_info, user_univ_info,
                                      shuffled_mats, shuffled_univs, depl_libs)
-
+    
     # Now lets check test_mats and the assigned parameters of test_neut
     assert test_mats[0].name == user_mats_info[1]["name"]
     assert test_mats[0].id == 1
     assert test_mats[0].is_depleting == user_mats_info[1]["depleting"]
-    assert test_mats[0].isotopes[0].name == "U235"
-    assert test_mats[0].isotopes[0].is_depleting is True
-    assert test_mats[0].isotopes[0].xs_library == "71c"
-    assert test_mats[0].isotopes[1].name == "O16"
-    assert test_mats[0].isotopes[1].is_depleting is True
-    assert test_mats[0].isotopes[1].xs_library == "70c"
+
+    assert test_mats[0].isotope_obj(0).name == "U235"
+    assert test_mats[0].isotope_obj(0).is_depleting is True
+    assert test_mats[0].isotope_obj(0).xs_library == "71c"
+    assert test_mats[0].isotope_obj(1).name == "O16"
+    assert test_mats[0].isotope_obj(1).is_depleting is True
+    assert test_mats[0].isotope_obj(1).xs_library == "70c"
     assert len(test_mats[0].isotopes_to_keep_in_model) == 2
     assert sorted(test_mats[0].isotopes_to_keep_in_model) == \
         sorted({'U235', 'O16'})
-    assert test_mats[1].isotopes[0].name == "U238"
-    assert test_mats[1].isotopes[0].is_depleting is True
-    assert test_mats[1].isotopes[0].xs_library == "72c"
-    assert test_mats[1].isotopes[1].name == "O16"
-    assert test_mats[1].isotopes[1].is_depleting is False
-    assert test_mats[1].isotopes[1].xs_library == "71c"
+    assert test_mats[1].isotope_obj(0).name == "U238"
+    assert test_mats[1].isotope_obj(0).is_depleting is True
+    assert test_mats[1].isotope_obj(0).xs_library == "72c"
+    assert test_mats[2].isotope_obj(0).name == "H4"
+    assert test_mats[2].isotope_obj(0).is_depleting is False
+    assert test_mats[2].isotope_obj(0).xs_library == "80c"
+    assert test_mats[1].isotope_obj(1).name == "O16"
+    assert test_mats[1].isotope_obj(1).is_depleting is False
+    assert test_mats[1].isotope_obj(1).xs_library == "71c"
     assert len(test_mats[1].isotopes_to_keep_in_model) == 0
     np.testing.assert_allclose(test_mats[0].atom_fractions,
                                [1. / 3., 2. / 3.], rtol=1e-15)
@@ -204,6 +216,7 @@ def test_mcnp_readwrite(simple_lib):
     ref_num_density = 1. * 0.6022140857 / np.dot([m_238, m_16], ref_fracs)
     assert test_mats[1].density == ref_num_density
 
+
     # Now check the data of the neutronics class
     assert test_neut.xsdir_file == lib_file
     ref_xsdir_data = \
@@ -214,7 +227,9 @@ def test_mcnp_readwrite(simple_lib):
          "54135.72c": 133.748000, "53135.70c": 133.750000,
          "53135.71c": 133.750000, "53135.72c": 133.750000,
          "8016.70c": 15.857510, "8016.71c": 15.857510, "8016.72c": 15.857510,
-         "1001.70c":0.999167, "1001.71c": 0.999167, "1001.72c": 0.999167}
+         "3006.70c": 5.9634, "3006.71c": 5.9634, "3006.72c": 5.9634,
+         "1001.70c": 0.999167, "1001.71c": 0.999167, "1001.72c": 0.999167,
+         "1004.80c": 0.999167, "lwtr.10t": 0.999167}
     # Check the dictionary
     assert len(test_neut.neutronics_isotopes) == len(ref_xsdir_data)
     assert sorted(test_neut.neutronics_isotopes.keys()) == \
@@ -230,18 +245,18 @@ def test_mcnp_readwrite(simple_lib):
 
     # Check the cells
     ref_cell_data = \
-        {"id": [1, 2, 3], "material_id": [1, 2, 0],
-         "material": [test_mats[0], test_mats[1], None],
-         "density": [1., ref_num_density, 0.], "surfaces": ["-2", "2 -3", "3"],
-         "coord_transform": [None, None, None], "universe_id": [0, 0, 0],
-         "lattice": [None, None, None], "fill_type": [None, None, None],
-         "fill_dims": [None, None, None],
-         "fill_transforms": [None, None, None], "_fill": [None, None, None],
-         "fill_ids": [None, None, None], "volume": [None, None, None],
+        {"id": [1, 2, 3, 4], "material_id": [1, 2, 0, 3],
+         "material": [test_mats[0], test_mats[1], None, test_mats[2]],
+         "density": [1., ref_num_density, 0., 1.], "surfaces": ["-2", "2 -3", "3", "-2"],
+         "coord_transform": [None, None, None, None], "universe_id": [0, 0, 0, 0],
+         "lattice": [None, None, None, None], "fill_type": [None, None, None, None],
+         "fill_dims": [None, None, None, None],
+         "fill_transforms": [None, None, None, None], "_fill": [None, None, None, None],
+         "fill_ids": [None, None, None, None], "volume": [None, None, None, None],
          "other_kwargs": [{"imp:n": "1", "imp:p": "2"},
                           {"imp:n": "1", "imp:p": "2.5"},
-                          {"imp:n,p": "0"}]}
-    for c in range(3):
+                          {"imp:n,p": "0"}, {"imp:n,p": "0"}]} #imp:n,p=0
+    for c in range(4):
         cell = test_neut.cells[ref_cell_data["id"][c]]
         for attrib in ref_cell_data.keys():
             # Density needs a floating point compare, the rest are direct:
@@ -260,11 +275,12 @@ def test_mcnp_readwrite(simple_lib):
 
     # We already checked the specific cells, lets just make sure the right
     # ones were assigned.
-    assert list(test_neut.universes[0].cells.keys()) == [1, 2, 3]
-    assert [c.id for c in test_neut.universes[0].cells.values()] == [1, 2, 3]
+    assert list(test_neut.universes[0].cells.keys()) == [1, 2, 3, 4]
+    assert [c.id for c in test_neut.universes[0].cells.values()] == [1, 2, 3, 4]
 
-    assert test_neut.max_user_tally_id == 44
-    assert test_neut.multiplier_mat_ids == set()
+    assert test_neut.max_user_tally_id == 35
+    assert test_neut.multiplier_mat_ids == set([1,2,5,6,7])
+    
     assert len(test_neut.coord_transforms) == 1
     # Should only have the default null transform
     assert test_neut.coord_transforms[0].is_null is True
@@ -294,16 +310,21 @@ def test_mcnp_readwrite(simple_lib):
     ref_surface = ["2 cz 2.", "*3 cx 3."]
     ref_material = \
         ["m0 nlib=70c", "m1 92235.71c 1.0 8016 2.0",
-         "m2 92238.72c -0.88 8016 -.12 nlib=71c"]
+         "m2 92238.72c -0.88 8016 -.12 nlib=71c",
+         "m3 1004.80c 1.0",
+         "m5 92235.71c 1.0 8016 2.0", 
+         "m6 92238.72c -0.88 8016 -.12 nlib=71c",
+         "m7 92235.71c 1.0 8016 2.0"]
     ref_tally = \
-        ["f1:p 1", "c1 0.5 1.0", "cf1 2", "cm1 1.", "sf1 1", "f4:n 1", "fm4 1",
+        ["f1:p 1", "cf1 2", "c1 0.5 1.0", "cm1 1.", "sf1 1", "fc4 comment", "f4:n 1",
+         "fm4 (1)(1 1 (1 -4)(-2))((1 1 102)(1 -1 2 1)(1 -1 5 1 6 2 7 3))",
          "fq4 1", "ft4 1", "fs4 1", "sd4 1", "fu4 1", "pert4:n 1",
-         "fc4 comment", "e4 0.5 20.0", "Em4 1", "t4 1", "tf4 1", "tm4 1",
-         "F14X:n 1", "f14y:n 1", "f14z:n 1", "kpert14 1", "ksen14 1",
-         "fmesh24:n data=1.0", "fic34:n 1", "fip34:n 1", "fir34:n 1",
-         "de44 1", "df44 1", "tmesh", "cmesh1:n 1", "cora1 1", "corb1 1",
-         "corc1 1", "ergsh1 1", "mshmf1 1", "rmesh1:n 1", "smesh1:n",
-         "gobble", "endmd"]
+          "e4 0.5 20.0", "Em4 1", "t4 1", "tf4 1", "tm4 1",
+         "f14:n 1", "kpert14 1", "ksen14 1",
+          "fic5:n 1", "fip15:n 1", "fir25:n 1",
+         "f35:n 1", "de35 1", "df35 1", "fmesh24:n data=1.0"]
+    ref_tmesh = ["tmesh", "cmesh1:n 1", "cora1 1", "corb1 1", "corc1 1", "ergsh1 1",
+                "mshmf1 1", "rmesh1:n 1", "smesh1:n", "gobble", "endmd"]
     ref_output = ["mplot 1", "print 10", "prdmp 1 1 1 1 1", "ptrac file=asc",
                   "histp -lhist=-1 1", "dbcn 1"]
     ref_other = \
@@ -323,10 +344,18 @@ def test_mcnp_readwrite(simple_lib):
          "mp 1"]
 
     for key, ref in zip(["message", "title", "material", "tally",
-                         "output", "other"],
+                         "tmesh", "output", "other"],
                         [ref_message, ref_title, ref_material,
-                         ref_tally, ref_output, ref_other]):
-        assert test_neut.base_input[key] == ref
+                         ref_tally, ref_tmesh, ref_output, ref_other]):
+        # check for test_neut.base_input for string comparison.
+        if key != "tally":
+            assert test_neut.base_input[key] == ref
+        # check for test_neut.base_input[tally], which is a list of tally
+        else:
+            base_input_tally = []
+            for tally in test_neut.base_input[key]:
+                base_input_tally.extend(tally.get_tally_block())
+            assert base_input_tally == ref
     # Now check the ref surfaces
     for i, surf in enumerate([test_neut.surfaces[2], test_neut.surfaces[3]]):
         assert str(surf) == ref_surface[i]
@@ -334,8 +363,11 @@ def test_mcnp_readwrite(simple_lib):
     # Now we can write the output file for comparison
     # This one will include the user's tallies and output
     out_name = "output.inp"
+    # suppose setting in ADDER the same tally for mcnp tallies.
+    user_tallies = {"1": "universe", "4": "universe", "14": "universe", "5": "universe",
+                    "15": "universe", "25": "universe", "35": "universe", "24": "universe"}
     test_neut.write_input(out_name, "test", test_mats, depl_libs, False, False,
-                          True, True)
+                          user_tallies, True, True)
     with open(out_name, "r") as f:
         test_out = f.readlines()
     os.remove(out_name)
@@ -344,14 +376,23 @@ def test_mcnp_readwrite(simple_lib):
     # Create the reference solutions
     ref_cell_block = ["1 1 1.0000000000000E+00 -2 u=0 imp:n=1 imp:p=2",
                       "2 2 6.7442405203693E-03 2 -3 u=0 imp:n=1 imp:p=2.5",
-                      "3 0 3 u=0 imp:n,p=0"]
+                      "3 0 3 u=0 imp:n,p=0", "4 3 1.0000000000000E+00 -2 u=0 imp:n,p=0"]
 
     ref_mat_block = \
         ["c ADDER Material Name: mat1",
          "m1 92235.71c 3.333333E-01 8016.70c 6.666667E-01",
          "c ADDER Material Name: 2",
          "m2 92238.72c {:1.6E} 8016.71c {:1.6E}".format(ref_fracs[0],
-                                                        ref_fracs[1])]
+                                                        ref_fracs[1]),
+         "c ADDER Material Name: 3",
+         "m3 1004.80c 1.000000E+00",
+         "c Multiplier Material Name: 5",
+         "m5 92235.71c 3.333333E-01 8016.70c 6.666667E-01",
+         "c Multiplier Material Name: 6",
+         "m6 92238.72c {:1.6E} 8016.71c {:1.6E}".format(ref_fracs[0],
+                                                        ref_fracs[1]),
+         "c Multiplier Material Name: 7",
+         "m7 92235.71c 3.333333E-01 8016.70c 6.666667E-01",]
     ref_out_file = ref_message + [""] + [ref_title + " test"] +  \
         ref_cell_block + [""] + ref_surface + [""] + ref_mat_block + \
         ["PRINT 10 60 128 130", "PRDMP 1 1 1 1 1", "mplot 1", "ptrac file=asc",
@@ -371,7 +412,7 @@ def test_mcnp_readwrite(simple_lib):
          "mode 1",
          "mphys 1",
          "mx 1",
-         "mp 1"] + ref_tally + [""]
+         "mp 1"] + ["c User tallies"] + ref_tally + ref_tmesh + [""]
     ref_out = [line + "\n" for line in ref_out_file]
     assert len(test_out) == len(ref_out)
     for i in range(len(test_out)):
@@ -379,13 +420,13 @@ def test_mcnp_readwrite(simple_lib):
 
     # Now we need to verify that it does not write each of user output
     # and user tallies. We will do this one at a time.
-    # Without print output, we lose the user's print table 10 command and the
-    # mplot command
-    ref_out[14] = "PRINT 60 128 130\n"
-    ref_out[15] = "PRDMP 0 0 1\n"
-    del ref_out[16:20]
+    # Without print output, we lose the user's print table 10 command, the 
+    # multiplier materials the mplot command
+    ref_out[23] = "PRINT 60 128 130\n"
+    ref_out[24] = "PRDMP 0 0 1\n"
+    del ref_out[25:29]
     test_neut.write_input(out_name, "test", test_mats, depl_libs, False, False,
-                          True, False)
+                          user_tallies, True, False, False)
     with open(out_name, "r") as f:
         test_out = f.readlines()
     os.remove(out_name)
@@ -393,13 +434,15 @@ def test_mcnp_readwrite(simple_lib):
     for i in range(len(test_out)):
         assert test_out[i] == ref_out[i]
 
-    # And now we will lose the user's tallies
-    del ref_out[33: -1]
+    # And now we will lose the multiplier materials and user's tallies 
+    del ref_out[17:23]
+    del ref_out[36: -1]
     test_neut.write_input(out_name, "test", test_mats, depl_libs, False, False,
-                          False, False)
+                          {}, False, False)
     with open(out_name, "r") as f:
         test_out = f.readlines()
     os.remove(out_name)
+    del test_out[-12:-1]
     assert len(test_out) == len(ref_out)
     for i in range(len(test_out)):
         assert test_out[i] == ref_out[i]
@@ -451,7 +494,8 @@ def test_mcnp_input_errors(simple_lib):
         # The next command should raise a ValueError due to the presence of the
         # error card.
         with pytest.raises(ValueError):
-            test_mats = test_neut.read_input(lib_file, num_neutron_groups,
+            neut_lib_isos = test_neut.parse_library(lib_file)
+            test_mats = test_neut.read_input(num_neutron_groups,
                                              user_mats_info, user_univ_info,
                                              shuffled_mats, shuffled_univs,
                                              depl_libs)
@@ -512,12 +556,13 @@ def test_mcnp_pass_input(simple_lib):
             f.write(start_inp)
         test_neut = adder.mcnp.McnpNeutronics("", "mcnp.EXE", fname, 1, 1,
                                               True, 1.e-3, False)
-        test_mats = test_neut.read_input(lib_file, num_neutron_groups,
+        neut_lib_isos = test_neut.parse_library(lib_file)
+        test_mats = test_neut.read_input(num_neutron_groups,
                                          user_mats_info, user_univ_info,
                                          shuffled_mats, shuffled_univs,
                                          depl_libs)
         test_neut.write_input(out_name, "test", test_mats, depl_libs, False,
-                              False, False, False)
+                              False, {}, True,False, )
         with open(out_name, "r") as f:
             test_out = f.readlines()
         os.remove(out_name)
@@ -584,12 +629,14 @@ def test_mcnp_card_to_cell(simple_lib):
             f.write(start_inp)
         test_neut = adder.mcnp.McnpNeutronics("", "mcnp.EXE", fname, 1, 1,
                                               True, 1.e-3, False)
-        test_mats = test_neut.read_input(lib_file, num_neutron_groups,
+        neut_lib_isos = test_neut.parse_library(lib_file)
+        test_mats = test_neut.read_input(num_neutron_groups,
                                          user_mats_info, user_univ_info,
                                          shuffled_mats, shuffled_univs,
                                          depl_libs)
         test_neut.write_input(out_name, "test", test_mats, depl_libs, False,
-                              False, False, False, False)
+                              False, {}, True,False,
+                              False)
         with open(out_name, "r") as f:
             test_out = f.readlines()
         os.remove(out_name)
@@ -648,11 +695,12 @@ def test_mcnp_like_but_cell(simple_lib):
         f.write(start_inp)
     test_neut = adder.mcnp.McnpNeutronics("", "mcnp.EXE", fname, 1, 1,
                                           True, 1.e-3, False)
-    test_mats = test_neut.read_input(lib_file, num_neutron_groups,
+    neut_lib_isos = test_neut.parse_library(lib_file)
+    test_mats = test_neut.read_input(num_neutron_groups,
                                      user_mats_info, user_univ_info,
                                      shuffled_mats, shuffled_univs, depl_libs)
     test_neut.write_input(out_name, "test", test_mats, depl_libs, False, False,
-                          False, False, False)
+                          {}, True,False, False)
     with open(out_name, "r") as f:
         test_out = f.readlines()
     os.remove(out_name)
@@ -713,7 +761,8 @@ def test_mcnp_xscards(simple_lib):
 
     test_neut = adder.mcnp.McnpNeutronics("", "mcnp.EXE", fname, 1, 1, True,
                                           1.e-3, False)
-    _ = test_neut.read_input(lib_file, num_neutron_groups, user_mats_info,
+    neut_lib_isos = test_neut.parse_library(lib_file)
+    _ = test_neut.read_input(num_neutron_groups, user_mats_info,
                              user_univ_info, shuffled_mats, shuffled_univs,
                              depl_libs)
     # Now check test_neut.allowed_isotopes for valid values based on
@@ -728,7 +777,9 @@ def test_mcnp_xscards(simple_lib):
          "54135.72c": 133.748000, "53135.70c": 133.750000,
          "53135.71c": 133.750000, "53135.72c": 133.750000,
          "8016.70c": 15.857510, "8016.71c": 15.857510, "8016.72c": 15.857510,
-         "1001.70c": 0.999167, "1001.71c": 0.999167, "1001.72c": 0.999167}
+         "3006.70c": 5.9634, "3006.71c": 5.9634, "3006.72c": 5.9634,
+         "1001.70c": 0.999167, "1001.71c": 0.999167, "1001.72c": 0.999167,
+         "1004.80c": 0.999167, "lwtr.10t": 0.999167}
     # XS1 and XS2 cards add in 2 5010 values
     ref_xsdir_data["5010.70c"] = 10.0
     ref_xsdir_data["5010.71c"] = 10.1
@@ -784,12 +835,13 @@ def test_mcnp_material_parsing_error(caplog, simple_lib):
 
     test_neut = adder.mcnp.McnpNeutronics("", "mcnp.EXE", fname, 1, 1,
                                           True, 1.e-3, False)
+    neut_lib_isos = test_neut.parse_library(lib_file)
     # The next command should raise an error via the logger. In this case
     # we look for SystemExit and then read in the captured logger output
     # to compare with expectations
     caplog.clear()
     with pytest.raises(SystemExit):
-        test_mats = test_neut.read_input(lib_file, num_neutron_groups,
+        test_mats = test_neut.read_input(num_neutron_groups,
                                          user_mats_info, user_univ_info,
                                          shuffled_mats, shuffled_univs,
                                          depl_libs)
@@ -829,12 +881,13 @@ def test_mcnp_material_parsing_error(caplog, simple_lib):
 
         test_neut = adder.mcnp.McnpNeutronics("", "mcnp.EXE", fname, 1, 1,
                                               True, 1.e-3, False)
+        neut_lib_isos = test_neut.parse_library(lib_file)
         # The next command should raise an error via the logger. In this case
         # we look for SystemExit and then read in the captured logger output
         # to compare with expectations
         caplog.clear()
         with pytest.raises(SystemExit):
-            test_mats = test_neut.read_input(lib_file, num_neutron_groups,
+            test_mats = test_neut.read_input(num_neutron_groups,
                                              user_mats_info, user_univ_info,
                                              shuffled_mats, shuffled_univs,
                                              depl_libs)
@@ -880,7 +933,8 @@ def test_mcnp_material_is_depleting(simple_lib):
     # Have the parserload up the info on this model
     test_neut = adder.mcnp.McnpNeutronics("", "mcnp.EXE", fname, 1, 1,
                                           True, 1.e-3, False)
-    test_mats = test_neut.read_input(lib_file, num_neutron_groups,
+    neut_lib_isos = test_neut.parse_library(lib_file)
+    test_mats = test_neut.read_input(num_neutron_groups,
                                      user_mats_info, user_univ_info,
                                      shuffled_mats, shuffled_univs,
                                      depl_libs)
@@ -890,9 +944,11 @@ def test_mcnp_material_is_depleting(simple_lib):
     # True/False is whether or not it is depleting (based on if present in
     # simplelib)
     ref_mat_iso_info = [[('U235', '71c', True), ('O16', '70c', False)],
-                        [('U238', '72c', True), ('O16', '71c', False)]]
+                        [('U238', '72c', True), ('O16', '71c', False)],
+                        [('H4', '80c', False)]]
     for i, mat in enumerate(test_mats):
-        for j, iso in enumerate(mat.isotopes):
+        for j in range(mat.num_isotopes):
+            iso = mat.isotope_obj(j)
             assert iso.name == ref_mat_iso_info[i][j][0]
             assert iso.xs_library == ref_mat_iso_info[i][j][1]
             assert iso.is_depleting == ref_mat_iso_info[i][j][2]
@@ -908,13 +964,15 @@ def test_mcnp_material_is_depleting(simple_lib):
     user_mats_info[1]["non_depleting_isotopes"] = ['U235']
     test_neut = adder.mcnp.McnpNeutronics("", "mcnp.EXE", fname, 1, 1,
                                           True, 1.e-3, False)
-    test_mats = test_neut.read_input(lib_file, num_neutron_groups,
+    neut_lib_isos = test_neut.parse_library(lib_file)
+    test_mats = test_neut.read_input(num_neutron_groups,
                                      user_mats_info, user_univ_info,
                                      shuffled_mats, shuffled_univs,
                                      depl_libs)
     ref_mat_iso_info[0][0] = ('U235', '71c', False)
     for i, mat in enumerate(test_mats):
-        for j, iso in enumerate(mat.isotopes):
+        for j in range(mat.num_isotopes):
+            iso = mat.isotope_obj(j)
             assert iso.name == ref_mat_iso_info[i][j][0]
             assert iso.xs_library == ref_mat_iso_info[i][j][1]
             assert iso.is_depleting == ref_mat_iso_info[i][j][2]
@@ -974,11 +1032,12 @@ c lower-case comment
 
         test_neut = adder.mcnp.McnpNeutronics("", "mcnp.EXE", fname, 1, 1,
                                               True, 1.e-3, False)
+        neut_lib_isos = test_neut.parse_library(lib_file)
         # The next command should create our materials and leave log msgs
         caplog.clear()
 
         # Now parse the input
-        test_mats = test_neut.read_input(lib_file, num_neutron_groups,
+        test_mats = test_neut.read_input(num_neutron_groups,
                                          user_mats_info, user_univ_info,
                                          shuffled_mats, shuffled_univs,
                                          depl_libs)
diff --git a/tests/unit/test_msr_component.py b/tests/unit/test_msr_component.py
index b68abac..105c800 100644
--- a/tests/unit/test_msr_component.py
+++ b/tests/unit/test_msr_component.py
@@ -72,7 +72,7 @@ def test_comp_init(depletion_lib):
     assert test_c._last_dt is None
     assert test_c._last_flux is None
     np.testing.assert_allclose(test_c.library.atomic_mass_vector, amu_vec)
-    np.testing.assert_allclose(test_c.decay_matrix, decay_mat)
+    np.testing.assert_allclose(test_c.decay_matrix.todense(), decay_mat)
 
     # Check the properties
     assert test_c.delta_t == (vol * density * 1000 / mass_flowrate)
diff --git a/tests/unit/test_msr_depletion.py b/tests/unit/test_msr_depletion.py
index c955f57..0a02611 100644
--- a/tests/unit/test_msr_depletion.py
+++ b/tests/unit/test_msr_depletion.py
@@ -12,6 +12,7 @@ def test_set_msr_params(depletion_lib):
     method = "brute"
     lib = depletion_lib
     num_dens = 1. / (235.043928190 * 1.e24) * AVOGADRO
+    ISO_REGISTRY.clear()
     mat1 = Material("mat1", 1, 1. * num_dens, [["U235", "70c"]],
                     [1.], True, "71c", 1, [], IN_CORE)
     mat2 = Material("mat2", 2, 2. * num_dens, [["U235", "70c"]],
@@ -76,7 +77,7 @@ def test_set_msr_params(depletion_lib):
     num_threads = 1
     num_procs = 2
     cram_order = 16
-    chunksize = 3
+    chunksize = 0
     test_d = MSRDepletion(exec_cmd, num_threads, num_procs, chunksize,
         cram_order)
     assert test_d.exec_cmd == exec_cmd
@@ -124,6 +125,7 @@ def test_execute(depletion_lib):
     lib = depletion_lib
     depl_libs = {0: lib}
     num_dens = 1. / (235.043928190 * 1.e24) * AVOGADRO
+    ISO_REGISTRY.clear()
     mat1 = Material("mat1", 1, 1. * num_dens, [["U235", "70c"]],
                     [1.], True, "71c", 1, [], IN_CORE)
     mat2 = Material("mat2", 2, 2. * num_dens, [["U235", "70c"]],
@@ -193,6 +195,7 @@ def test_execute(depletion_lib):
         cram_order)
 
     test_d.set_msr_params("average", method, [sys_data], materials, depl_libs)
+    ISO_REGISTRY.register_depletion_lib_isos(depl_libs, [mat1, mat2, mat3])
 
     # Lets check the flux setting
     mat1.flux = np.array([1.])
@@ -228,14 +231,14 @@ def test_execute(depletion_lib):
     test_d.systems[0]._concentration_history = None
 
     # reset mat1's concentrations to match what we expect for the ref
-    mat1.isotopes = [Isotope("U235", "70c")]
+    mat1.isotopes = [("U235", "70c", True)]
     mat1.atom_fractions = [1.]
     mat1.density = 1.E-4
 
     test_d.execute(materials, depl_libs, 337.5 / 86400., 0, 1, 0.)
 
     # Solution same as in test_msr_system
-    calc_isos = [iso.name for iso in mat1.isotopes]
+    calc_isos = [mat1.isotope_obj(i).name for i in range(mat1.num_isotopes)]
     assert calc_isos == ["H1", "U235"]
     np.testing.assert_allclose(mat1.number_densities,
                                [5.28e14, 1.0e+20], rtol=1.8E-7)
diff --git a/tests/unit/test_origen22depletion.py b/tests/unit/test_origen22depletion.py
index 6f42b02..0e8ad51 100644
--- a/tests/unit/test_origen22depletion.py
+++ b/tests/unit/test_origen22depletion.py
@@ -36,7 +36,7 @@ def test_depletion_init():
         test_d = Origen22Depletion(exec_cmd, num_threads, num_procs,
                                    str(chunksize))
     with pytest.raises(ValueError):
-        test_d = Origen22Depletion(exec_cmd, num_threads, num_procs, 0)
+        test_d = Origen22Depletion(exec_cmd, num_threads, num_procs, -1)
 
     # Check that the attributes exist and their values are set correctly
     test_d = Origen22Depletion(exec_cmd, num_threads, num_procs, chunksize)
diff --git a/tests/unit/test_reactor.py b/tests/unit/test_reactor.py
index e401d87..3f88e0e 100755
--- a/tests/unit/test_reactor.py
+++ b/tests/unit/test_reactor.py
@@ -1,8 +1,13 @@
 import adder
+from adder.input import create_mat_supply_storage, create_univ_supply_storage
+from adder.mcnp.cell import Cell
+from adder.mcnp.universe import Universe
+from adder.constants import IN_CORE, STORAGE, SUPPLY
 from collections import OrderedDict
 import pytest
 import numpy as np
 import logging
+import adder.mcnp as mcnp
 
 
 def test_reactor_init():
@@ -19,7 +24,7 @@ def test_reactor_init():
     h5_filename = "test.h5"
     num_threads = 2
     num_procs = 4
-    chunksize = 20
+    chunksize = 0
     use_depletion_library_xs = True
     reactivity_thresh = 1.E-8
     reactivity_thresh_init = False
@@ -174,7 +179,7 @@ def test_reactor_init():
         test_rx = adder.Reactor(name, neutronics_solver, depletion_solver,
                                 mpi_cmd, neutronics_exec, depletion_exec,
                                 base_neutronics_input_file, h5_filename,
-                                num_threads, num_threads, num_procs, 0,
+                                num_threads, num_threads, num_procs, -1,
                                 use_depletion_library_xs, reactivity_thresh,
                                 reactivity_thresh_init)
 
@@ -332,7 +337,12 @@ def test_reactor_init_materials_and_input(caplog, depletion_lib):
     user_mats_info[2]["volume"] = 1.
     user_mats_info[2]["non_depleting_isotopes"] = ["U238"]
     user_mats_info[2]["use_default_depletion_library"] = True
-    user_mats_info[2]["apply_reactivity_threshold_to_initial_inventory"] = True
+    user_mats_info[7] = OrderedDict()
+    user_mats_info[7]["name"] = "supply_123_test"
+    user_mats_info[7]["depleting"] = True
+    user_mats_info[7]["non_depleting_isotopes"] = []
+    user_mats_info[7]["use_default_depletion_library"] = True
+    user_mats_info[7]["status"] = 2
     user_univ_info = OrderedDict()
     shuffled_mats = set()
     shuffled_univs = set()
@@ -380,18 +390,15 @@ def test_reactor_init_materials_and_input(caplog, depletion_lib):
                                      shuffled_mats, shuffled_univs)
 
     # Check the materials
+    exp_names = [str(1), "mat 2", "supply_123_test"]
+    exp_volumes = [None, 1., None]
     for i, test_mat in enumerate(test_rx.materials):
-        if i == 0:
-            assert test_mat.name == str(i + 1)
-        else:
-            assert test_mat.name == "mat 2"
+        assert test_mat.name == exp_names[i]
         assert test_mat.density == 1.
-        if i == 0:
-            assert test_mat.volume is None
-        else:
-            assert test_mat.volume == 1.
+        assert test_mat.volume == exp_volumes[i]
         isotope_data = [("H1", "70c"), ["U235", "70c"], ["U238", "72c"]]
-        for j, test_iso in enumerate(test_mat.isotopes):
+        for j in range(test_mat.num_isotopes):
+            test_iso = test_mat.isotope_obj(j)
             assert test_iso.name == isotope_data[j][0]
             assert test_iso.xs_library == isotope_data[j][1]
             if j == 0:
@@ -404,10 +411,10 @@ def test_reactor_init_materials_and_input(caplog, depletion_lib):
                     assert test_iso.is_depleting is True
 
         np.testing.assert_equal(test_mat.atom_fractions, [0.4, 0.5, 0.1])
-        if i == 0:
-            assert test_mat.is_depleting is True
-        else:
+        if i == 1:
             assert test_mat.is_depleting is False
+        else:
+            assert test_mat.is_depleting is True
         assert test_mat.default_xs_library == "71c"
         if i == 0:
             assert test_mat.is_default_depletion_library is False
@@ -416,7 +423,7 @@ def test_reactor_init_materials_and_input(caplog, depletion_lib):
             assert test_mat.is_default_depletion_library is True
             assert test_mat.depl_lib_name is 0
         assert test_mat.thermal_xs_libraries == []
-        assert test_mat.isotopes_in_neutronics == [True, True, True]
+        assert np.all(test_mat.isotopes_in_neutronics == True)
         assert test_mat.num_isotopes == 3
         if i == 0:
             assert isinstance(test_mat.isotopes_to_keep_in_model, set)
@@ -445,7 +452,8 @@ def test_reactor_init_materials_and_input(caplog, depletion_lib):
          ID  |  Depl  |       Name        |  Vol [cc]
 -----------------------------------------------------
           1  |  True  |         1         | None
-          2  | False  |       mat 2       | 1.000000E+00"""
+          2  | False  |       mat 2       | 1.000000E+00
+          7  |  True  |  supply_123_test  | None"""
 
     # Convert ref_txt to a list of stripped lines
     # To avoid pytest version specific differences, we will remove whitespace
@@ -483,11 +491,24 @@ def test_reactor_init_materials_and_input(caplog, depletion_lib):
     test_rx.materials[0].status = 1
     assert test_rx.total_volume == 1.
 
+    # Check that the validate storage materials method 
+    # correctly creates a unique depletion library if the
+    # is_default_depletion_library flag is False
+    storage_mat = test_rx.materials[2]
+    storage_mat.status = 1 
+    assert storage_mat.depl_lib_name == 0
+    test_rx.validate_storage_materials()
+    assert storage_mat.depl_lib_name == 0
+    storage_mat.is_default_depletion_library = False
+    test_rx.validate_storage_materials()
+    assert storage_mat.depl_lib_name == 'supply_123_test'
+
 
 def test_reactor_update_depletion_constants(simple_lib):
     # Note: this method also fully tests:
     # Reactor._flux_scaling_constant(...)
     # Reactor._update_material_fluxes(...)
+    # Reactor._update_material_fission_quantities(...)
     # Reactor._update_Q_recoverable()
 
     # Set up base reactor with 2 materials (same as in previous test)
@@ -520,7 +541,7 @@ def test_reactor_update_depletion_constants(simple_lib):
 
     # Now create a reactor we can assign the materials to
     name = "test"
-    neutronics_solver = "test"
+    neutronics_solver = "mcnp"
     depletion_solver = "test"
     neutronics_exec = "mcnp.EXE"
     depletion_exec = "origen2.EXE"
@@ -540,6 +561,9 @@ def test_reactor_update_depletion_constants(simple_lib):
     test_rx.power = 7.
     use_power = True
 
+    # Set arbitrary irradiation times for updating depletion constants
+    dts = [10.37, 9.81, 5.11]
+
     # Now build our flux and volume dictionaries
     flux = OrderedDict()
     flux[1] = np.array([3.0])
@@ -547,6 +571,20 @@ def test_reactor_update_depletion_constants(simple_lib):
     volumes = OrderedDict()
     volumes[1] = 0.5
     volumes[2] = 0.7
+    user_tally_res = OrderedDict()
+    user_tally_res[4] = {}
+    user_tally_res[4]["material_names"] = ["m1", "m3", "m5"]
+    user_tally_res[4]["universe_names"] = ["u1", "u3", "u5"]
+    user_tally_res[4]["facet_ids"] = [100, 300, 500]
+    user_tally_res[4]["tally_matrix"] = np.array([[11, 2], [3, 5], [4, 74], [21, 10],
+                                        [1, 15], [34, 51], [33, 56], [37, 50],])
+    user_tally_res[4]["tally_matrix_err"] = np.array([[0.11, 2], [0.3, 0.5], [0.4, 0.74],
+                                                      [0.21, 0.10],[0.1, 0.15], [0.34, 0.51],
+                                                      [0.33, 0.56], [0.37, 0.50],])
+
+    # create user tally
+    test_rx.neutronics.user_tallies={}
+    test_rx.neutronics.user_tallies[4] = adder.Tally(id=4)
 
     # Set our constants to values to be used in updating our fluxes
     keff = 2.0
@@ -586,17 +624,37 @@ def test_reactor_update_depletion_constants(simple_lib):
     ref_tot_fr = v1_fr + v2_fr
     ref_Q_recov = ref_tot_Q / ref_tot_fr
 
+    # Reference flux normalization factor
+    ref_flux_norm = 7. * nu / (keff * ref_Q_recov * 1.6021766208e-19)
+
+    # Power density, burnup, fission density
+    dt = dts[0]
+    ref_power_density1 = ref_flux_norm * 3.0 * v1_Q * \
+                         1.6021766208e-19 * 1.0e6 / 0.5
+    ref_power_density2 = ref_flux_norm * 6.0 * v2_Q * \
+                         1.6021766208e-19 * 1.0e6 / 0.7
+    ref_burnup1 = ref_power_density1 * 0.5 * 1.0e-6 * dt
+    ref_burnup2 = ref_power_density2 * 0.5 * 1.0e-6 * dt
+    ref_fission_density1 = ref_flux_norm * 3.0 * v1_fr * dt * 86400 / 0.5
+    ref_fission_density2 = ref_flux_norm * 6.0 * v2_fr * dt * 86400 / 0.7
+
     def _reset_vals(test_rx):
         # Reset tested values
         test_rx.Q_recoverable = -1.
         test_rx.materials[0].volume = 0.
         test_rx.materials[1].volume = 0.
         test_rx.materials[0].flux[0] = 0.
-        test_rx.materials[0].flux[0] = 0.
+        test_rx.materials[1].flux[0] = 0.
 
     # Now update our fluxes
+    # (VM, 8/15/2024) ..and check power density, burnup, fission density
     _reset_vals(test_rx)
-    test_rx._update_depletion_constants(flux, nu, keff, use_power, volumes)
+
+    is_zero_power = False
+    test_rx._update_depletion_constants(flux, nu, keff, use_power, volumes, user_tally_res,
+                                        is_zero_power, dt)
+    assert (abs(test_rx.flux_normalization - ref_flux_norm) / ref_flux_norm) \
+           < 3.e-14
     assert abs(test_rx.Q_recoverable - ref_Q_recov) < 3.e-14
     ref_flux1 = 8.4 * 3.0 / 3.23194554407919E-17
     ref_flux1 = nu * test_rx.power * 3.0 / \
@@ -609,39 +667,99 @@ def test_reactor_update_depletion_constants(simple_lib):
     assert (abs(test_rx.flux_level - ref_flux_level) / ref_flux_level) < 1.e-14
     assert abs(test_rx.materials[0].volume - volumes[1]) < 1.e-15
     assert abs(test_rx.materials[1].volume - volumes[2]) < 1.e-15
+    assert (abs(test_rx.materials[0].power_density - ref_power_density1) \
+            / ref_power_density1) < 1.e-15
+    assert (abs(test_rx.materials[1].power_density - ref_power_density2)) \
+           < 1.e-15
+    assert (abs(test_rx.materials[0].burnup - ref_burnup1) / ref_burnup1) \
+           < 1.e-15
+    assert (abs(test_rx.materials[1].burnup - ref_burnup2)) < 1.e-15
+    assert (abs(test_rx.materials[0].fission_density - ref_fission_density1) \
+            / ref_fission_density1) < 1.e-15
+    assert (abs(test_rx.materials[1].fission_density - ref_fission_density2)) \
+           < 1.e-15
 
     # Try with a zero power case
+    # (VM, 8/15/2024) Note that the burnup and fission density are integrated
+    #                 over time and, as such, should not be 0 but unchanged
+    dt = dts[1]
     _reset_vals(test_rx)
+    zero_flux = OrderedDict()
+    zero_flux[1] = np.array([0.])
+    zero_flux[2] = np.array([0.])
+    ref_Q_recov_zero = 0
     test_rx.power = 0.
-    test_rx._update_depletion_constants(flux, nu, keff, use_power, volumes)
-    assert abs(test_rx.Q_recoverable - ref_Q_recov) < 3.e-14
+
+    is_zero_power = True
+    test_rx._update_depletion_constants(flux, nu, keff, use_power, volumes, user_tally_res,
+                                        is_zero_power, dt)
+    assert abs(test_rx.Q_recoverable - ref_Q_recov_zero) < 3.e-14
     assert test_rx.materials[0].flux[0] == 0.
     assert test_rx.materials[1].flux[0] == 0.
     assert abs(test_rx.materials[0].volume - volumes[1]) < 1.e-15
     assert abs(test_rx.materials[1].volume - volumes[2]) < 1.e-15
     assert test_rx.flux_level == 0.
+    assert test_rx.materials[0].power_density == 0.
+    assert test_rx.materials[1].power_density == 0.
+    assert (abs(test_rx.materials[0].burnup - ref_burnup1) / ref_burnup1) \
+           < 1.e-15
+    assert (abs(test_rx.materials[1].burnup - ref_burnup2)) < 1.e-15
+    assert (abs(test_rx.materials[0].fission_density - ref_fission_density1) \
+            / ref_fission_density1) < 1.e-15
+    assert (abs(test_rx.materials[1].fission_density - ref_fission_density2)) \
+           < 1.e-15
 
     # Try with setting flux instead of power
-    test_rx.flux_level = 10.0
+    dt = dts[2]
+    test_rx.flux_level = 1e18
+    ref_power_density1 = 1e18 * v1_Q * 1.6021766208e-19 * 1.0e6 / 0.5
+    ref_power_density2 = 0.0
+    ref_burnup1 += ref_power_density1 * 0.5 * 1.0e-6 * dt
+    ref_burnup2 += ref_power_density2 * 0.5 * 1.0e-6 * dt
+    ref_fission_density1 += 1e18 * v1_fr * dt * 86400 / 0.5
+    ref_fission_density2 += 0.0 * v2_fr * dt * 86400 / 0.7
+    is_zero_power = False
     use_power = False
     Vtot = volumes[1]
     _reset_vals(test_rx)
-    test_rx._update_depletion_constants(flux, nu, keff, use_power, volumes)
+    test_rx._update_depletion_constants(flux, nu, keff, use_power, volumes, user_tally_res,
+                                        is_zero_power, dt)
     assert abs(test_rx.Q_recoverable - ref_Q_recov) < 3.e-14
     assert abs(test_rx.materials[0].flux[0] - test_rx.flux_level) < 1.e-15
     assert test_rx.materials[1].flux[0] == 0.
     assert abs(test_rx.materials[0].volume - volumes[1]) < 1.e-15
     assert abs(test_rx.materials[1].volume - volumes[2]) < 1.e-15
+    assert (abs(test_rx.materials[0].power_density - ref_power_density1) \
+            / ref_power_density1) < 1.e-15
+    assert (abs(test_rx.materials[1].power_density - ref_power_density2)) \
+           < 1.e-15
+    assert (abs(test_rx.materials[0].burnup - ref_burnup1) / ref_burnup1) \
+           < 1.e-15
+    assert (abs(test_rx.materials[1].burnup - ref_burnup2)) < 1.e-15
+    assert (abs(test_rx.materials[0].fission_density - ref_fission_density1) \
+            / ref_fission_density1) < 1.e-15
+    assert (abs(test_rx.materials[1].fission_density - ref_fission_density2)) \
+           < 1.e-15
 
     # Try with a zero power case (w/ flux_level in use)
     _reset_vals(test_rx)
     test_rx.flux_level = 0.
-    test_rx._update_depletion_constants(flux, nu, keff, use_power, volumes)
+    test_rx._update_depletion_constants(flux, nu, keff, use_power, volumes, user_tally_res,
+                                        is_zero_power, dt)
     assert abs(test_rx.Q_recoverable - ref_Q_recov) < 3.e-14
     assert test_rx.materials[0].flux[0] == 0.
     assert test_rx.materials[1].flux[0] == 0.
     assert abs(test_rx.materials[0].volume - volumes[1]) < 1.e-15
     assert abs(test_rx.materials[1].volume - volumes[2]) < 1.e-15
+    assert test_rx.materials[0].power_density == 0.
+    assert test_rx.materials[1].power_density == 0.
+    assert (abs(test_rx.materials[0].burnup - ref_burnup1) / ref_burnup1) \
+           < 1.e-15
+    assert (abs(test_rx.materials[1].burnup - ref_burnup2)) < 1.e-15
+    assert (abs(test_rx.materials[0].fission_density - ref_fission_density1) \
+            / ref_fission_density1) < 1.e-15
+    assert (abs(test_rx.materials[1].fission_density - ref_fission_density2)) \
+           < 1.e-15
 
 
 def test_reactor_hdf5(depletion_lib):
@@ -697,7 +815,7 @@ def test_reactor_hdf5(depletion_lib):
     assert new_test_rx.name == name
     assert new_test_rx.neutronics.solver == neutronics_solver
     assert new_test_rx.depletion.solver == depletion_solver
-    assert len(new_test_rx.materials) == 2
+    assert len(new_test_rx.materials) == 3
     assert test_rx.case_label == "Initial"
     assert test_rx.operation_label == "Initial"
     assert test_rx.case_idx == 0
@@ -721,18 +839,15 @@ def test_reactor_hdf5(depletion_lib):
     assert new_test_rx.end_time is None
 
     # Check the materials
+    exp_names = [str(1), "mat 2", "supply_123_test"]
+    exp_volumes = [None, 1., None]
     for i, test_mat in enumerate(test_rx.materials):
-        if i == 0:
-            assert test_mat.name == str(i + 1)
-        else:
-            assert test_mat.name == "mat 2"
+        assert test_mat.name == exp_names[i]
         assert test_mat.density == 1.
-        if i == 0:
-            assert test_mat.volume is None
-        else:
-            assert test_mat.volume == 1.
+        assert test_mat.volume == exp_volumes[i]
         isotope_data = [("H1", "70c"), ["U235", "70c"], ["U238", "72c"]]
-        for j, test_iso in enumerate(test_mat.isotopes):
+        for j in range(test_mat.num_isotopes):
+            test_iso = test_mat.isotope_obj(j)
             assert test_iso.name == isotope_data[j][0]
             assert test_iso.xs_library == isotope_data[j][1]
             if j == 0:
@@ -746,10 +861,10 @@ def test_reactor_hdf5(depletion_lib):
 
         np.testing.assert_allclose(test_mat.atom_fractions,
                                    [0.4, 0.5, 0.1], rtol=1.e-16, atol=1.e-16)
-        if i == 0:
-            assert test_mat.is_depleting is True
-        else:
+        if i == 1:
             assert test_mat.is_depleting is False
+        else:
+            assert test_mat.is_depleting is True
         assert test_mat.default_xs_library == "71c"
         if i == 0:
             assert test_mat.is_default_depletion_library is False
@@ -758,7 +873,7 @@ def test_reactor_hdf5(depletion_lib):
             assert test_mat.is_default_depletion_library is True
             assert test_mat.depl_lib_name is 0
         assert test_mat.thermal_xs_libraries == []
-        assert test_mat.isotopes_in_neutronics == [True, True, True]
+        assert np.all(test_mat.isotopes_in_neutronics == True)
         assert test_mat.num_isotopes == 3
 
 
@@ -817,3 +932,264 @@ def test_reactor_init_library(caplog):
         assert last_log == ('adder.reactor', logging.ERROR,
                             'Depletion Library gobledy_gook.h5 Was Not Found!')
     caplog.clear()
+
+def test_reactor_materials_depl_lib(caplog, depletion_lib, monkeypatch):
+    # This test ensures that storage materials are assigned unique depletion
+    # libraries after being redefined from supply in the ADDER input file
+
+    # Set the parameters needed to initialize classes
+    name = "test"
+    neutronics_solver = "test"
+    depletion_solver = "test"
+    mpi_cmd = "mpirun"
+    neutronics_exec = "mcnp.EXE"
+    depletion_exec = "origen2.EXE"
+    base_neutronics_input_file = "sometext"
+    h5_filename = "test.h5"
+    num_threads = 2
+    num_procs = 4
+    chunksize = 0
+    reactivity_thresh = 1.E-8
+    reactivity_thresh_init = False
+    neutronics_library_file = "test_lib_file.txt"
+    depletion_lib_file = "test_lib.h5"
+    depletion_lib_name = "test"
+    depletion_lib.to_hdf5("test_lib.h5")
+
+    # Set common materials information
+    statuses = [
+        SUPPLY, IN_CORE, IN_CORE, SUPPLY, SUPPLY,
+        IN_CORE, IN_CORE, SUPPLY, IN_CORE, IN_CORE,
+        SUPPLY, SUPPLY, IN_CORE, IN_CORE, SUPPLY,
+        IN_CORE, SUPPLY, IN_CORE, SUPPLY, IN_CORE,
+        IN_CORE, IN_CORE, SUPPLY, SUPPLY, SUPPLY
+    ]
+    density = 1.0
+    isotope_data = [("H1", "70c"), ["U235", "70c"], ["U238", "72c"]]
+    atom_fractions = [4., 5., 1.]
+    is_depleting = True
+    default_xs_library = "71c"
+    num_groups = 1
+    thermal_xs_libraries = []
+
+    # Two different behaviors depending on whether the default xs is to be used
+    for use_depletion_library_xs in [False, True]:
+
+        # Setup the test reactor
+        test_rx = adder.Reactor(name, neutronics_solver, depletion_solver,
+                                mpi_cmd, neutronics_exec, depletion_exec,
+                                base_neutronics_input_file, h5_filename,
+                                num_threads, num_threads, num_procs, chunksize,
+                                use_depletion_library_xs, reactivity_thresh,
+                                reactivity_thresh_init)
+    
+        # Generate a set of made-up materials
+        custom_mats = []
+        for idx, status in enumerate(statuses):
+            mat_id = idx + 1
+            name = f'test_{mat_id}_{status}'
+            mat = adder.Material(name, mat_id, density, isotope_data,
+                                 atom_fractions, is_depleting, default_xs_library,
+                                 num_groups, thermal_xs_libraries, status)
+            custom_mats.append(mat)
+    
+        # Define monkeypatch function to return materials
+        def mock_read_input(*args, **kwargs):
+            return custom_mats 
+    
+        # Initialize materials
+        monkeypatch.setattr(test_rx.neutronics, "read_input", mock_read_input) 
+        test_rx.init_materials_and_input(neutronics_library_file,
+                                         depletion_lib_file, depletion_lib_name,
+                                         OrderedDict(), OrderedDict(),
+                                         OrderedDict(), OrderedDict())
+        
+        # Check that the materials have the status setup above (sanity check)
+        for i, status in enumerate(statuses):
+            assert test_rx.materials[i].status == status
+    
+        # Simulate adjusting materials from supply to storage    
+        ids = [4,7,10,22,23]
+        config_storage = {
+            'redefine': {
+                'list':     {
+                    'neutronics_ids': [custom_mats[i].id for i in ids]
+                }
+            }
+        }
+        create_mat_supply_storage(config_storage, 
+                                  test_rx.materials, test_rx.depletion_libs,
+                                  "[materials][[storage]]")
+
+        # Validate storage materials and assign unique libraries as needed
+        test_rx.validate_storage_materials()
+    
+        # Assert that selected materials have changed state to STORAGE
+        for i in ids:
+            assert test_rx.materials[i].status == STORAGE
+    
+        # Cycle through all the materials and check their depletion libraries
+        lib_names = test_rx.depletion_libs.keys()
+        for test_mat in test_rx.materials: 
+            assert test_mat.status in [IN_CORE, STORAGE, SUPPLY]
+            if use_depletion_library_xs:
+                # All materials should be assigned the default xs library
+                assert test_mat.depl_lib_name is 0
+            else:
+                # Assert that SUPPLY mats are using the default xs library, 
+                # whereas STORAGE materials are assigned unique xs librares 
+                if test_mat.status == SUPPLY:
+                    assert test_mat.depl_lib_name is 0
+                elif test_mat.status in [STORAGE, IN_CORE]: 
+                    assert test_mat.depl_lib_name == test_mat.name
+                    assert test_mat.depl_lib_name in lib_names
+
+    # Clear log
+    caplog.clear()
+
+
+def test_reactor_universes_depl_lib(caplog, depletion_lib, monkeypatch):
+    # This test ensures that storage universes are assigned unique depletion
+    # libraries after being redefined from supply in the ADDER input file
+
+    # Set the parameters needed to initialize classes
+    name = "test"
+    neutronics_solver = "test"
+    depletion_solver = "test"
+    mpi_cmd = "mpirun"
+    neutronics_exec = "mcnp.EXE"
+    depletion_exec = "origen2.EXE"
+    base_neutronics_input_file = "sometext"
+    h5_filename = "test.h5"
+    num_threads = 2
+    num_procs = 4
+    chunksize = 0
+    reactivity_thresh = 1.E-8
+    reactivity_thresh_init = False
+    neutronics_library_file = "test_lib_file.txt"
+    depletion_lib_file = "test_lib.h5"
+    depletion_lib_name = "test"
+    depletion_lib.to_hdf5("test_lib.h5")
+
+    # Set common materials information
+    density = 1.0
+    isotope_data = [("H1", "70c"), ["U235", "70c"], ["U238", "72c"]]
+    atom_fractions = [4., 5., 1.]
+    is_depleting = True
+    default_xs_library = "71c"
+    num_groups = 1
+    thermal_xs_libraries = []
+    surfaces = [10, 20, 30, 40, -50]
+
+    # For setting up our universes
+    statuses = [IN_CORE, SUPPLY, IN_CORE, SUPPLY, IN_CORE, SUPPLY]
+    custom_universe_ids = [0, 3, 9, 7, 18, 11]
+
+    # Two different behaviors depending on whether the default xs is to be used
+    for use_depletion_library_xs in [False, True]:
+
+        # Setup the test reactor
+        test_rx = adder.Reactor(name, neutronics_solver, depletion_solver,
+                                mpi_cmd, neutronics_exec, depletion_exec,
+                                base_neutronics_input_file, h5_filename,
+                                num_threads, num_threads, num_procs, chunksize,
+                                use_depletion_library_xs, reactivity_thresh,
+                                reactivity_thresh_init)
+
+        # Setup cells, materials, and universes
+        custom_cells = []
+        custom_mats = []
+        custom_universes = OrderedDict()
+        for universe_id, status in zip(custom_universe_ids, statuses):
+            uni_name = f'uni_test_{universe_id}_{status}'
+            universe = Universe(uni_name, universe_id)
+            for idx in range(10):
+                mat_id = (idx + 1) + universe_id*10
+                cell_id = mat_id
+                name = f'test_{mat_id}_{status}'
+                mat = adder.Material(name, mat_id, density, isotope_data,
+                                     atom_fractions, is_depleting, default_xs_library,
+                                     num_groups, thermal_xs_libraries, status)
+                cell = Cell(cell_id, mat.id, density, surfaces,
+                                  universe_id=universe_id)
+                cell.material = mat
+                universe.add_cells([cell])
+                custom_mats.append(mat)
+                custom_cells.append(cell)
+            custom_universes[universe_id] = universe
+
+        # Define monkeypatch function to return materials
+        def mock_read_input(*args, **kwargs):
+            return custom_mats 
+    
+        # Initialize materials and assign cells and universes to test reactor
+        monkeypatch.setattr(test_rx.neutronics, "read_input", mock_read_input) 
+        test_rx.init_materials_and_input(neutronics_library_file,
+                                         depletion_lib_file, depletion_lib_name,
+                                         OrderedDict(), OrderedDict(),
+                                         OrderedDict(), OrderedDict())
+        test_rx.neutronics.cells = custom_cells
+        test_rx.neutronics.universes = custom_universes
+
+        # Check that the materials and associated cells and universes have the 
+        # status defined above (sanity check)
+        for test_univ, status in zip(test_rx.neutronics.universes.values(), 
+                                     statuses):
+            assert test_univ.status == status
+            for test_cell in test_univ.cells.values():
+                test_mat = test_cell.material
+                assert test_cell.status == status
+                assert test_mat.status == status
+                
+    
+        # Simulate adjusting universes from supply to storage    
+        config_storage = {
+            'redefine': {
+                'item':     {
+                    'neutronics_id': 3
+                },
+                'item_2':   {
+                    'neutronics_id': 11
+                }
+            }
+        }
+        create_univ_supply_storage(config_storage, test_rx, 
+                                   "[universes][[storage]]")
+
+        # Validate storage materials and assign unique libraries as needed
+        test_rx.validate_storage_materials()
+
+        # Assert that selected universes and corresponding cells and materials 
+        # have changed status to STORAGE
+        test_univs = [x for x in test_rx.neutronics.universes.values() 
+                      if x.id in [3,11]]
+        for test_univ in test_univs:
+            assert test_univ.status == STORAGE
+            for test_cell in test_univ.cells.values():
+                test_mat = test_cell.material
+                assert test_cell.status == STORAGE
+                assert test_mat.status == STORAGE
+    
+        # Cycle through all the universes and associated materials and cells
+        # and check their status and the materials' depletion libraries
+        lib_names = test_rx.depletion_libs.keys()
+        for test_univ in test_rx.neutronics.universes.values(): 
+            assert test_univ.status in [IN_CORE, STORAGE, SUPPLY]
+            for test_cell in test_univ.cells.values():
+                test_mat = test_cell.material
+                assert test_cell.status == test_univ.status
+                assert test_mat.status == test_univ.status
+                if use_depletion_library_xs:
+                    # All materials should be assigned the default xs library
+                    assert test_mat.depl_lib_name is 0
+                else:
+                    # Assert that SUPPLY mats are using the default xs library, 
+                    # whereas STORAGE materials are assigned unique xs librares 
+                    if test_mat.status == SUPPLY:
+                        assert test_mat.depl_lib_name is 0
+                    elif test_mat.status in [STORAGE, IN_CORE]: 
+                        assert test_mat.depl_lib_name == test_mat.name
+                        assert test_mat.depl_lib_name in lib_names
+
+    # Clear log
+    caplog.clear()
